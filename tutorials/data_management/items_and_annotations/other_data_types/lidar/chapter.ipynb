{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR Data Setup\n",
    "\n",
    "## Using Dataloop Mapping\n",
    "\n",
    "### Files and Calibration Data Setup\n",
    "\n",
    "To prepare a dataset for LiDAR video creation, please ensure that you complete the prerequisite steps outlined in the [LiDAR Data Setup](https://docs.dataloop.ai/docs/lidar-data-setup) documentation.\n",
    "\n",
    "### Create the LiDAR Video File\n",
    "\n",
    "Once all files are ready, to create the LiDAR video file (of all the PCD files stitched together), do as follows:\n",
    "\n",
    "1. Install [Dataloop LiDAR SDK](https://github.com/dataloop-ai-apps/dtlpy-lidar) to your local python environment, using the command:\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n   pip install git+https://github.com/dataloop-ai-apps/dtlpy-lidar.git\n   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Use the following code snippet to create the LiDAR video file:\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "   from dtlpylidar.parsers.base_parser import LidarFileMappingParser\n",
    "\n",
    "   dataset = dl.datasets.get(dataset_id=\"<dataset id>\")\n",
    "   mapping_item = dataset.items.get(item_id=\"<mapping.json item id>\")\n",
    "   frames_item = LidarFileMappingParser().parse_data(mapping_item=mapping_item)\n",
    "   frames_item.open_in_web()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. The output item will be a `frame.json` file (the LiDAR video file) with all the PCD files stitched together,\n",
    "   where each frame contains the following information:\n",
    "\n",
    "   - **PCD file:** The point cloud data of the 3D scene for the given frame.\n",
    "   - **JPEG/PNG files:** The 2D images of the available camera sources for the given frame.\n",
    "   - **Calibration data:** The calibration data of the LiDAR sensor and the camera sources for the given frame (as was specified in the `mapping.json` file).\n",
    "\n",
    "4. (Optional) Once all files are ready, contact Dataloop to execute the Ground Detection - on each provided .pcd file to enable the Ground Detection Toggle on the LiDAR Studio.\n",
    "\n",
    "### Upload Framed Annotations\n",
    "\n",
    "See how to upload different types of framed annotations to the LiDAR video item in the [Annotations](https://developers.dataloop.ai/tutorials/annotations/) page, under **LiDAR Annotations** section.\n",
    "\n",
    "**Notice:** Make sure that the `frames.json` file includes the `fps` key in its metadata. \\\n",
    "Set it to a default value of `1` if it is not already present.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n{\n  \"system\": {\n    \"originalname\": \"frames.json\",\n    \"size\": 32712,\n    \"encoding\": \"7bit\",\n    \"shebang\": {\n      \"dltype\": \"PCDFrames\"\n    },\n    \"taskStatusLog\": [],\n    \"mimetype\": \"application/json\",\n    \"isBinary\": false,\n    \"refs\": []\n  },\n  \"fps\": 1\n}\n```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Using Custom LiDAR Parser\n",
    "\n",
    "### Brief explanation\n",
    "\n",
    "This section provides an advanced guide about how to set up a LiDAR scene dataset and create a LiDAR video file on the\n",
    "Dataloop platform for any directory structure of a LiDAR scene, as long as the files are in the following formats:\n",
    "\n",
    "1. **3D Scene Files** - Point Cloud Data files in `.pcd` **ASCII** format with a size limit of 70 MB.\n",
    "2. **2D Camera Views Files** - Image files in JPEG/PNG formats.\n",
    "3. **Calibration Data Files** - Any file format that contains the required [Camera Calibration Parameters](https://www.mathworks.com/help/vision/ug/camera-calibration.html#:~:text=the%20intrinsics%20parameters.-,Camera%20Calibration%20Parameters,-The%20calibration%20algorithm).\n",
    "\n",
    "In this guide we will show an example of modifying the [CustomBaseParser](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py)\n",
    "to support the [PandaSet](https://www.kaggle.com/datasets/usharengaraju/pandaset-dataset) dataset. \\\n",
    "However, this parser can be extended to support custom LiDAR scenes by modifying the available `Customizable` methods as needed.\n",
    "\n",
    "### Step 1: Files Setup\n",
    "\n",
    "Create a dataset on the Dataloop platform and upload the following required LiDAR files to the dataset:\n",
    "\n",
    "1. **3D Scene Files** - Point Cloud Data files used for generating the 3D scenes.\n",
    "2. **2D Camera Views Files** - Usually showing the angle and viewport of the cameras that captured the main scene.\n",
    "3. **Calibration Data Files** Any type of files that contains all required information to align the point cloud data with the camera images.\n",
    "   For a detailed explanation about the parameters required in the mapping.json file, please refer to the Camera Calibration Parameters.\n",
    "\n",
    "#### Example of arranging the files with PandaSet\n",
    "\n",
    "To prepare the PandaSet dataset, do as follows:\n",
    "\n",
    "1. Go to [PandaSet Kaggle Page](https://www.kaggle.com/datasets/usharengaraju/pandaset-dataset).\n",
    "2. Download the dataset and extract the files from the `.zip` file.\n",
    "3. Open a project on the Dataloop platform and create a new dataset for it.\n",
    "4. Select a scene folder from the extracted files in the `.zip` file keep the following folders:\n",
    "   - `lidar`\n",
    "   - `camera`\n",
    "5. **Normalize the data**, by updating the folders files through the following steps:\n",
    "   1. Locate the `poses.json` file in the `lidar` folder and open it.\n",
    "   2. Convert the PCD files from `.ply` to `.pcd` format, and apply the transformations from the `poses.json` file to the PCD files.\n",
    "6. Upload the folders with the updated files to the dataset on the Dataloop platform.\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "- **File Format Assumptions:** \\\n",
    "  The converter requires that the remote dataset will already have the PandaSet 3D scene files in `.pkl` format to converted into `.pcd` format. \\\n",
    "  For more details on why `.pcd` files are preferred, please refer to the [PCD file format documentation](https://pointclouds.org/documentation/tutorials/pcd_file_format.html).\n",
    "- **Conversion Scripts:** \\\n",
    "  You can find helpful scripts for converting `.pkl` files to `.pcd` in the `dtlpylidar/utilities/converters` directory, on [Dataloop LiDAR SDK](https://github.com/dataloop-ai-apps/dtlpy-lidar),\n",
    "  or you can use the provided example in the section (Upload PandaSet to Dataloop) for uploading the PandaSet dataset with the updated files.\n",
    "\n",
    "#### Dataset structure explanation\n",
    "\n",
    "The PandaSet scene folder structure:\n",
    "\n",
    "- `lidar`:\n",
    "  - Point cloud files in `.pkl` format for each frame (must be converted to `.pcd` format).\n",
    "  - `poses.json` \u2013 contains the poses for each frame.\n",
    "  - `timestamps.json` (optional) \u2013 includes timestamps for the frames.\n",
    "- `camera`:\n",
    "  - Per-camera sub-folder:\n",
    "    - Images for each frame.\n",
    "    - `intrinsics.json` \u2013 camera intrinsic parameters.\n",
    "    - `poses.json` \u2013 camera poses.\n",
    "    - `timestamps.json` (optional) \u2013 includes timestamps for the frames.\n",
    "\n",
    "#### Json files structure\n",
    "\n",
    "##### - `poses.json` file structure (similar for lidar and cameras)\n",
    "\n",
    "Each object refer to a different frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"position\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.0}, \"heading\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}},  # PCD frame 0 extrinsics / Camera N frame 0 extrinsics\n",
    "    {\"position\": {\"x\": 0.5, \"y\": 0.5, \"z\": 0.0}, \"heading\": {\"w\": 1.0, \"x\": 0.0, \"y\": 0.0, \"z\": 0.0}}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### - `intrinsics.json` file structure (for cameras)\n",
    "\n",
    "Each camera has static intrinsics calibrations across all its images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"fx\": 933.4667, \"fy\": 934.6754, \"cx\": 896.4692, \"cy\": 507.3557}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### - `timestamps.json` file structure (similar for lidar and cameras)\n",
    "\n",
    "Each object refer to a different frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    1557539924.49981,  # PCD frame 0 timestamp / Camera N frame 0 timestamp\n",
    "    1557539924.599788\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Upload PandaSet to Dataloop\n",
    "\n",
    "To upload the files to the dataset, you can use the following scripts to upload the scene folder to the dataset on the Dataloop platform:\n",
    "\n",
    "1. Define the `dataset_id`, `scene_folder` and `remote_path` (on the dataset) to the target dataset for uploading the PandaSet scene.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "# Set the dataset id, scene folder path and remote path\n",
    "dataset_id = \"<dataset id>\"\n",
    "scene_folder = \"C:/data/pandaset/001\"\n",
    "remote_path = \"/001\"\n",
    "\n",
    "dataset = dl.datasets.get(dataset_id=dataset_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Execute the following function to upload the scene to the dataset on the Dataloop platform, ensuring it adheres to the correct structure\n",
    "   (make sure [dtlpy-lidar](https://github.com/dataloop-ai-apps/dtlpy-lidar) is installed).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import shutil\n",
    "\n",
    "from dtlpylidar.utilities import transformations\n",
    "\n",
    "\n",
    "def upload_pandaset_to_dataloop(dataset: dl.Dataset, scene_folder: str, remote_path = \"/\"):\n",
    "    lidar_folder = os.path.join(scene_folder, \"lidar\")\n",
    "    camera_folder = os.path.join(scene_folder, \"camera\")\n",
    "\n",
    "    # Create new folder for the updated scene\n",
    "    updated_scene_folder = os.path.join(scene_folder, \"updated_scene\")\n",
    "    updated_scene_lidar_folder = os.path.join(updated_scene_folder, \"lidar\")\n",
    "    updated_scene_camera_folder = os.path.join(updated_scene_folder, \"camera\")\n",
    "    os.makedirs(updated_scene_lidar_folder, exist_ok=True)\n",
    "    os.makedirs(updated_scene_camera_folder, exist_ok=True)\n",
    "\n",
    "    # Copy the scene folder to the updated scene folder\n",
    "    shutil.copytree(lidar_folder, updated_scene_lidar_folder, dirs_exist_ok=True)\n",
    "    shutil.copytree(camera_folder, updated_scene_camera_folder, dirs_exist_ok=True)\n",
    "\n",
    "    # Open the poses.json file to get the poses data\n",
    "    with open(os.path.join(updated_scene_lidar_folder, \"poses.json\"), 'r') as f:\n",
    "        poses_json_data: list = json.load(f)\n",
    "\n",
    "    # Convert all the PCD files from .pkl to .pcd format and apply the transformations\n",
    "    pkl_filepaths = sorted(pathlib.Path(updated_scene_lidar_folder).rglob('*.pkl'))\n",
    "    for idx, pkl_filepath in enumerate(pkl_filepaths):\n",
    "        with open(pkl_filepath, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        # Convert data to DataFrame if needed\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            df = data\n",
    "        else:\n",
    "            df = pd.DataFrame(data)\n",
    "\n",
    "        # Extract x, y, z coordinates\n",
    "        points = df[['x', 'y', 'z']].to_numpy()\n",
    "\n",
    "        # Create Open3D PointCloud object\n",
    "        point_cloud = o3d.geometry.PointCloud()\n",
    "        point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "        # Apply transformation\n",
    "        position = [\n",
    "            poses_json_data[idx].get(\"position\", dict()).get(\"x\", 0),\n",
    "            poses_json_data[idx].get(\"position\", dict()).get(\"y\", 0),\n",
    "            poses_json_data[idx].get(\"position\", dict()).get(\"z\", 0)\n",
    "        ]\n",
    "        heading = [\n",
    "            poses_json_data[idx].get(\"heading\", dict()).get(\"x\", 0),\n",
    "            poses_json_data[idx].get(\"heading\", dict()).get(\"y\", 0),\n",
    "            poses_json_data[idx].get(\"heading\", dict()).get(\"z\", 0),\n",
    "            poses_json_data[idx].get(\"heading\", dict()).get(\"w\", 0)\n",
    "        ]\n",
    "        rotation = transformations.rotation_matrix_from_quaternion(*heading)\n",
    "        transform = transformations.calc_transform_matrix(rotation=rotation, position=position)\n",
    "        point_cloud.transform(transform)\n",
    "\n",
    "        # Save the PCD data in .pcd format\n",
    "        pcd_filepath = pkl_filepath.with_suffix(\".pcd\")\n",
    "        o3d.io.write_point_cloud(str(pcd_filepath), point_cloud)\n",
    "        os.remove(pkl_filepath)\n",
    "\n",
    "    # Upload the updated scene folder to the dataset\n",
    "    updated_scene_folder = os.path.join(updated_scene_folder, \"*\")\n",
    "    dataset.items.upload(local_path=updated_scene_folder, remote_path=remote_path, overwrite=True)\n",
    "\n",
    "upload_pandaset_to_dataloop(dataset=dataset, scene_folder=scene_folder, remote_path=remote_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Step 2: [Build the Custom Base Parser](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py)\n",
    "\n",
    "Once all files are ready, all the data available in the dataset needs to be merged in order to create the LiDAR video file (`frames.json` file).\n",
    "\n",
    "To do that the `CustomBaseParser` methods needs to be implemented to parse the **Calibration data** from the dataset and build the `frames.json` file.\n",
    "\n",
    "**Notice:** In the next section we will show an example on how to implement the function to support the PandaSet dataset,\n",
    "and explain for what each method is used for.\n",
    "\n",
    "#### Example functions implementation for PandaSet:\n",
    "\n",
    "In this section we will show an example implementation of each method in the `CustomBaseParser` to support parsing the PandaSet dataset `Calibration data` and creating the LiDAR video file.\n",
    "\n",
    "##### - [Download data (Customizable)](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L20)\n",
    "\n",
    "A method to specify the required binaries and JSON annotations that need to be downloaded for use in subsequent parsing functions.\n",
    "\n",
    "##### - [Parse LiDAR data (Customizable)](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L45)\n",
    "\n",
    "A method to parse LiDAR sensor data from the downloaded files\n",
    "(Extrinsic and Timestamps).\n",
    "\n",
    "- `images_and_pcds.LidarPcdData` - A class that encapsulates LiDAR sensor calibration information for PCD files in the 3D scene (per frame).\n",
    "\n",
    "`Notice:` This class later get converted into json formant, and get added to the `frames.json` file.\n",
    "\n",
    "##### - [Parse cameras data (Customizable)](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L93)\n",
    "\n",
    "A method to parse camera data from all available downloaded files\n",
    "(Intrinsic, Extrinsic, Timestamps and Distortion).\n",
    "\n",
    "- `images_and_pcds.LidarCameraData` - A class that stores camera calibration information required to position a camera object in the 3D scene (per frame, per camera).\n",
    "- `images_and_pcds.LidarImageData` - A class extending `images_and_pcds.LidarCameraData` by associating a 2D image with the camera object in the 3D scene (per frame, per camera).\n",
    "\n",
    "`Notice:` This classes later get converted into json formant, and get added to the `frames.json` file.\n",
    "\n",
    "##### - [Build LiDAR scene](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L251)\n",
    "\n",
    "A method to combine the `lidar_data` and `cameras_data` to construct the `frames.json` file, which represents a LiDAR video containing all point cloud and image files seamlessly integrated. Each frame includes the following information:\n",
    "\n",
    "1. `PCD file:` The point cloud data of the 3D scene for the given frame.\n",
    "2. `JPEG/PNG files:` The images of the available cameras for the given frame.\n",
    "\n",
    "This integration ensures that each frame is a complete representation of the scene, combining LiDAR and camera data for synchronized analysis.\n",
    "\n",
    "##### - [Run](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L286)\n",
    "\n",
    "A method to execute the parser to process a dataset containing LiDAR data, using all the above functions, and upload the resulting `frames.json` file.\n",
    "\n",
    "### Step 3: [Run the Custom Base Parser](https://github.com/dataloop-ai-apps/dtlpy-lidar/blob/13dd1b8f1170438c61376ca10446a78580b3914f/dtlpylidar/parsers/custom_base_parser.py#L332)\n",
    "\n",
    "After implementing all the required functions in the `CustomBaseParser`, run the following code snippet to run the parser to create and upload the `frames.json` file to the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}