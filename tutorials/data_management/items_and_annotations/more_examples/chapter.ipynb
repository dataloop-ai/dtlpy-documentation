{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Item and Annotation Examples \ud83c\udf93\n",
    "\n",
    "Welcome to our advanced guide for working with items and annotations! Here you'll find detailed examples and advanced techniques for managing your data in Dataloop.\n",
    "\n",
    "## Advanced Item Examples and Operations \ud83c\udfaf\n",
    "\n",
    "### Advanced Upload Scenarios \ud83d\ude80\n",
    "\n",
    "#### Batch Upload with Metadata and Annotations\n",
    "\n",
    "Want to upload multiple items with their metadata and annotations? Here's how to use a Pandas DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dtlpy as dl\n",
    "\n",
    "# Prepare your data\n",
    "upload_data = [\n",
    "    {\n",
    "        'local_path': r\"E:\\TypesExamples\\000000000064.jpg\",\n",
    "        'local_annotations_path': r\"E:\\TypesExamples\\000000000776.json\",\n",
    "        'remote_path': '/first',\n",
    "        'remote_name': 'f.jpg',\n",
    "        'item_metadata': {'user': {'category': 'first'}}\n",
    "    },\n",
    "    {\n",
    "        'local_path': r\"E:\\TypesExamples\\000000000776.jpg\",\n",
    "        'local_annotations_path': r\"E:\\TypesExamples\\000000000776.json\",\n",
    "        'remote_path': \"/second\",\n",
    "        'remote_name': 's.jpg',\n",
    "        'item_metadata': {'user': {'category': 'second'}}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(upload_data)\n",
    "\n",
    "# Upload with DataFrame\n",
    "dataset = dl.datasets.get(dataset_id='your-dataset-id')\n",
    "items = dataset.items.upload(\n",
    "    local_path=df,\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Working with Different File Types \ud83d\udcc1\n",
    "\n",
    "#### Image Arrays with OpenCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create or load your array\n",
    "img_array = cv2.imread('path/to/image.jpg')\n",
    "# Or create a random array\n",
    "random_array = np.random.rand(100, 100, 3) * 255\n",
    "random_array = random_array.astype(np.uint8)\n",
    "\n",
    "# Upload array (remember to specify remote_name!)\n",
    "item = dataset.items.upload(\n",
    "    local_path=random_array,\n",
    "    remote_name='generated_image.jpg'  # Only .jpg or .png formats are supported!\n",
    ")\n",
    "\n",
    "# Download as array\n",
    "buffer = item.download(\n",
    "    save_locally=False,  # Returns a buffer instead of saving to disk\n",
    "    to_array=True       # Converts the buffer directly to a numpy array\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Important Notes:**\n",
    "- Use `save_locally=False` to get a buffer instead of saving to disk\n",
    "- Use `to_array=True` to get the buffer as a numpy array\n",
    "\n",
    "#### Image Arrays with PIL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load with PIL\n",
    "pil_image = Image.open('path/to/image.jpg')\n",
    "np_array = np.asarray(pil_image)\n",
    "\n",
    "# Upload the array\n",
    "item = dataset.items.upload(\n",
    "    local_path=np_array,\n",
    "    remote_name='pil_image.jpg'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Advanced Metadata Operations \ud83d\udcca\n",
    "\n",
    "#### Complex Metadata Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare complex metadata\n",
    "metadata = {\n",
    "    'user': {\n",
    "        'categories': ['dog', 'cat'],\n",
    "        'attributes': {\n",
    "            'size': 'large',\n",
    "            'colors': ['brown', 'white'],\n",
    "            'age': 3\n",
    "        },\n",
    "        'validation': {\n",
    "            'verified': True,\n",
    "            'verified_by': 'john.doe@example.com',\n",
    "            'verified_date': '2024-01-01'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Upload with complex metadata\n",
    "item = dataset.items.upload(\n",
    "    local_path='path/to/image.jpg',\n",
    "    remote_name='pet.jpg',\n",
    "    item_metadata=metadata\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Batch Metadata Update\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata for multiple items\n",
    "filters = dl.Filters()\n",
    "filters.add(field='dir', values='/pets')\n",
    "\n",
    "update_values = {\n",
    "    'user': {\n",
    "        'batch_processed': True,\n",
    "        'process_date': '2024-01-01'\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset.items.update(\n",
    "    filters=filters,\n",
    "    update_values=update_values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Working with Large Datasets \ud83d\uddc4\ufe0f\n",
    "\n",
    "### Progress Tracking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# Get all items\n",
    "filters = dl.Filters()\n",
    "pages = dataset.items.list(filters=filters)\n",
    "\n",
    "# Create progress bar\n",
    "pbar = tqdm.tqdm(total=pages.items_count)\n",
    "\n",
    "# Process items with progress\n",
    "for item in pages.all():\n",
    "    # Your processing logic here\n",
    "    process_item(item)\n",
    "    pbar.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Parallel Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tqdm\n",
    "\n",
    "def process_item(item):\n",
    "    # Your processing logic here\n",
    "    return True\n",
    "\n",
    "# Create progress bar\n",
    "pbar = tqdm.tqdm(total=pages.items_count)\n",
    "\n",
    "# Process in parallel\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    futures = []\n",
    "    for item in pages.all():\n",
    "        future = executor.submit(process_item, item)\n",
    "        futures.append(future)\n",
    "\n",
    "    # Track progress\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "        pbar.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Advanced Annotation Examples and Operations \ud83c\udfaf\n",
    "\n",
    "Welcome to our advanced guide for working with annotations! Here you'll find detailed examples and techniques for managing complex annotation scenarios in Dataloop.\n",
    "\n",
    "### Working with Different Formats \ud83d\udce6\n",
    "\n",
    "#### Converting from COCO Format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = dl.Converter()\n",
    "converter.upload_local_dataset(\n",
    "    from_format=dl.AnnotationFormat.COCO,\n",
    "    dataset=dataset,\n",
    "    local_items_path=r\"C:/path/to/items\",\n",
    "    # Make sure item names match the COCO JSON file\n",
    "    local_annotations_path=r\"C:/path/to/annotations/file/coco.json\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Working with VTT Format\n",
    "\n",
    "Perfect for video transcription annotations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths\n",
    "local_item_path = r\"/Users/local/path/to/item.png\"\n",
    "local_vtt_path = r\"/Users/local/path/to/subtitles.vtt\"\n",
    "\n",
    "# Upload item\n",
    "item = dataset.items.upload(local_path=local_item_path)\n",
    "\n",
    "# Upload VTT file - wait for item upload to complete\n",
    "builder = item.annotations.builder()\n",
    "builder.from_vtt_file(filepath=local_vtt_path)\n",
    "item.annotations.upload(builder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Video Annotations \ud83c\udfa5\n",
    "\n",
    "#### Adding Time-Based Annotations\n",
    "\n",
    "Here's how to handle annotations that span multiple frames with visibility changes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read annotation data from CSV\n",
    "df = pd.read_csv(r\"C:/file.csv\")\n",
    "\n",
    "# Get video item\n",
    "item = dataset.items.get(item_id=\"video-item-id\")\n",
    "builder = item.annotations.builder()\n",
    "\n",
    "# Add annotations frame by frame\n",
    "for i_row, row in df.iterrows():\n",
    "    builder.add(\n",
    "        annotation_definition=dl.Box(\n",
    "            top=row[\"top\"],\n",
    "            left=row[\"left\"],\n",
    "            bottom=row[\"bottom\"],\n",
    "            right=row[\"right\"],\n",
    "            label=row[\"label\"]\n",
    "        ),\n",
    "        object_visible=row[\"visible\"],  # Handle visibility\n",
    "        object_id=row[\"annotation id\"],  # Track same object across frames\n",
    "        frame_num=row[\"frame\"]\n",
    "    )\n",
    "\n",
    "# Upload all annotations\n",
    "item.annotations.upload(annotations=builder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Audio Annotations \ud83c\udfb5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your audio file\n",
    "item = dataset.items.get(filepath=\"/my_audio.mp4\")\n",
    "\n",
    "# Create annotations using builder\n",
    "builder = item.annotations.builder()\n",
    "builder.add(\n",
    "    annotation_definition=dl.Subtitle(label=\"speech\", text=\"Hello world\"),\n",
    "    start_time=\"00:00:01\",\n",
    "    end_time=\"00:00:05\"\n",
    ")\n",
    "\n",
    "# Add multiple segments\n",
    "builder.add(\n",
    "    annotation_definition=dl.Subtitle(label=\"music\", text=\"Background music\"),\n",
    "    start_time=\"00:00:06\",\n",
    "    end_time=\"00:00:10\"\n",
    ")\n",
    "\n",
    "# Upload annotations\n",
    "item.annotations.upload(builder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Batch Operations \ud83d\udcca\n",
    "\n",
    "#### Copy Annotations Between Items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get source and target items\n",
    "source_item = dataset.items.get(item_id=\"source-id\")\n",
    "target_item = dataset.items.get(item_id=\"target-id\")\n",
    "\n",
    "# Copy all annotations\n",
    "target_item.annotations.upload(source_item.annotations.list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Upload from Local JSON\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations from JSON file\n",
    "annotations = dl.AnnotationCollection.from_json_file(\n",
    "    filepath=r\"/home/project/annotations.json\"\n",
    ")\n",
    "\n",
    "# Upload to item\n",
    "item = dataset.items.get(item_id=\"target-item-id\")\n",
    "item.annotations.upload(annotations=annotations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Downloading Annotations \ud83d\udce5\n",
    "\n",
    "#### Multiple Format Downloads\n",
    "\n",
    "You can download annotations in various formats:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download in multiple formats\n",
    "dataset.download(\n",
    "    local_path=r\"C:/downloads\",\n",
    "    annotation_options=[\n",
    "        dl.VIEW_ANNOTATION_OPTIONS_MASK,\n",
    "        dl.VIEW_ANNOTATION_OPTIONS_JSON,\n",
    "        dl.ViewAnnotationOptions.INSTANCE\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Filtered Downloads\n",
    "\n",
    "Download specific annotations based on filters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for specific items\n",
    "item_filters = dl.Filters(resource=\"items\", field=\"dir\", values=\"/specific_folder\")\n",
    "\n",
    "# Filter for specific annotations\n",
    "annotation_filters = dl.Filters(\n",
    "    resource=dl.FiltersResource.ANNOTATION,\n",
    "    field=\"label\",\n",
    "    values=\"desired_label\"\n",
    ")\n",
    "\n",
    "# Download with filters\n",
    "dataset.download(\n",
    "    local_path=r\"C:/filtered_downloads\",\n",
    "    filters=item_filters,\n",
    "    annotation_filters=annotation_filters,\n",
    "    annotation_options=dl.VIEW_ANNOTATION_OPTIONS_JSON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Format Conversion \ud83d\udd04\n",
    "\n",
    "Want to convert annotations between different formats? We've got you covered! First, grab our handy converter toolkit:\n",
    "\n",
    "1. Install our [dtlpy-converters](https://github.com/dataloop-ai-apps/dtlpy-converters) package \ud83d\udee0\ufe0f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\npip install git+https://github.com/dataloop-ai-apps/dtlpy-converters\n```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Let's start converting! \ud83d\ude80\n",
    "\n",
    "#### Converting TO Dataloop Format \u2b07\ufe0f\n",
    "\n",
    "Here's how to bring your COCO/YOLO/VOC annotations into Dataloop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "from dtlpyconverters.coco import CocoToDataloop\n",
    "from dtlpyconverters.yolo import YoloToDataloop\n",
    "from dtlpyconverters.voc import VocToDataloop\n",
    "\n",
    "\n",
    "# \ud83c\udfaf COCO to Dataloop\n",
    "coco_dataset = dl.datasets.get(dataset_id=\"dataset_id\")\n",
    "converter = CocoToDataloop(\n",
    "    dataset=coco_dataset,\n",
    "    input_items_path=r\"C:/path/to/coco/items\",\n",
    "    # Make sure item filenames match the COCO json! \ud83c\udfaf\n",
    "    input_annotations_path=r\"C:/path/to/coco/items/annotations\",\n",
    "    upload_items=True\n",
    ")\n",
    "converter.convert(\n",
    "    coco_json_filename=\"annotations.json\",\n",
    "    annotation_options=[\n",
    "        dl.AnnotationType.BOX,\n",
    "        dl.AnnotationType.SEGMENTATION\n",
    "    ],\n",
    "    to_polygon=True\n",
    ")\n",
    "\n",
    "# \ud83c\udfaf YOLO to Dataloop\n",
    "yolo_dataset = dl.datasets.get(dataset_id=\"dataset_id\")\n",
    "converter = YoloToDataloop(\n",
    "    dataset=yolo_dataset,\n",
    "    input_items_path=r\"C:/path/to/yolo/items\",\n",
    "    # Make sure item filenames match YOLO txt files! \ud83c\udfaf\n",
    "    input_annotations_path=r\"C:/path/to/yolo/items/annotations\",\n",
    "    upload_items=True,\n",
    "    add_labels_to_recipe=True\n",
    ")\n",
    "converter.convert(\n",
    "    labels_txt_filepath=r\"C:/path/to/yolo/items/labels/labels.txt\"\n",
    ")\n",
    "\n",
    "# \ud83c\udfaf VOC to Dataloop\n",
    "voc_dataset = dl.datasets.get(dataset_id='dataset_id')\n",
    "converter = VocToDataloop(\n",
    "    dataset=voc_dataset,\n",
    "    input_items_path=r\"C:/path/to/voc/items\",\n",
    "    # Make sure item filenames match VOC xml files! \ud83c\udfaf\n",
    "    input_annotations_path=r\"C:/path/to/voc/items/annotations\",\n",
    "    upload_items=True,\n",
    "    add_labels_to_recipe=True\n",
    ")\n",
    "converter.convert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Converting FROM Dataloop Format \u2b06\ufe0f\n",
    "\n",
    "Need to export your Dataloop annotations to other formats? Here's how:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "from dtlpyconverters.coco import DataloopToCoco\n",
    "from dtlpyconverters.yolo import DataloopToYolo\n",
    "from dtlpyconverters.voc import DataloopToVoc\n",
    "\n",
    "# Set up your filters (optional but powerful!) \ud83c\udfaf\n",
    "filters = dl.Filters()\n",
    "# Example: Get items from specific folder\n",
    "filters.add(field=dl.FiltersKnownFields.DIR, values='/dog_name')\n",
    "# Example: Filter for dog annotations\n",
    "filters.add_join(field=dl.FiltersKnownFields.LABEL, values='dog')\n",
    "\n",
    "# \ud83c\udfaf Dataloop to COCO\n",
    "coco_dataset = dl.datasets.get(dataset_id='')\n",
    "converter = DataloopToCoco(\n",
    "    dataset=coco_dataset,\n",
    "    input_annotations_path=r'C:/input_coco',\n",
    "    output_annotations_path=r'C:/output_coco',\n",
    "    download_annotations=True,\n",
    "    output_items_path=None,\n",
    "    download_items=False,\n",
    "    filters=filters,\n",
    "    label_to_id_mapping=None\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# \ud83c\udfaf Dataloop to YOLO\n",
    "yolo_dataset = dl.datasets.get(dataset_id='')\n",
    "converter = DataloopToYolo(\n",
    "    dataset=yolo_dataset,\n",
    "    input_annotations_path=r'C:/input_yolo',\n",
    "    output_annotations_path=r'C:/output_yolo',\n",
    "    download_annotations=True,\n",
    "    output_items_path=None,\n",
    "    download_items=False,\n",
    "    filters=filters\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# \ud83c\udfaf Dataloop to VOC\n",
    "voc_dataset = dl.datasets.get(dataset_id='')\n",
    "converter = DataloopToVoc(\n",
    "    dataset=voc_dataset,\n",
    "    input_annotations_path=r'C:/input_voc',\n",
    "    output_annotations_path=r'C:/output_voc',\n",
    "    download_annotations=True,\n",
    "    output_items_path=None,\n",
    "    download_items=False,\n",
    "    filters=filters\n",
    ")\n",
    "converter.convert()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Pro Tips! \ud83d\udca1**\n",
    "- Always check that your item filenames match the annotation files\n",
    "- Use filters to convert specific subsets of your data\n",
    "- Remember that converter functions are async - use `asyncio.run()`!\n",
    "\n",
    "## Best Practices for Large Scale Operations \ud83c\udfaf\n",
    "\n",
    "### Error Handling  \ud83d\udee1\ufe0f\n",
    "\n",
    "**Error Handling**: Always include error handling for large operations\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "       items = dataset.items.upload(local_path=large_batch)\n",
    "   except dl.exceptions.PlatformException as e:\n",
    "       print(f\"Platform error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Performance Optimization \ud83d\ude80\n",
    "\n",
    "**Batch Processing**: Group operations for better performance\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Batch upload with progress tracking\n",
    "   items_batch = []\n",
    "   with tqdm.tqdm(total=len(file_list)) as pbar:\n",
    "       for i, file_path in enumerate(file_list):\n",
    "           items_batch.append({\n",
    "               'local_path': file_path,\n",
    "               'remote_name': f'processed_{i}.jpg'\n",
    "           })\n",
    "           if len(items_batch) == 100:  # Process in batches of 100\n",
    "               dataset.items.upload(local_path=pd.DataFrame(items_batch))\n",
    "               items_batch = []\n",
    "               pbar.update(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Progress Tracking**: Use progress bars for long operations\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track progress for any operation\n",
    "   def process_with_progress(items):\n",
    "       with tqdm.tqdm(total=len(items)) as pbar:\n",
    "           for item in items:\n",
    "               # Your processing logic here\n",
    "               process_item(item)\n",
    "               pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Parallel Processing \ud83d\udd04\n",
    "\n",
    "7. **Multi-threading**: Use parallel processing for large datasets\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "   def process_in_parallel(items, max_workers=32):\n",
    "       with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "           futures = []\n",
    "           for item in items:\n",
    "               future = executor.submit(process_item, item)\n",
    "               futures.append(future)\n",
    "\n",
    "           # Wait for all tasks to complete\n",
    "           for future in futures:\n",
    "               future.result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Logging \ud83d\udcdd\n",
    "\n",
    "**Logging**: Maintain detailed logs for debugging\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process_with_logging(item):\n",
    "        try:\n",
    "            logger.info(f\"Processing item: {item.id}\")\n",
    "            # Your processing logic here\n",
    "            logger.info(f\"Successfully processed item: {item.id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing item {item.id}: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need More Help? \ud83e\udd14\n",
    "\n",
    "- Check out our [Python SDK Documentation](https://sdk-docs.dataloop.ai/en/latest/entities.html)\n",
    "- Visit our [Community Forum](https://dataloop.ai/community)\n",
    "- Explore our [Tutorials](https://docs.dataloop.ai/tutorials)\n",
    "\n",
    "Happy coding! \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}