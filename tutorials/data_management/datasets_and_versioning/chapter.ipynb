{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Datasets and Versioning in Dataloop \ud83d\uddc4\ufe0f\n",
    "\n",
    "Welcome to your guide to managing datasets in Dataloop! Whether you're organizing your data, connecting to cloud storage, or managing versions, we've got you covered. Let's dive in!\n",
    "\n",
    "## Understanding Datasets \ud83d\udcda\n",
    "\n",
    "Think of datasets as smart buckets in Dataloop that can hold any type of data item. The cool part? Your data can live anywhere - either on Dataloop's storage or your favorite cloud provider. There's no limit to how many datasets you can have in a project, making it perfect for versioning and experimentation.\n",
    "\n",
    "## Creating and Managing Datasets \ud83d\udee0\ufe0f\n",
    "\n",
    "### Creating Your First Dataset \u2728\n",
    "\n",
    "Let's start with the basics - creating a dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'My Amazing Dataset'\n",
    "dataset = project.datasets.create(dataset_name=dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Creating a Cloud-Connected Dataset \u2601\ufe0f\n",
    "\n",
    "If you didn't connect your cloud storage to Dataloop yet, you can do it by following the instructions in one of the following tutorials:\n",
    "\n",
    "- [Amazon Web Services (S3)](/tutorials/data_management/external_storage_drivers/aws_s3/chapter.md)\n",
    "- [Microsoft Azure Blob Storage](/tutorials/data_management/external_storage_drivers/azure_blob/chapter.md)\n",
    "- [Google Cloud Storage](/tutorials/data_management/external_storage_drivers/gcs/chapter.md)\n",
    "\n",
    "Already have your data in the cloud? No problem! If you've set up your cloud integration and driver, you can create a dataset that connects directly to your cloud storage:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'my-project-name'\n",
    "driver = 'my_driver_name'\n",
    "dataset_name = 'my_dataset_name'\n",
    "\n",
    "# Get your project\n",
    "project = dl.projects.get(project_name=project_name)\n",
    "\n",
    "# See available drivers\n",
    "project.drivers.list().print()\n",
    "\n",
    "# Create dataset with cloud driver\n",
    "dataset = project.datasets.create(\n",
    "    driver=driver,\n",
    "    dataset_name=dataset_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Finding Your Datasets \ud83d\udd0d\n",
    "\n",
    "Need to find specific datasets? Use our powerful DQL (Dataloop Query Language) to filter and search:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up filters\n",
    "filters = dl.Filters(resource=dl.FiltersResource.DATASET)\n",
    "filters.add(field='name', values='my dataset')\n",
    "\n",
    "# List matching datasets\n",
    "datasets = project.datasets.list(filters=filters)\n",
    "datasets.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Organizing with Directories \ud83d\udcc2\n",
    "\n",
    "Keep your files organized by creating directories based on any context you need - upload time, batch, source, etc:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/directory/name'\n",
    "dataset.items.make_dir(directory=directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Deep Copying Between Datasets \ud83d\udccb\n",
    "\n",
    "Need to copy data between datasets? Here's how to do it while preserving your folder structure and annotations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination details\n",
    "src_folder = '/source_folder'\n",
    "dst_folder = '/destination_folder'\n",
    "src_project_name = 'source_project_name'\n",
    "src_dataset_name = 'source_dataset_name'\n",
    "dst_project_name = 'destination_project_name'\n",
    "dst_dataset_name = 'destination_dataset_name'\n",
    "\n",
    "# Copy settings\n",
    "copy_annotations = True\n",
    "flat_copy = False  # Keep folder structure (False) or copy all files to root (True)\n",
    "\n",
    "# Get source dataset\n",
    "project = dl.projects.get(project_name=src_project_name)\n",
    "dataset_from = project.datasets.get(dataset_name=src_dataset_name)\n",
    "\n",
    "# Set up filters for source folder\n",
    "filters = dl.Filters()\n",
    "filters.add(field='filename', values=src_folder.rstrip('/') + '/**')\n",
    "\n",
    "# Get all items to copy\n",
    "pages = dataset_from.items.list(filters=filters)\n",
    "\n",
    "# Get destination dataset\n",
    "project = dl.projects.get(project_name=dst_project_name)\n",
    "dataset_to = project.datasets.get(dataset_name=dst_dataset_name)\n",
    "\n",
    "# Copy files and annotations\n",
    "for page in pages:\n",
    "    for item in page:\n",
    "        # Download without saving to disk\n",
    "        buffer = item.download(save_locally=False)\n",
    "        \n",
    "        # Set filename based on copy type\n",
    "        if flat_copy:\n",
    "            buffer.name = item.name\n",
    "        else:\n",
    "            buffer.name = item.filename[len(src_folder) + 1:]\n",
    "            \n",
    "        # Upload to destination\n",
    "        print(f\"Adding {buffer.name} to {dst_folder}\")\n",
    "        new_item = dataset_to.items.upload(\n",
    "            local_path=buffer,\n",
    "            remote_path=dst_folder\n",
    "        )\n",
    "        \n",
    "        if not isinstance(new_item, dl.Item):\n",
    "            print(f'Failed to upload {buffer.name} to {dst_folder}')\n",
    "            continue\n",
    "            \n",
    "        print(f\"Successfully uploaded {new_item.filename}\")\n",
    "        \n",
    "        # Copy annotations if requested\n",
    "        if copy_annotations:\n",
    "            new_item.annotations.upload(item.annotations.list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Versioning: Your Time Machine \ud83d\udd70\ufe0f\n",
    "\n",
    "Dataloop's powerful versioning system helps you manage your data like a pro. Here's what you can do:\n",
    "\n",
    "- Create golden training sets \ud83c\udfc6\n",
    "- Snapshot datasets for reproducibility \ud83d\udcf8\n",
    "- Experiment with different subsets \ud83e\uddea\n",
    "- Manage tasks and assignments \ud83d\udccb\n",
    "- Roll back to previous versions if needed \u23ee\ufe0f\n",
    "\n",
    "### Cloning Datasets \ud83d\udc11\n",
    "\n",
    "Want a copy of your dataset? Cloning creates a new dataset that references the original files (no duplicate storage needed):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'my-dataset-id'\n",
    "clone_name = 'clone-name'\n",
    "\n",
    "# Get original dataset\n",
    "dataset = project.datasets.get(dataset_id=dataset_id)\n",
    "\n",
    "# Create clone with specific settings\n",
    "dataset_clone = dataset.clone(\n",
    "    clone_name=clone_name,\n",
    "    filters=dl.Filters(field='dir', values='/only-this-folder'),\n",
    "    with_items_annotations=True,\n",
    "    with_metadata=True,\n",
    "    with_task_annotations_status=True,\n",
    "    target_directory='/clone-folder'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Merging Datasets \ud83e\udd1d\n",
    "\n",
    "Need to combine datasets? Here's what happens when you merge:\n",
    "\n",
    "* **Cloned Datasets**: Items, annotations, and metadata merge smoothly - you'll see all annotations on the same items\n",
    "* **Different Datasets (non-clones)**: Similar items might appear multiple times\n",
    "* **Different Recipes**: You'll need to match recipes before merging (use 'Switch recipe' in dataset options)\n",
    "\n",
    "Here's how to merge datasets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = [\"dataset-1-id\", \"dataset-2-id\"]\n",
    "project_ids = [\"dataset-1-project-id\", \"dataset-2-project-id\"]\n",
    "merge_name = 'my_dataset-merge'\n",
    "\n",
    "# Merge the datasets\n",
    "dataset_merge = dl.datasets.merge(\n",
    "    merge_name=merge_name,\n",
    "    project_ids=project_ids,\n",
    "    dataset_ids=dataset_ids,\n",
    "    with_items_annotations=True,\n",
    "    with_metadata=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Collections: Your Data's Best Friend \ud83e\udd1d\n",
    "\n",
    "Think of Collections as smart tags on steroids! They're your secret weapon for organizing data like a pro. Whether you're juggling labeling tasks, managing massive datasets, or getting your data ready for model training - Collections have got your back! \n",
    "\n",
    "Want to learn all the cool tricks? Check out our [Dataloop documentation](https://docs.dataloop.ai/docs/organize-your-data#collections) for the full scoop! \ud83c\udf93\n",
    "\n",
    "### Become a Collections Master \ud83c\udfaf\n",
    "\n",
    "Ready to become a Collections wizard? The Dataloop SDK gives you superpowers to create, update, delete, and manage collections at both dataset and item levels. Let's break it down!\n",
    "\n",
    "**Dataset Level Magic Tricks \u2728**\n",
    "\n",
    "These are your dataset-wide spells for managing collections. Think of them as your high-level organization tools:\n",
    "\n",
    "1. Create a new collection (max 10 per dataset - choose wisely!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.create(name: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Give your collection a fancy new name (keep it unique!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.update(collection_id: str, new_name: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. Make a collection disappear (poof! \ud83c\udfa9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.delete(collection_id: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "4. Clone a collection (it's like ctrl+c, ctrl+v, but cooler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.clone(collection_id: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "5. See all your collections in one place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.list_all_collections()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "6. Find the lone wolves (items not in any collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.collections.list_unassigned_items()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Item Level Ninja Moves \ud83e\udd77**\n",
    "\n",
    "These methods are your precision tools - perfect for when you need that surgical accuracy:\n",
    "\n",
    "1. Add an item to a collection (like adding a card to your favorite deck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.assign_collection(item_id: str, collection_name: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. Remove an item from a collection (no hard feelings!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.unassign_collection(item_id: str, collection_id: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. Check which collections an item belongs to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.list_collections(item_id: str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "** Bulk Operations \ud83e\udd16**\n",
    "\n",
    "Assign and unassign items to collections in bulk, using dl.Filters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dl.Filters()\n",
    "filters.add(field='id', values=['<item_id>'], operator=dl.FiltersOperations.IN)\n",
    "dataset.collections.assign(collections=['my_collection'], filters=filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Or everything in a directory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dl.Filters()\n",
    "filters.add(field='dir', values='/my_directory')\n",
    "dataset.collections.assign(collections=['my_collection'], filters=filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Same for unassigning:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dl.Filters()\n",
    "filters.add(field='id', values=['<item_id>'], operator=dl.FiltersOperations.IN)\n",
    "dataset.collections.unassign(collections=['my_collection'], filters=filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Show Time! \ud83c\udfac Real-World Examples**\n",
    "\n",
    "Let's see these powers in action:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "project = dl.projects.get(project_name='<project_name>')\n",
    "dataset = project.datasets.get(dataset_id='<dataset_id>')\n",
    "\n",
    "# Get a VIP list of all collections\n",
    "dataset.collections.list_all_collections()\n",
    "\n",
    "# Create a shiny new collection\n",
    "dataset.collections.create(collection='my_awesome_collection')\n",
    "\n",
    "# Clone it (because good things deserve doubles!)\n",
    "dataset.collections.clone(collection_name='my_awesome_collection_2')\n",
    "\n",
    "# Oops, changed our mind - let's delete one\n",
    "dataset.collections.delete(collection_name='my_awesome_collection_2')\n",
    "\n",
    "# Give it a cooler name\n",
    "dataset.collections.update(collection_name='my_super_awesome_collection')\n",
    "\n",
    "# Find the items playing hide and seek\n",
    "dataset.collections.list_unassigned_items()\n",
    "\n",
    "# Add an item to our cool collection\n",
    "dataset.items.get(item_id='<item_id>').assign_collection(collections=['my_super_awesome_collection'])\n",
    "\n",
    "# Let an item go free\n",
    "dataset.items.get(item_id='<item_id>').unassign_collection(collections=['my_super_awesome_collection'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ML Subsets: Your Dataset's Secret Sauce \ud83c\udf1f\n",
    "\n",
    "Welcome to ML Subsets - your dataset's personal organizer for machine learning! It's like having a smart assistant that helps you split your data into perfect training, validation, and test portions. No more manual sorting - we've got you covered! \n",
    "\n",
    "Want to become an ML Subsets guru? Check out our [detailed guide](https://docs.dataloop.ai/docs/organize-your-data#ml-subsets)! \ud83d\udcda\n",
    "\n",
    "### ML Subsets: The Fun Way! \ud83c\udfae\n",
    "\n",
    "Let's see how to slice and dice your dataset with style:\n",
    "\n",
    "**1. The Perfect Split (60-20-20 Style) \ud83c\udfaf**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "project = dl.projects.get(project_name='<project_name>')\n",
    "dataset = project.datasets.get(dataset_id='<dataset_id>')\n",
    "\n",
    "filters = dl.Filters(field='type', values='file')\n",
    "dataset.split_ml_subsets(\n",
    "    items_query=filters,\n",
    "    percentages={'train': 60, 'validation': 20, 'test': 20}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Like a chef perfectly portioning ingredients! \ud83d\udc68\u200d\ud83c\udf73\n",
    "* Your files get VIP treatment in train (60%), validation (20%), and test (20%) clubs\n",
    "* Perfectly balanced, as all things should be! \n",
    "\n",
    "**2. Send an Item to Training Camp \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dl.Filters()\n",
    "filters.add(field='id', values=['<item_id>'], operator=dl.FiltersOperations.IN)\n",
    "dataset.assign_subset_to_items(subset='train', items_query=filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Hand-pick items for special training\n",
    "* Like choosing your star player for the big game!\n",
    "\n",
    "**3. Give an Item a Break \ud83c\udfd6\ufe0f**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = dl.Filters()\n",
    "filters.add(field='id', values=['<item_id>'], operator=dl.FiltersOperations.IN)\n",
    "dataset.remove_subset_from_items(items_query=filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Sometimes items need a vacation from their subset\n",
    "* No hard feelings - they can always come back later!\n",
    "\n",
    "**4. Find the Free Agents \ud83d\udd0d**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_items_missing_ml_subset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Spot items that haven't joined a team yet\n",
    "* Perfect for making sure no data is left behind!\n",
    "\n",
    "## Need More Help? \ud83e\udd14\n",
    "\n",
    "Check out our [comprehensive documentation](https://docs.dataloop.ai/docs/welcome) for more details on dataset management and versioning.\n",
    "\n",
    "Happy data managing! \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}