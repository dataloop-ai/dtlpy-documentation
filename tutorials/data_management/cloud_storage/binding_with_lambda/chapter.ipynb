{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Create an AWS Lambda to Continuously Sync a Bucket with Dataloop's Dataset  \n", "  \n", "If you want to catch events from the AWS bucket and update the Dataloop  Dataset you need to set up a Lambda.  \n", "The Lambda will catch the AWS bucket events and will reflect them into the Dataloop Platform.  \n", "  \n", "We created the environment zip file with our SDK for python3.8. For other version or more package try creating you own layer.  \n", "(We used (this)[https://www.geeksforgeeks.org/how-to-install-python-packages-for-aws-lambda-layers] tutorial and the python:3.8 docker image)  \n", "  \n", "# Create the Lambda  \n", "  \n", "Create a new Lambda and copy the following code:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import os\n", "import urllib.parse\n", "", "# Set dataloop path to tmp (to read/write from the lambda)\n", "os.environ[\"DATALOOP_PATH\"] = \"/tmp\"\n", "import dtlpy as dl\n", "", "DATASET_ID = ''\n", "DTLPY_USERNAME = ''\n", "DTLPY_PASSWORD = ''\n", "", "def lambda_handler(event, context):\n", "    dl.login_m2m(email=DTLPY_USERNAME, password=DTLPY_PASSWORD)\n", "    dataset = dl.datasets.get(dataset_id=DATASET_ID,\n", "                              fetch=False  # to avoid GET the dataset each time\n", "                              )\n", "", "    for record in event['Records']:\n", "        # Get the bucket name\n", "        bucket = record['s3']['bucket']['name']\n", "", "        # Get the file name\n", "        filename = urllib.parse.unquote_plus(record['s3']['object']['key'], encoding='utf-8')\n", "", "        if 'ObjectRemoved' in record['eventName']:\n", "            # On delete event - delete the item from Dataloop\n", "            try:\n", "                dtlpy_filename = '/' + filename\n", "                filters = dl.Filters(field='filename', values=dtlpy_filename)\n", "                dataset.items.delete(filters=filters)\n", "            except Exception as e:\n", "                raise e\n", "", "        elif 'ObjectCreated' in record['eventName']:\n", "            # On create event - add a new item to the Dataset\n", "            try:\n", "                # upload the file\n", "                path = 'external://' + filename\n", "                # dataset.items.upload(local_path=path, overwrite=True) # if overwrite is required\n", "                dataset.items.upload(local_path=path)\n", "            except Exception as e:\n", "                raise e\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have create a Layer with the Dataloop SDK ready.  \n", "After creating the lambda, select the \"Add Layer\" and upload the zip file downloaded from (here)[https://storage.googleapis.com/dtlpy/aws-python3.8-lambda-layer/layer.zip]  \n", "  \n", "Go to the bucket you using, and create he event:  \n", "1. Go to Properties \u2192 Event notifications \u2192 Create event notification  \n", "1. Choose a name for the Event  \n", "1. For Event types choose: All object create events, All object delete events  \n", "1. Destination - Lambda function \u2192 Choose from your Lambda functions \u2192 choose the function you build \u2192 SAVE  \n", "  \n", "Deploy and you're good to go!  \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}