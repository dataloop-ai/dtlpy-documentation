{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Pagination  \n", "### Pages  \n", "We use pages instead of a list when we have an object that contains a lot of information.  \n", "  \n", "The page object divides a large list into pages (with a default of 1000 items) in order to save time when going over the items.  \n", "  \n", "It is the same as we display it in the annotation platform, see example <a href=\"https://dataloop.ai/docs/organize-dataset#datastructuredisplay\" target=\"_blank\">here</a>.  \n", "  \n", "You can redefine the number of items on a page with the page_size attribute.  \n", "When we go over the items we use nested loops to first go to the pages and then go over the items for each page.  \n", "  \n", "### Iterator of Items  \n", "You can create a generator of items with different filters.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "# Get the project    \n", "project = dl.projects.get(project_name='project_name')\n", "# Get the dataset\n", "dataset = project.datasets.get(dataset_name='dataset_name')\n", "# Get items in pages (1000 item per page)\n", "filters = dl.Filters()\n", "filters.add(field='filename', values='/your/file/path.mimetype')\n", "pages = dataset.items.list(filters=filters)\n", "# Count the items\n", "print('Number of items in dataset: {}'.format(pages.items_count))\n", "# Go over all item and print the properties\n", "for i_page, page in enumerate(pages):\n", "    print('{} items in page {}'.format(len(page), i_page))\n", "    for item in page:\n", "        item.print()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A Page entity iterator also allows reverse iteration for cases in which you want to change items during the iteration:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Go over all item and print the properties\n", "for i_page, page in enumerate(reversed(pages)):\n", "    print('{} items in page {}'.format(len(page), i_page))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you want to iterate through all items within your filter, you can also do so without going through them page by page:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["for item in pages.all():\n", "    print(item.name)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you are planning to do some process on each item, it's faster to use multi-threads (or multi-process) for parallel computation.  \n", "The following uses ThreadPoolExecutor with 32 workers to process parallel batches of 32 items:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["from concurrent.futures import ThreadPoolExecutor\n", "def single_item(item):\n", "    # do some work on item\n", "    print(item.filename)\n", "    return True\n", "", "with ThreadPoolExecutor(max_workers=32) as executor:\n", "    executor.map(single_item, pages.all())\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lets compare the runtime to see that now the process is faster:  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["from concurrent.futures import ThreadPoolExecutor\n", "import time\n", "", "tic = time.time()\n", "for item in pages.all():\n", "    # do stuff on item\n", "    time.sleep(1)\n", "print('One by one took {:.2f}[s]'.format(time.time() - tic))\n", "", "def single_item(item):\n", "    # do stuff on item\n", "    time.sleep(1)\n", "    return True\n", "", "tic = time.time()\n", "with ThreadPoolExecutor(max_workers=32) as executor:\n", "    executor.map(single_item, pages.all())\n", "print('Using threads took {:.2f}[s]'.format(time.time() - tic))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Visualizing the progress with tqdm progress bar:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import tqdm\n", "pbar = tqdm.tqdm(total=pages.items_count)\n", "", "def single_item(item):\n", "    # do stuff on item\n", "    time.sleep(1)\n", "    pbar.update()\n", "    return True\n", "", "with ThreadPoolExecutor(max_workers=32) as executor:\n", "    executor.map(single_item, pages.all())\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Set page_size  \n", "The following example sets the page_size to 50:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["# Create filters instance\n", "filters = dl.Filters()\n", "# Get filtered item list in a page object, where the starting page is 1\n", "pages = dataset.items.list(filters=filters, page_offset=1, page_size=50)\n", "# Count the items\n", "print('Number of filtered items in dataset: {}'.format(pages.items_count))\n", "# Print items from page 1\n", "print('Length of first page: {}'.format(len(pages.items)))\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}