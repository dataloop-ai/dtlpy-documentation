{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting Dataloop with Google Cloud Storage \ud83c\udf09\n",
    "\n",
    "Ever wondered how to connect your Google Cloud Storage (GCS) seamlessly with Dataloop? You're in the right place! Let's walk through the process step by step, from setting up your integration to automating your data sync.\n",
    "\n",
    "## Choose Your Integration Adventure! \ud83c\udfae\n",
    "\n",
    "Before we dive into the technical stuff, let's pick the right integration path for your needs. We've got several exciting options:\n",
    "\n",
    "### Cross Project Integration: The Team Player \ud83e\udd1d\n",
    "\n",
    "Want to connect across different GCP projects? Here's your game plan:\n",
    "\n",
    "1. \ud83e\udea3 Create a Cloud Storage Bucket in your GCP kingdom\n",
    "2. \ud83d\udc6e\u200d\u2642\ufe0f Set up an IAM policy (your security badge)\n",
    "3. \ud83d\udd17 Create the integration and get your VIP pass (IAM user) from Dataloop\n",
    "\n",
    "Ready to become a cross-project master? Check out our [detailed guide](https://docs.dataloop.ai/docs/cross-project-integration)!\n",
    "\n",
    "### Private Key Integration: The Secret Agent \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\n",
    "\n",
    "Need that extra layer of security? Here's your mission, should you choose to accept it:\n",
    "\n",
    "1. \ud83e\udea3 Create a Cloud Storage Bucket (your secure vault)\n",
    "2. \ud83d\udc51 Create an IAM role (your security clearance)\n",
    "3. \ud83e\udd16 Create a Service Account (your trusted agent)\n",
    "4. \ud83d\udd11 Generate a Private Key (your secret decoder ring)\n",
    "\n",
    "For the classified details, visit our [secret handbook](https://docs.dataloop.ai/docs/private-key-integration)!\n",
    "\n",
    "### Google Artifacts Registry Integration: The Modern Curator \ud83d\udce6\n",
    "\n",
    "Want to manage your container artifacts like a pro? Here's the blueprint:\n",
    "\n",
    "1. \ud83c\udfd7\ufe0f Create and Configure your GCP Google Artifacts Registry\n",
    "2. \ud83e\udd1d Shake hands with Dataloop (integrate the platforms)\n",
    "\n",
    "Discover all the artifacts secrets in our [curator's guide](https://docs.dataloop.ai/docs/google-artifacts-registry)!\n",
    "\n",
    "### Google Container Registry Integration: The Classic Container Master \ud83d\udc33\n",
    "\n",
    "Prefer the classic container registry? We've got you covered:\n",
    "\n",
    "1. \ud83c\udfed Create and Configure your GCP Google Container Registry\n",
    "2. \ud83d\udd04 Connect it with Dataloop (smooth sailing ahead!)\n",
    "\n",
    "Master the container arts with our [comprehensive guide](https://docs.dataloop.ai/docs/google-container-registry)!\n",
    "\n",
    "## Step 1: Setting Up GCP Integration \ud83d\udd17\n",
    "\n",
    "Before we can start moving data around, we need to establish a secure connection between Dataloop and Google Cloud Platform. Let's set up the integration:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import json\n",
    "\n",
    "if dl.token_expired():\n",
    "    dl.login()\n",
    "organization = dl.organizations.get(organization_name=org_name)\n",
    "\n",
    "# Read your GCP service account key JSON file\n",
    "with open(r\"C:\\gcsfile.json\", 'r') as f:\n",
    "    gcs_json = json.load(f)\n",
    "gcs_to_string = json.dumps(gcs_json)\n",
    "\n",
    "# Create the integration\n",
    "integration = organization.integrations.create(\n",
    "    name='gcs-integration',\n",
    "    integrations_type=dl.ExternalStorage.GCS,\n",
    "    options={\n",
    "        'key': '',\n",
    "        'secret': '',\n",
    "        'content': gcs_to_string\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To learn more about setting up integrations and required permissions, check out our [Dataloop documentation](https://docs.dataloop.ai/docs/storage-gcp).\n",
    "\n",
    "## Step 2: Creating Your Storage Driver \ud83c\udfaf\n",
    "\n",
    "Now that we have our integration set up, let's create a storage driver - think of it as your personal data concierge that connects your specific GCS bucket to Dataloop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "project = dl.projects.get('<project_name>')\n",
    "driver = project.drivers.create(\n",
    "    name='driver_name',\n",
    "    driver_type=dl.ExternalStorage.GCS,\n",
    "    integration_id=integration.id,\n",
    "    bucket_name='<bucket_name>',\n",
    "    allow_external_delete=True,\n",
    "    path=\"\"  # Optional: specify a path within the bucket\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Once your driver is ready, you can create a dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = project.datasets.create(dataset_name=dataset_name, driver=driver)\n",
    "# Sync the dataset\n",
    "dataset.sync()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 3: Syncing Your Data \ud83d\udd04\n",
    "\n",
    "### Manual Sync \u26a1\n",
    "\n",
    "Need to sync a specific item? You can use the same syntax as with other cloud providers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "dl.login()\n",
    "# Use the full item path in GCS context\n",
    "item_path = 'external://' + '<Your_item_full_name>'\n",
    "# Optional: specify a destination folder\n",
    "remote_path = '/Test_Folder'\n",
    "dataset = dl.datasets.get(dataset_id='your dataset id')\n",
    "dataset.items.upload(local_path=item_path, remote_path=remote_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Automatic Sync with Cloud Functions \u2728\n",
    "\n",
    "Want your Dataloop dataset to automatically stay in sync with your GCS bucket? Let's set up Google Cloud Functions!\n",
    "\n",
    "#### Prerequisites \ud83d\udccb\n",
    "\n",
    "1. A Google Cloud Platform (GCP) account ([Get started here](https://cloud.google.com/docs/get-started))\n",
    "2. A GCS bucket created and ready to use\n",
    "3. Basic familiarity with [Google Cloud Functions](https://cloud.google.com/functions) (optional)\n",
    "\n",
    "#### Setting Up Your Cloud Functions \ud83d\udee0\ufe0f\n",
    "\n",
    "You'll need to create two functions: one for file creation/updates and another for deletions.\n",
    "\n",
    "![add_layer](../../../../../assets/bind_gcs/create_function.png)  \n",
    "![add_layer](../../../../../assets/bind_gcs/settings.png)  \n",
    "\n",
    "##### Function for Create/Update Events\n",
    "\n",
    "1. Create Your Function:\n",
    "   * Go to Cloud Functions and click \"Create Function\"\n",
    "   * Basic settings:\n",
    "     - Environment: 1st gen\n",
    "     - Function name: Choose a name\n",
    "     - Region: Select your preferred region\n",
    "\n",
    "2. Configure the Trigger:\n",
    "   * Trigger type: Cloud Storage\n",
    "   * Event type: On (finalizing/creating) file in the selected bucket\n",
    "   * Bucket: Choose your target bucket\n",
    "\n",
    "3. Configure Runtime Settings:\n",
    "   * Runtime: Python 3.7\n",
    "   * Entry point: create_gcs\n",
    "   * Add environment variables:\n",
    "     - `DATASET_ID`\n",
    "     - `DTLPY_USERNAME`\n",
    "     - `DTLPY_PASSWORD`\n",
    "\n",
    "4. Add Code:\n",
    "   * Add to requirements.txt:\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n     dtlpy\n     ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   * Add this code to main.py:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATALOOP_PATH\"] = \"/tmp\"\n",
    "import dtlpy as dl\n",
    "\n",
    "dataset_id = os.environ.get('DATASET_ID')\n",
    "dtlpy_username = os.environ.get('DTLPY_USERNAME')\n",
    "dtlpy_password = os.environ.get('DTLPY_PASSWORD')\n",
    "\n",
    "def create_gcs(event, context):\n",
    "    \"\"\"Triggered by a change to a Cloud Storage bucket.\n",
    "    Args:\n",
    "         event (dict): Event payload.\n",
    "         context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    file = event\n",
    "    dl.login_m2m(email=dtlpy_username, password=dtlpy_password)\n",
    "    dataset = dl.datasets.get(\n",
    "        dataset_id=dataset_id,\n",
    "        fetch=False  # to avoid GET the dataset each time\n",
    "    )\n",
    "    driver_path = dl.drivers.get(driver_id=dataset.driver).path\n",
    "    remote_path = None\n",
    "    if driver_path == '/':\n",
    "        driver_path = None\n",
    "    if driver_path is not None and driver_path not in file['name']:\n",
    "        return\n",
    "    if driver_path:\n",
    "        remote_path = file['name'].replace(driver_path, '')\n",
    "    file_name = 'external://' + file['name']\n",
    "    dataset.items.upload(local_path=file_name, remote_path=remote_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Function for Delete Events\n",
    "\n",
    "Create a second function following the same steps, but with these differences:\n",
    "* Event type: On (deleting) file in the selected bucket\n",
    "* Entry point: delete_gcs\n",
    "* Use this code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DATALOOP_PATH\"] = \"/tmp\"\n",
    "import dtlpy as dl\n",
    "\n",
    "dataset_id = os.environ.get('DATASET_ID')\n",
    "dtlpy_username = os.environ.get('DTLPY_USERNAME')\n",
    "dtlpy_password = os.environ.get('DTLPY_PASSWORD')\n",
    "\n",
    "def delete_gcs(event, context):\n",
    "    \"\"\"Triggered by a change to a Cloud Storage bucket.\n",
    "    Args:\n",
    "         event (dict): Event payload.\n",
    "         context (google.cloud.functions.Context): Metadata for the event.\n",
    "    \"\"\"\n",
    "    file = event\n",
    "    dl.login_m2m(email=dtlpy_username, password=dtlpy_password)\n",
    "    dataset = dl.datasets.get(\n",
    "        dataset_id=dataset_id,\n",
    "        fetch=False  # to avoid GET the dataset each time\n",
    "    )\n",
    "    driver_path = dl.drivers.get(driver_id=dataset.driver).path\n",
    "    if driver_path == '/':\n",
    "        driver_path = None\n",
    "    if driver_path is not None and driver_path not in file['name']:\n",
    "        return\n",
    "    if driver_path:\n",
    "        remote_path = file['name'].replace(driver_path, '')\n",
    "    else:\n",
    "        remote_path = file['name']\n",
    "    dataset.items.delete(filename=remote_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Need the bot credentials? Here's how to get them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "dl.login()\n",
    "project = dl.projects.get(project_name='project name')\n",
    "bot = project.bots.create(name='serviceAccount', return_credentials=True)\n",
    "print('\ud83e\udd16 Bot username:', bot.id)\n",
    "print('\ud83d\udd11 Bot password:', bot.password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need More Help? \ud83e\udd14\n",
    "\n",
    "For detailed GCP integration setup, check out our [comprehensive documentation](https://docs.dataloop.ai/docs/storage-gcp).\n",
    "\n",
    "Happy data syncing! \ud83d\ude80\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}