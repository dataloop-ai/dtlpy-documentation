{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Model Metrics: Your AI's Report Card \ud83d\udcca\n",
    "\n",
    "Want to keep track of how well your model is performing? Let's explore how to log and visualize your model's metrics in Dataloop! \n",
    "\n",
    "## Getting Started \ud83d\ude80\n",
    "\n",
    "> \ud83d\udca1 **Pro Tip**: All models from our marketplace automatically track metrics. This guide is for custom models!\n",
    "\n",
    "### What You'll Need \ud83d\udccb\n",
    "- A Dataloop Package Kit (`dl.DPK`)\n",
    "- A Model with a dataset ID (`dl.Model`)\n",
    "\n",
    "## Setting Up Your Metrics Dashboard \ud83c\udfaf\n",
    "\n",
    "First, let's create our tracking environment:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Connect to your project\n",
    "project = dl.projects.get(project_name='your-awesome-project')\n",
    "\n",
    "# Create a package for your model\n",
    "dpk = project.dpks.publish()\n",
    "\n",
    "# Install the DPK\n",
    "project.apps.install(dpk=dpk)\n",
    "\n",
    "# Create a model to track\n",
    "model = dpk.models.create(\n",
    "    model_name='My Tracked Model',\n",
    "    description='A model with awesome metrics tracking',\n",
    "    dataset_id='your-dataset-id',\n",
    "    labels=[]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Logging Your Metrics \ud83d\udcc8\n",
    "\n",
    "Let's add some training metrics! Here's a simple example tracking training progress:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate training metrics\n",
    "epochs = np.linspace(0, 9, 10)\n",
    "accuracies = np.array([0.82, 0.85, 0.87, 0.89, 0.90, 0.91, 0.92, 0.93, 0.94, 0.95])\n",
    "losses = np.array([0.5, 0.4, 0.35, 0.3, 0.25, 0.23, 0.2, 0.18, 0.15, 0.13])\n",
    "\n",
    "# Log accuracy metrics\n",
    "print(\"\ud83d\udcca Logging accuracy metrics...\")\n",
    "for epoch, accuracy in zip(epochs, accuracies):\n",
    "    model.metrics.create(\n",
    "        samples=dl.PlotSample(\n",
    "            figure='Training Metrics',\n",
    "            legend='Model Accuracy',\n",
    "            x=epoch,\n",
    "            y=accuracy\n",
    "        ),\n",
    "        dataset_id=model.dataset_id\n",
    "    )\n",
    "\n",
    "# Log loss metrics\n",
    "print(\"\ud83d\udcc9 Logging loss metrics...\")\n",
    "for epoch, loss in zip(epochs, losses):\n",
    "    model.metrics.create(\n",
    "        samples=dl.PlotSample(\n",
    "            figure='Training Metrics',\n",
    "            legend='Training Loss',\n",
    "            x=epoch,\n",
    "            y=loss\n",
    "        ),\n",
    "        dataset_id=model.dataset_id\n",
    "    )\n",
    "\n",
    "print(\"\u2728 Metrics logged successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Your metrics will appear in your model's \"Metrics\" tab, looking something like this:\n",
    "\n",
    "![Model Metrics Visualization](../../../../assets/images/model_management/tutorial_model_metrics.png)\n",
    "\n",
    "> \ud83c\udfaf **Pro Tip**: Compare different training runs by selecting multiple metrics in the sidebar!\n",
    "\n",
    "## Analyzing Your Metrics \ud83d\udcca\n",
    "\n",
    "Want to dig into your metrics programmatically? Here's how:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all metrics\n",
    "print(\"\ud83d\udd0d Fetching metrics...\")\n",
    "metrics = model.metrics.list()\n",
    "\n",
    "# Method 1: Iterate through samples\n",
    "print(\"\\n\ud83d\udcca Individual Metrics:\")\n",
    "for sample in metrics.all():\n",
    "    print(f\"Epoch {sample.x}: {sample.y:.3f}\")\n",
    "\n",
    "# Method 2: Convert to DataFrame\n",
    "print(\"\\n\ud83d\udcc8 Metrics DataFrame:\")\n",
    "df = metrics.to_df()\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Best Practices for Metrics Tracking \ud83d\udc51\n",
    "\n",
    "1. **Organization** \ud83d\udccb\n",
    "   - Use consistent metric names\n",
    "   - Group related metrics together\n",
    "   - Add clear legends and labels\n",
    "\n",
    "2. **Tracking Strategy** \ud83c\udfaf\n",
    "   - Log metrics at regular intervals\n",
    "   - Include both training and validation metrics\n",
    "   - Track multiple performance indicators\n",
    "\n",
    "3. **Visualization** \ud83d\udcca\n",
    "   - Use appropriate plot types\n",
    "   - Include units when relevant\n",
    "   - Keep plots clean and readable\n",
    "\n",
    "## Pro Tips \ud83d\udca1\n",
    "\n",
    "1. **Real-time Monitoring** \u26a1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log metrics during training\n",
    "   for epoch in range(num_epochs):\n",
    "       # Your training loop\n",
    "       model.metrics.create(\n",
    "           samples=dl.PlotSample(\n",
    "               figure='Live Training',\n",
    "               legend='Accuracy',\n",
    "               x=epoch,\n",
    "               y=current_accuracy\n",
    "           ),\n",
    "           dataset_id=model.dataset_id\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. **Custom Metrics** \ud83c\udfa8\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log multiple metrics types\n",
    "   model.metrics.create(\n",
    "       samples=[\n",
    "           dl.PlotSample(figure='Performance', legend='Precision', x=epoch, y=precision),\n",
    "           dl.PlotSample(figure='Performance', legend='Recall', x=epoch, y=recall),\n",
    "           dl.PlotSample(figure='Performance', legend='F1', x=epoch, y=f1_score)\n",
    "       ],\n",
    "       dataset_id=model.dataset_id\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Happy tracking! \ud83d\udcc8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}