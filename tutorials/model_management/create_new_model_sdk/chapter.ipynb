{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your Own Model: The DIY Guide \ud83d\udee0\ufe0f\n",
    "\n",
    "Ready to bring your own model to the Dataloop platform? Let's start building together! This guide will show you how to create your first custom model adapter and get your model running smoothly on our platform.\n",
    "\n",
    "## Choose Your Path: SDK or UI \ud83d\udee4\ufe0f\n",
    "\n",
    "You've got two ways to bring your model to life in Dataloop:\n",
    "\n",
    "### Option 1: Using the SDK (This Guide) \ud83d\udcbb\n",
    "Follow along with this guide to create your model programmatically using our Python SDK.\n",
    "\n",
    "### Option 2: Using the Dataloop UI \ud83d\udc41\ufe0f\n",
    "\n",
    "Prefer a more visual approach? You can use the [Dataloop UI](https://docs.dataloop.ai/docs/models-overview#using-the-dataloop-ui) to create and integrate your model. Here's how:\n",
    "\n",
    "1. **Connect Your Docker Registry** \ud83d\udc33\n",
    "   - Link your container registry:\n",
    "     * [AWS ECR](https://docs.dataloop.ai/docs/aws-elastic-container-registry)\n",
    "     * [Google Container Registry (GCR)](https://docs.dataloop.ai/docs/google-container-registry)\n",
    "     * [Google Artifact Registry (GAR)](https://docs.dataloop.ai/docs/google-artifacts-registry)\n",
    "\n",
    "2. **Create Your Model Application** \ud83c\udfa8\n",
    "   - Navigate to the [Model Marketplace](https://docs.dataloop.ai/docs/marketplace-applications#how-to-create-an-application)\n",
    "   - Create a new application\n",
    "   - Link your Docker image:\n",
    "     * Provide the image URL\n",
    "     * Connect it to your application\n",
    "     * Enable predictions, training, and workflow capabilities\n",
    "\n",
    "Now, let's dive into the SDK approach! \ud83d\ude80\n",
    "\n",
    "## The Model Adapter: Your Bridge to Dataloop \ud83c\udf09\n",
    "\n",
    "Think of the model adapter as a translator between your model and Dataloop. It's like teaching your model to speak our language! Let's create one:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import torch\n",
    "import os\n",
    "class SimpleModelAdapter(dl.BaseModelAdapter):\n",
    "    def load(self, local_path, **kwargs):\n",
    "        \"\"\"Load your model from saved weights\"\"\"\n",
    "        print('\ud83d\udd04 Loading model from:', local_path)\n",
    "        self.model = torch.load(os.path.join(local_path, 'model.pth'))\n",
    "\n",
    "    def predict(self, batch, **kwargs):\n",
    "        \"\"\"Run predictions on a batch of data\"\"\"\n",
    "        print(f'\ud83c\udfaf Predicting batch of size: {len(batch)}')\n",
    "        \n",
    "        # Get model predictions\n",
    "        preds = self.model(batch)\n",
    "        \n",
    "        # Convert predictions to Dataloop format\n",
    "        batch_annotations = list()\n",
    "        for i_img, predicted_class in enumerate(preds):\n",
    "            # Create a collection for each image\n",
    "            image_annotations = dl.AnnotationCollection()\n",
    "            \n",
    "            # Add predictions as classifications\n",
    "            image_annotations.add(\n",
    "                annotation_definition=dl.Classification(label=predicted_class),\n",
    "                model_info={'name': self.model_name}\n",
    "            )\n",
    "            batch_annotations.append(image_annotations)\n",
    "            \n",
    "        return batch_annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> \ud83d\udca1 **Pro Tip**: Check out our [ResNet adapter example](https://github.com/dataloop-ai-apps/torch-models/blob/main/adapters/resnet/resnet_adapter.py) on GitHub for a production-ready implementation!\n",
    "\n",
    "## Publishing Your Model App \ud83d\ude80\n",
    "\n",
    "### 1. Create Your Manifest File \ud83d\udcdd\n",
    "\n",
    "First, you'll need a `dataloop.json` manifest file. Think of it as your app's ID card, identifying all the important parts of your app. Here's a template:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n{\n    \"name\": \"my-awesome-model\",\n    \"displayName\": \"My Awesome Model\",\n    \"version\": \"1.0.0\",\n    \"scope\": \"project\",\n    \"description\": \"A fantastic model that does amazing things!\",\n    \"codebase\": {\n        \"type\": \"git\",\n        \"gitUrl\": \"https://github.com/your-repo/your-model\",\n        \"gitTag\": \"v1.0.0\"\n    },\n    \"components\": {\n        \"computeConfigs\": [\n            {\n                \"name\": \"inference-service\",\n                \"runtime\": {\n                    \"podType\": \"regular-xs\",\n                    \"concurrency\": 1,\n                    \"autoscaler\": {\n                        \"type\": \"rabbitmq\",\n                        \"minReplicas\": 0,\n                        \"maxReplicas\": 2,\n                        \"queueLength\": 100\n                    }\n                }\n            }\n        ],\n        \"modules\": [\n            {\n                \"name\": \"model-module\",\n                \"entryPoint\": \"model_adapter.py\",\n                \"className\": \"Adapter\",\n                \"computeConfig\": \"inference-service\"\n            }\n        ],\n        \"models\": [\n            {\n                \"name\": \"my-model\",\n                \"moduleName\": \"model-module\",\n                \"configuration\": {\n                    \"weights_filename\": \"weights.pth\",\n                    \"batch_size\": 4,\n                    \"confidence_threshold\": 0.25\n                }\n            }\n        ]\n    }\n}\n```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 2. Publish Your App \ud83c\udf89\n",
    "\n",
    "Time to share your creation with the world (or at least your project)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your project\n",
    "project = dl.projects.get(project_name=\"your-awesome-project\")\n",
    "# Publish your app\n",
    "dpk = project.dpks.publish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3. Install Your App \ud83d\udce6\n",
    "\n",
    "#### Option A: Through the UI \ud83d\udda5\ufe0f\n",
    "1. Go to Models Marketplace\n",
    "2. Find your app\n",
    "3. Click \"Install\" - Done! \u2728\n",
    "\n",
    "#### Option B: Using Python \ud83d\udc0d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your project\n",
    "project = dl.projects.get(project_name=\"your-awesome-project\")\n",
    "# Get your app's DPK\n",
    "dpk = project.dpks.get(dpk_name='my-awesome-model')\n",
    "# Install it!\n",
    "app = project.apps.install(dpk=dpk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Upload Your Model Weights \ud83c\udfcb\ufe0f\u200d\u2642\ufe0f\n",
    "\n",
    "Now let's give your model its superpowers:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your project and model\n",
    "project = dl.projects.get(project_name=\"your-awesome-project\")\n",
    "model = project.models.get(\"my-model\")\n",
    "\n",
    "# Upload your weights\n",
    "artifact = model.artifacts.upload(filepath='/path/to/weights.pth')\n",
    "\n",
    "# Update the configuration\n",
    "model.configuration['weights_filename'] = artifact.filename\n",
    "\n",
    "# Deploy your model\n",
    "model.deploy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing Your Model \ud83e\uddea\n",
    "\n",
    "### Method 1: Using the UI \ud83d\udda5\ufe0f\n",
    "1. Go to the \"Deployed\" tab\n",
    "2. Find your model\n",
    "3. Click the \"Test\" tab\n",
    "4. Drag & drop an image\n",
    "5. Click \"Test\" and watch the magic happen! \u2728\n",
    "\n",
    "### Method 2: Using Python \ud83d\udc0d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your model and test item\n",
    "model = dl.models.get(model_id='your-model-id')\n",
    "item = dl.items.get(item_id='your-test-item-id')\n",
    "\n",
    "# Run prediction\n",
    "execution = model.predict(item_ids=[item.id])\n",
    "\n",
    "# Wait for results\n",
    "execution.wait()\n",
    "execution = dl.executions.get(execution_id=execution.id)\n",
    "\n",
    "# Check the status\n",
    "print(f\"Prediction status: {execution.status[-1]['status']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Training Your Model \ud83c\udf93\n",
    "\n",
    "Time to teach your model some new tricks! Let's add training capabilities to your model adapter:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModelAdapter(dl.BaseModelAdapter):\n",
    "    def train(self, data_path, **kwargs):\n",
    "        \"\"\"Train your model on Dataloop dataset\"\"\"\n",
    "        print('\ud83c\udfaf Starting training with data from:', data_path)\n",
    "        \n",
    "        # Get training parameters from configuration\n",
    "        epochs = self.configuration.get('epochs', 10)\n",
    "        batch_size = self.configuration.get('batch_size', 32)\n",
    "        learning_rate = self.configuration.get('learning_rate', 0.001)\n",
    "        \n",
    "        # Setup training\n",
    "        train_dataset = self.load_data(data_path)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, batch in enumerate(train_dataset):\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(batch['images'])\n",
    "                loss = criterion(outputs, batch['labels'])\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print(f'\ud83d\udd04 Epoch {epoch + 1}, Batch {i + 1}: Loss = {running_loss / 100:.3f}')\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "            \n",
    "        print('\ud83c\udf89 Training completed!')\n",
    "        \n",
    "    def save(self, local_path):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'configuration': self.configuration\n",
    "        }\n",
    "        checkpoint_path = os.path.join(local_path, f'checkpoint.pth')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f'\ud83d\udcbe Saved checkpoint: {checkpoint_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To train your model:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your model\n",
    "parent_model = project.models.get('my-model')\n",
    "\n",
    "# Get the dataset\n",
    "dataset = project.datasets.get(dataset_name='my-ground-truth')\n",
    "\n",
    "# Clone the model\n",
    "model = parent_model.clone(model_name='my-model-trained',\n",
    "                           dataset=dataset)\n",
    "\n",
    "# Set training configuration\n",
    "model.configuration.update({\n",
    "    'epochs': 20,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'optimizer': 'adam'\n",
    "})\n",
    "\n",
    "# Start training\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> \ud83d\udd25 **Important Note**: If you want your model to include annotations that were generated by a model in the training subsets, you must set \"include_model_annotations\": True in the model configuration. This ensures that both manually created and AI-generated annotations are considered during training.\n",
    "\n",
    "> \ud83d\udca1 **Pro Tip**: Always monitor your training metrics! Add logging and validation steps to track your model's progress.\n",
    "\n",
    "## Export The Weights \ud83c\udfaf\n",
    "\n",
    "Once your model is trained and ready, it's time to export those precious weights! Here's how:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "model = project.models.get('my-model-trained')\n",
    "# Download everything\n",
    "model.artifacts.download(local_path='./my-model-trained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Best Practices for Weight Management \ud83d\udccb\n",
    "\n",
    "1. **Version Control** \ud83d\udd04\n",
    "   - Use semantic versioning for your weights\n",
    "   - Keep a changelog of training modifications\n",
    "   - Store training parameters with weights\n",
    "\n",
    "2. **Validation** \u2705\n",
    "   - Test exported weights before deployment\n",
    "   - Verify model performance after loading\n",
    "   - Keep validation metrics for comparison\n",
    "\n",
    "3. **Documentation** \ud83d\udcdd\n",
    "   - Record training parameters\n",
    "   - Note any preprocessing requirements\n",
    "   - Document expected input/output formats\n",
    "\n",
    "> \ud83d\udd25 **Hot Tip**: Always keep a backup of your best performing weights!\n",
    "\n",
    "\n",
    "## Embedding Models\n",
    "\n",
    "Embedding models are powerful tools that convert your data into numerical vectors, enabling similarity search, clustering, and other advanced analytics. Here's how to implement and use them effectively:\n",
    "\n",
    "### Implementing the Embedding Function\n",
    "\n",
    "To create an embedding model, you need to implement the `embed` function in your model adapter:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dtlpy as dl\n",
    "\n",
    "class EmbeddingModelAdapter(dl.BaseModelAdapter):\n",
    "    def load(self, local_path, **kwargs):\n",
    "        self.model = torch.load(os.path.join(local_path, 'model.pth'))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        # Set the embedding size from the load\n",
    "        self.configuration[\"embeddings_size\"] = 512\n",
    "\n",
    "        \n",
    "    def embed(self, batch, **kwargs):\n",
    "        \"\"\"\n",
    "        Convert a batch of items into embedding vectors\n",
    "        \n",
    "        Args:\n",
    "            batch: List of items to embed\n",
    "            **kwargs: Additional parameters\n",
    "            \n",
    "        Returns:\n",
    "            List of embedding vectors\n",
    "        \"\"\"\n",
    "        embeddings = list()\n",
    "        for item in batch:\n",
    "            # Process your item and generate embedding\n",
    "            # This is a placeholder - replace with your actual embedding logic\n",
    "            embedding = self.model(item)  # Your embedding generation logic here\n",
    "            embeddings.append(embedding)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "When creating an embedding model, you must specify the embedding size either in the model adapter (as in the example above), or in the model configuration:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configuration = {\n",
    "    'embeddings_size': 512,  # Size of your embedding vectors\n",
    "    'batch_size': 32,        # Batch size for processing\n",
    "    'device': 'cuda'         # Device to run the model on\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> \ud83d\udca1 **Pro Tip**: Check out our [DINOv2 adapter example](https://github.com/dataloop-ai-apps/dinov2-image-embedder/blob/main/adapter.py) on GitHub for a production-ready implementation!\n",
    "\n",
    "### Working with Feature Sets\n",
    "\n",
    "Each embedding model model entity can have one associated feature set that stores all the generated embeddings. Here's how to access it after features have been created:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "# Get your model\n",
    "model = dl.models.get(model_id=\"your-model-id\")\n",
    "\n",
    "# Access the feature set\n",
    "feature_set = model.feature_set\n",
    "print(f\"Feature set name: {feature_set.name}\")\n",
    "print(f\"Feature set size: {feature_set.size}\")\n",
    "\n",
    "# List all features\n",
    "pages = feature_set.features.list()\n",
    "print(f\"Number of features: {pages.items_count}\")\n",
    "\n",
    "# Get specific features\n",
    "features = feature_set.features.get(feature_id=\"specific-feature-id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Best Practices for Embedding Models\n",
    "\n",
    "1. **Vector Normalization** \ud83d\udccf\n",
    "   - Normalize your embeddings to unit length\n",
    "   - This ensures consistent similarity calculations\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embeddings(embeddings):\n",
    "       return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. **Batch Processing** \ud83d\udd04\n",
    "   - Process items in batches for efficiency\n",
    "   - Use appropriate batch sizes based on your model and hardware\n",
    "\n",
    "3. **Metadata Management** \ud83d\udccb\n",
    "   - Store relevant metadata with your embeddings\n",
    "   - Include timestamps, model version, and preprocessing details\n",
    "\n",
    "4. **Version Control** \ud83d\udd04\n",
    "   - Keep track of different embedding model versions\n",
    "   - Document changes in embedding generation logic\n",
    "\n",
    "5. **Performance Optimization** \u26a1\n",
    "   - Use GPU acceleration when available\n",
    "   - Implement caching for frequently accessed embeddings\n",
    "\n",
    "### Example: Complete Embedding Model Implementation\n",
    "\n",
    "Here's a complete example of an embedding model implementation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import dtlpy as dl\n",
    "\n",
    "class SimpleEmbeddingAdapter(dl.BaseModelAdapter):\n",
    "    def load(self, local_path, **kwargs):\n",
    "        \"\"\"Load the model weights\"\"\"\n",
    "        self.model = torch.load(os.path.join(local_path, 'model.pth'))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def embed(self, batch, **kwargs):\n",
    "        \"\"\"Generate embeddings for a batch of items\"\"\"\n",
    "        embeddings = []\n",
    "        with torch.no_grad():\n",
    "            for item in batch:\n",
    "                # Load and preprocess image\n",
    "                image = self._load_image(item)\n",
    "                image = image.to(self.device)\n",
    "                \n",
    "                # Generate embedding\n",
    "                embedding = self.model(image)\n",
    "                embedding = embedding.cpu().numpy()\n",
    "                \n",
    "                # Normalize embedding\n",
    "                embedding = embedding / np.linalg.norm(embedding)\n",
    "                embeddings.append(embedding)\n",
    "                \n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Monitoring and Maintenance\n",
    "\n",
    "1. **Track Embedding Quality** \ud83d\udcca\n",
    "   - Monitor embedding distributions\n",
    "   - Check for embedding drift over time\n",
    "   - Validate similarity search results\n",
    "\n",
    "2. **Storage Management** \ud83d\udcbe\n",
    "   - Implement cleanup for old embeddings\n",
    "   - Archive unused feature sets\n",
    "   - Monitor storage usage\n",
    "\n",
    "3. **Performance Monitoring** \ud83d\udcc8\n",
    "   - Track embedding generation time\n",
    "   - Monitor memory usage\n",
    "   - Log errors and exceptions\n",
    "\n",
    "## Troubleshooting Tips \ud83d\udd0d\n",
    "\n",
    "If something's not working as expected:\n",
    "\n",
    "1. **Check Service Status** \ud83d\udea6\n",
    "   - Make sure your model service is up and running\n",
    "   - Look for the green light in the services page\n",
    "\n",
    "2. **Check the Logs** \ud83d\udccb\n",
    "   - Go to \"Model Management\" > \"Deployed\" tab\n",
    "   - Click on the \"Executions\" number\n",
    "   - Look for the paper icon to view logs\n",
    "\n",
    "3. **Common Issues** \u26a0\ufe0f\n",
    "   - Timeouts: Your service might need more resources\n",
    "   - Memory errors: Try reducing batch size\n",
    "   - Missing dependencies: Check your requirements.txt\n",
    "\n",
    "## Ready to Make Your Own? \ud83c\udfb8\n",
    "\n",
    "You've just created your own custom model in Dataloop! Remember:\n",
    "- Test thoroughly before deployment\n",
    "- Monitor your model's performance\n",
    "- Keep your weights and code in sync\n",
    "- Document any special requirements\n",
    "\n",
    "Happy modeling! \ud83d\ude80\n",
    "\n",
    "> \ud83c\udf93 **Need More Help?** Check our [documentation](https://docs.dataloop.ai)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}