{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Analytics\n",
    "\n",
    "## Total Working Time - User Stats Studio Time and Annotation Classify Bulk Time\n",
    "\n",
    "Total working time is derived by summing up the measure types `userStatsStudioTime` and `annotationClassifyBulkTime`.\n",
    "\n",
    "Below is an example of tracking the total working time at the dataset level.\n",
    "\n",
    "**Note**: Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself. If multiple dimensions, such as userId or datasetId, are passed in the context, the API will return aggregated data based on the provided dimensions.\n",
    "\n",
    "**Code Description**\n",
    "\n",
    "The following code is used to extract the total working time shown in the image above. In the `payload`, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- If neither parameter is provided: The aggregated data will be fetched for all datasets and users available in the `projectId`.\n",
    "\n",
    "- If both parameters are provided: The aggregated data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"userStatsStudioTime\", \n",
    "            \"pageSize\": 0\n",
    "            },\n",
    "        {\n",
    "            \"measureType\": \"annotationClassifyBulkTime\",\n",
    "            \"pageSize\": 0\n",
    "            }\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "total_time = 0\n",
    "studio_time = samples[0]\n",
    "bulk_time = samples[1]\n",
    "\n",
    "if studio_time['response']:\n",
    "    total_time += studio_time['response'][0]['activityDuration']\n",
    "\n",
    "if bulk_time['response']:\n",
    "    total_time += bulk_time['response'][0]['totalTime']\n",
    "\n",
    "print(f'total_time in minutes: {int(total_time / (1000 * 60))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Net Annotation Time | Avg Annotation on Item | Avg Annotation Time | Avg Annotation per Items | Total Annotation Time\n",
    "\n",
    "The `annotationCounters` measureType is used for tracking the following metrics:\n",
    "\n",
    "- **Net annotation time**\n",
    "- **Average item time**\n",
    "- **Average annotation time**\n",
    "- **Annotations per item** (available in UI)\n",
    "\n",
    "The `annotationWholeTime` measureType is used for tracking:\n",
    "\n",
    "- **Total annotation time** (available in UI)\n",
    "\n",
    "## Annotation Counter and Annotation Whole Time\n",
    "\n",
    "**Note**: Grouping is not supported for these metrics in the payload, and dimensions must be passed in the context.\n",
    "\n",
    "- If multiple dimensions such as `userId`, `datasetId`, etc., are passed in the context, the response will return aggregated data for the provided dimensions.\n",
    "- If the parameters `datasetId` and `userId` are not passed, the aggregated data will be fetched for all datasets and users available in the `projectId`.\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If neither parameter is provided**: The aggregated data will be fetched for all datasets and users available in the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**: The aggregated data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import math\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"annotationCounters\",\n",
    "             \"pageSize\": 0\n",
    "             },\n",
    "        {\n",
    "            \"measureType\": \"annotationWholeTime\", \n",
    "            \"pageSize\": 0}\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "net_annotation_time = 0\n",
    "avg_item_time = 0\n",
    "avg_annotation_time = 0\n",
    "avg_annotations_per_item = 0\n",
    "annotation_whole_time = 0\n",
    "\n",
    "annotation_counters = samples[0]\n",
    "annotation_wholetime = samples[1]\n",
    "\n",
    "if annotation_counters['response']:\n",
    "    net_annotation_time += annotation_counters['response'][0]['totalTime']\n",
    "    avg_item_time += annotation_counters['response'][0]['avgItemAnnotationTime']\n",
    "    avg_annotation_time += annotation_counters['response'][0]['avgAnnotationTime']\n",
    "    avg_annotations_per_item += annotation_counters['response'][0]['avgAnnotationCountPerItem']\n",
    "\n",
    "if annotation_wholetime['response']:\n",
    "    annotation_whole_time += annotation_wholetime['response'][0]['totalTime']\n",
    "\n",
    "print(f'net_annotation_time in minutes: {int(net_annotation_time/(1000*60))} \\n'\n",
    "        f'avg_item_time in minutes: {int(avg_item_time/(1000*60))} \\n'\n",
    "        f'avg_annotation_time in minutes: {int(avg_annotation_time/(1000*60))} \\n'\n",
    "        f'avg_annotations_per_item: {math.ceil(avg_annotations_per_item)} \\n'\n",
    "        f'annotation_whole_time in minutes: {int(annotation_whole_time/(1000*60))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Annotations Count Per Task\n",
    "\n",
    "Use the following code to extract the total annotations for items in a task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "\n",
    "\n",
    "# Configuration: Set your project name and dataset ID\n",
    "project_name = 'your_project_name_here'\n",
    "dataset_id = 'your_dataset_id_here'\n",
    "\n",
    "# Initialize Project and Dataset\n",
    "project = dl.projects.get(project_name=project_name)\n",
    "dataset = project.datasets.get(dataset_id=dataset_id)\n",
    "\n",
    "\n",
    "# Retrieve all tasks in the dataset\n",
    "tasks = dataset.tasks.list()\n",
    "task_ids = [task.id for task in tasks]\n",
    "\n",
    "# Process each task and count total annotations\n",
    "for task_id in task_ids:\n",
    "    print(f\"\\nProcessing Task ID: {task_id}\")\n",
    "\n",
    "    # Filter items that belong to the current task\n",
    "    filters = dl.Filters(field='metadata.system.refs.id', values=task_id)\n",
    "    task_items = dataset.items.list(filters=filters)\n",
    "    print(f\"Items found: {task_items.items_count}\")\n",
    "\n",
    "    # Initialize total annotation counter\n",
    "    total_annotations = 0\n",
    "\n",
    "    # Count annotations for each item in the task\n",
    "    for item in task_items.all():\n",
    "        item_get = dataset.items.get(item_id=item.id)\n",
    "        count = getattr(item_get, 'annotations_count', 0)\n",
    "        print(f\"Item {item.id} annotations_count = {count}\")\n",
    "        total_annotations += count\n",
    "\n",
    "    # Fetch task details and print summary\n",
    "    task = dataset.tasks.get(task_id=task_id)\n",
    "    print(f\"Task Name: {task.name}, Total Annotations: {total_annotations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Average Annotation Time Per Label\n",
    "\n",
    "`avgAnnotationTimePerLabel` measureType is used for tracking average annotation time per label.\n",
    "\n",
    "Below code is an example of tracking the average annotation time per label at the dataset level.\n",
    "\n",
    "**Note:** Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself.\n",
    "\n",
    "**Code Description**\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If neither parameter is provided**: The data will be fetched for all labels available in the datasets for the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**: The data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id],\n",
    "        \"userId\": [\"e714acd9f43445e73c0a03752454c262e5d43f7a7a97542988b5d874190635af\"]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"avgAnnotationTimePerLabel\",\n",
    "            \"sortDirection\": \"descending\"\n",
    "            }\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    data = samples[0]['response']\n",
    "    df = pd.DataFrame.from_dict(data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Item Annotation Duration\n",
    "\n",
    "Use the following code to extract the item annotation duration at the dataset level.\n",
    "Here we are using the `itemAnnotationDuration` measureType.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "            \"startTime\": project.created_at,\n",
    "            \"endTime\": None,\n",
    "            \"context\": {\n",
    "                        \"projectId\": [project.id],\n",
    "                        \"datasetId\": [dataset.id],\n",
    "                        \"userId\": [\"e714acd9f43445e73c0a03752454c262e5d43f7a7a97542988b5d874190635af\"]\n",
    "            },\n",
    "            \"measures\": [\n",
    "                {\n",
    "                    \"measureType\": \"itemAnnotationDuration\",\n",
    "                    \"sortDirection\": \"descending\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    data = samples[0]['response']\n",
    "    df = pd.DataFrame.from_dict(data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Annotation Timeline\n",
    "\n",
    "The `annotationTimeline` measureType is used for tracking the annotation timeline.\n",
    "\n",
    "Below is an example of tracking the annotation timeline at the dataset level.\n",
    "\n",
    "**Note:** Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself.\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If `timeGranularity` is not provided**:  \n",
    "  By default, it will pick \"hour\" as the `timeGranularity`. In the example code below, \"hour\" and \"day\" are passed as `timeGranularity`, and the response will include both hour-level and day-level data.\n",
    "\n",
    "- **If neither `datasetId` nor `userId` is provided**: The data will be fetched for all items available in the datasets for the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**: The data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"annotationTimeline\",\n",
    "            \"sortDirection\": \"descending\",\n",
    "            \"timeGranularity\": [\"hour\", \"day\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    hour_data = samples[0]['response']\n",
    "    hour_df = pd.DataFrame.from_dict(data=hour_data)\n",
    "\n",
    "if samples[1]['response']:\n",
    "    day_data = samples[1]['response']\n",
    "    day_df = pd.DataFrame.from_dict(data=day_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Item Status Timeline\n",
    "\n",
    "The `itemStatusTimeline` measureType is used for tracking the item status timeline.\n",
    "\n",
    "Below is an example of tracking the Item Status Timeline at the dataset level.\n",
    "\n",
    "**Note:** Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself.\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If `timeGranularity` is not provided**:  \n",
    "  By default, it will pick \"hour\" as the `timeGranularity`. In the example code below, \"hour\" and \"day\" are passed as `timeGranularity`, and the response will include both hour-level and day-level data.\n",
    "\n",
    "- **If neither `datasetId` nor `userId` is provided**:  \n",
    "  The data will be fetched for all items available in the datasets for the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**:  \n",
    "  The data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"itemStatusTimeline\",\n",
    "            \"sortDirection\": \"descending\",\n",
    "            \"timeGranularity\": [\"hour\", \"day\"]\n",
    "            }\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    hour_data = samples[0]['response']\n",
    "    hour_df = pd.DataFrame.from_dict(data=hour_data)\n",
    "\n",
    "if samples[1]['response']:\n",
    "    day_data = samples[1]['response']\n",
    "    day_df = pd.DataFrame.from_dict(data=day_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Average Annotation Time Per Annotator\n",
    "\n",
    "The `avgItemAnnotationTimePerAnnotator` measureType is used for tracking the average annotation time per annotator.\n",
    "\n",
    "Below is an example of tracking the Average Annotation Time Per Annotator at the dataset level.\n",
    "\n",
    "**Note:** Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself.\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If neither `datasetId` nor `userId` is provided**: The data will be fetched for all items available in the datasets for the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**: The data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"avgItemAnnotationTimePerAnnotator\",\n",
    "            \"sortDirection\": \"descending\"\n",
    "            }\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    data = samples[0]['response']\n",
    "    df = pd.DataFrame.from_dict(data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Count Items in Annotation Time Bucket\n",
    "\n",
    "The `countItemInAnnotationTimeBucket` measureType is used for tracking the count of items in annotation time buckets.\n",
    "\n",
    "Below is an example of tracking the Count Items in Annotation Time Bucket at the dataset level.\n",
    "\n",
    "**Note:** Grouping is not supported for this metric in the payload, and dimensions must be passed in the context itself.\n",
    "\n",
    "The following code is used to extract the metrics shown in the image above. In the payload, `datasetId` and `userId` are optional parameters.\n",
    "\n",
    "- **If `timeGranularity` is not provided**:  \n",
    "  By default, it will pick \"hour\" as the `timeGranularity`. In the example code below, \"hour\" and \"day\" are passed as `timeGranularity`, and the response will include both hour-level and day-level data.\n",
    "\n",
    "- **If neither `datasetId` nor `userId` is provided**: The data will be fetched for all items available in the datasets for the `projectId`.\n",
    "\n",
    "- **If both parameters are provided**: The data will be extracted specifically based on the given parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import pandas as pd\n",
    "\n",
    "project = dl.projects.get(project_name='my project')\n",
    "dataset = project.datasets.get(dataset_name='my dataset')\n",
    "\n",
    "payload = {\n",
    "    \"startTime\": project.created_at,\n",
    "    \"endTime\": None,\n",
    "    \"context\": {\n",
    "        \"projectId\": [project.id],\n",
    "        \"datasetId\": [dataset.id]\n",
    "    },\n",
    "    \"measures\": [\n",
    "        {\n",
    "            \"measureType\": \"countItemInAnnotationTimeBucket\",\n",
    "            \"sortDirection\": \"descending\",\n",
    "            \"timeGranularity\": [\"hour\", \"day\"]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "success, resp = dl.client_api.gen_request(req_type=\"post\",\n",
    "                                          path=\"/analytics/query\",\n",
    "                                          json_req=payload)\n",
    "samples = resp.json()\n",
    "if samples[0]['response']:\n",
    "    hour_data = samples[0]['response']\n",
    "    hour_df = pd.DataFrame.from_dict(data=hour_data)\n",
    "\n",
    "if samples[1]['response']:\n",
    "    day_data = samples[1]['response']\n",
    "    day_df = pd.DataFrame.from_dict(data=day_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}