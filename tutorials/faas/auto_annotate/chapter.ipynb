{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Example: Model Annotations Service  \n", "This tutorial demonstrates creating and deploying a service that pre-annotates an items before manual annotation work is performed, as part of active-learning process.  \n", "  \n", "## Service Code  \n", "Your code can perform any action you need toe execute as part of pre-annotating items for example:  \n", "- Access a remote server/API to retrieve annotations  \n", "- Run your algorithm or ML model as a service in Dataloop FaaS  \n", "  \n", "In this example we use a simple face detection algorithm that uses Cv2 and Caffe model  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import os\n", "import cv2\n", "import dtlpy as dl\n", "", "class ServiceRunner:\n", "    def __init__(self,\n", "                 model_filename: str,\n", "                 prototxt_filename: str,\n", "                 min_confidence: float):\n", "        prototxt = os.path.join(os.getcwd(), prototxt_filename)\n", "        weights = os.path.join(os.getcwd(), model_filename)\n", "        print(\"[INFO] loading model...\")\n", "        self.net = cv2.dnn.readNetFromCaffe(prototxt, weights)\n", "        self.min_confidence = min_confidence\n", "", "    def detect(self, item: dl.Item):\n", "        print(\"[INFO] downloading image...\")\n", "        filename = item.download()\n", "        try:\n", "            # load the input image and construct an input blob for the image\n", "            # by resizing to a fixed 300x300 pixels and then normalizing it\n", "            print(\"[INFO] opening image...\")\n", "            image = cv2.imread(filename)\n", "            (h, w) = image.shape[:2]\n", "            blob = cv2.dnn.blobFromImage(cv2.resize(image,\n", "                                                    (300, 300)), 1.0,\n", "                                         (300, 300),\n", "                                         (104.0, 177.0, 123.0))\n", "            # pass the blob through the network and obtain the detections and\n", "            # predictions\n", "            print(\"[INFO] computing object detections...\")\n", "            self.net.setInput(blob)\n", "            detections = self.net.forward()\n", "            # create annotation builder to add annotations to item\n", "            print(\"[INFO] uploading annotations...\")\n", "            builder = item.annotations.builder()\n", "            # loop over the detections\n", "            for i in range(0, detections.shape[2]):\n", "                # extract the confidence (i.e., probability) associated with the\n", "                # prediction\n", "                confidence = detections[0, 0, i, 2]\n", "                # filter out weak detections by ensuring the `confidence` is\n", "                # greater than the minimum confidence\n", "                if confidence > self.min_confidence:\n", "                    # compute the (x, y)-coordinates of the bounding box for the\n", "                    # object\n", "                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n", "                    (startX, startY, endX, endY) = box.astype(\"int\")\n", "                    # draw the bounding box of the face along with the associated\n", "                    # probability\n", "                    builder.add(\n", "                        annotation_definition=dl.Box(\n", "                            top=startY,\n", "                            left=startX,\n", "                            right=endX,\n", "                            bottom=endY,\n", "                            label='person'\n", "                        ),\n", "                        model_info={\n", "                            'name': 'Caffe',\n", "                            'confidence': confidence\n", "                        }\n", "                    )\n", "                    # upload annotations\n", "            builder.upload()\n", "            print(\"[INFO] Done!\")\n", "        finally:\n", "            os.remove(filename)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define the module  \n", "In this example, we load the model in the init method, which runs only once at deployment time, saving us time bu not loading on each execution/  \n", "This can inputs are attributes that we want the service to include for its entire lifetime. In this case, it's the model and weights files we want the service to use and the confidence limit for accepting detections.  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["module = dl.PackageModule(\n", "    init_inputs=[\n", "        dl.FunctionIO(name='model_filename', type=dl.PackageInputType.STRING),\n", "        dl.FunctionIO(name='prototxt_filename', type=dl.PackageInputType.STRING),\n", "        dl.FunctionIO(name='min_confidence', type=dl.PackageInputType.FLOAT)\n", "    ],\n", "    functions=[\n", "        dl.PackageFunction(\n", "            name='detect',\n", "            description='OpenCV face detection using Caffe model',\n", "            inputs=[\n", "                dl.FunctionIO(name='item', type=dl.PackageInputType.ITEM)\n", "            ]\n", "        )\n", "    ]\n", ")\n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["numpy == 1.18\n", "opencv - python == 3.4\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Model and weights files  \n", "The function uses 2 files containing the model and its weights for inferencing detections. We need to have these files at the same folder as the entry point.  \n", "To get these files please download them here.  \n", "https://storage.googleapis.com/dtlpy/model_assets/faas-tutorial/model_weights.zip  \n", "  \n", "##Package Requirements  \n", "Our package's codebase uses 2 Python libraries that are not standard ones. Therefore, we need to make sure they are pre-installed before running the entry point. One way to do so is to use a custom Docker Image (information on this process can be found here. The other way is to add a requirements.txt file to the package codebase. To do so, simply add the following requirements.txt file in the same folder of the entry point (main.py):  \n", "https://docs.dataloop.ai/docs/service-runtime#customimage  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["package = project.packages.push(\n", "    src_path='<path to folder containing the codebase>',\n", "    package_name='face-detector',\n", "    modules=[module]\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Push the Package  \n", "Make sure you have the following files in one directory:  \n", "- main.py  \n", "- requirements.txt  \n", "- res10_300x300_ssd_iter_140000.caffemodel  \n", "- deploy.prototxt.txt  \n", "  \n", "Run this to push your package:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["service = package.deploy(\n", "    service_name='face-detector',\n", "    init_input=[\n", "        dl.FunctionIO(name='model_filename',\n", "                      type=dl.PackageInputType.STRING,\n", "                      value='res10_300x300_ssd_iter_140000.caffemodel'),\n", "        dl.FunctionIO(name='prototxt_filename',\n", "                      type=dl.PackageInputType.STRING,\n", "                      value='deploy.prototxt.txt'),\n", "        dl.FunctionIO(name='min_confidence',\n", "                      type=dl.PackageInputType.FLOAT,\n", "                      value=0.5)\n", "    ],\n", "    runtime=dl.KubernetesRuntime(concurrency=1)\n", "    # The runtime argument Concurrency=1 means that only one execution can run at a time (no parallel executions).\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Deploy The  Service  \n", "The package is now ready to be deployed as a service in the Dataloop Platform.  \n", "Whenever executed, your package will run as a service on default instance type. Review the service configuration to configure it to your needs, for example  \n", "- Change instance-type to use stronger instances with more memory, CPU and GPU  \n", "- Increase auto-scaling to handle larger loads  \n", "- Increase timeouts to allow longer execution time  \n", "  \n", "  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["filters = dl.Filters(resource=dl.FiltersResource.ITEM)\n", "filters.add(field='metadata.system.mimetype', values='image*')\n", "trigger = service.triggers.create(\n", "    name='face-detector',\n", "    function_name=\"detect\",\n", "    resource=dl.TriggerResource.ITEM,\n", "    actions=dl.TriggerAction.CREATED,\n", "    filters=filters\n", ")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Trigger the Service  \n", "Once the service is deployed, we can create a trigger to run it automatically when a certain event occurs.  \n", "In our example we trigger the face-detection service whenever an item is uploaded to the platform.  \n", "Consider using other triggers or different ways to run you service:  \n", "- Add the services to a FaaS-node in a pipeline, before annotation tasks  \n", "- Use DQL trigger to run only on specific datasets, or in specific tasks  \n", "- Run the service when an item is updated  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["self.package.artifacts.download(artifact_name=artifact_filename,\n", "                                local_path=full_weight_path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Uploading Model Weights as Artifacts  \n", "Large data files such as ML model weights can be too big to include in a package. These and other large files can be uploaded as artifact.  \n", "  \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}