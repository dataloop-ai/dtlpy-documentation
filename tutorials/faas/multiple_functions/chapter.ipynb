{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Advanced Use Case: Multiple Functions  \n", "## Create and Deploy a Package of Several Functions  \n", "First, login to the Dataloop platform:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "if dl.token_expired():\n", "    dl.login()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let\u2019s define the project and dataset you will work with in this tutorial.  \n", "To create a new project and dataset:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project = dl.projects.create(project_name='project-sdk-tutorial')\n", "project.datasets.create(dataset_name='dataset-sdk-tutorial')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To use an existing project and dataset:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["project = dl.projects.get(project_name='project-sdk-tutorial')\n", "dataset = project.datasets.get(dataset_name='dataset-sdk-tutorial')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Write your code  \n", "The following code consists of two image-manipulation methods:  \n", "* RGB to grayscale over an image  \n", "* CLAHE Histogram Equalization over an image - Contrast Limited Adaptive Histogram Equalization (CLAHE) to equalize images  \n", "  \n", "To proceed with this tutorial, copy the following code and save it as a main.py file.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["import dtlpy as dl\n", "import cv2\n", "import numpy as np\n", "", "class ImageProcess(dl.BaseServiceRunner):\n", "    @staticmethod\n", "    def rgb2gray(item: dl.Item):\n", "        \"\"\"\n", "        Function to convert RGB image to GRAY\n", "        Will also add a modality to the original item\n", "        :param item: dl.Item to convert\n", "        :return: None\n", "        \"\"\"\n", "        buffer = item.download(save_locally=False)\n", "        bgr = cv2.imdecode(np.frombuffer(buffer.read(), np.uint8), -1)\n", "        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n", "        gray_item = item.dataset.items.upload(local_path=gray,\n", "                                              remote_path='/gray' + item.dir,\n", "                                              remote_name=item.filename)\n", "        # add modality\n", "        item.modalities.create(name='gray',\n", "                               ref=gray_item.id)\n", "        item.update(system_metadata=True)\n", "", "    @staticmethod\n", "    def clahe_equalization(item: dl.Item):\n", "        \"\"\"\n", "        Function to perform histogram equalization (CLAHE)\n", "        Will add a modality to the original item\n", "        Based on opencv https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html\n", "        :param item: dl.Item to convert\n", "        :return: None\n", "        \"\"\"\n", "        buffer = item.download(save_locally=False)\n", "        bgr = cv2.imdecode(np.frombuffer(buffer.read(), np.uint8), -1)\n", "        # create a CLAHE object (Arguments are optional).\n", "        lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n", "        lab_planes = cv2.split(lab)\n", "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n", "        lab_planes[0] = clahe.apply(lab_planes[0])\n", "        lab = cv2.merge(lab_planes)\n", "        bgr_equalized = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n", "        bgr_equalized_item = item.dataset.items.upload(local_path=bgr_equalized,\n", "                                                       remote_path='/equ' + item.dir,\n", "                                                       remote_name=item.filename)\n", "        # add modality\n", "        item.modalities.create(name='equ',\n", "                               ref=bgr_equalized_item.id)\n", "        item.update(system_metadata=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define the module  \n", "Multiple functions may be defined in a single package under a \u201cmodule\u201d entity. This way you will be able to use a single codebase for various services.  \n", "  \n", "Here, we will create a module containing the two functions we discussed. The \u201cmain.py\u201d file you downloaded is defined as the module entry point. Later, you will specify its directory file path.  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["modules = [dl.PackageModule(name='image-processing-module',\n", "                            entry_point='main.py',\n", "                            class_name='ImageProcess',\n", "                            functions=[dl.PackageFunction(name='rgb2gray',\n", "                                                          description='Converting RGB to gray',\n", "                                                          inputs=[dl.FunctionIO(type=dl.PackageInputType.ITEM,\n", "                                                                                name='item')]),\n", "                                       dl.PackageFunction(name='clahe_equalization',\n", "                                                          description='CLAHE histogram equalization',\n", "                                                          inputs=[dl.FunctionIO(type=dl.PackageInputType.ITEM,\n", "                                                                                name='item')])\n", "                                       ])]\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Push the package  \n", "When you deployed the service in the previous tutorial (\u201cSingle Function\u201d), a module and a package were automatically generated.  \n", "  \n", "Now we will explicitly create and push the module as a package in the Dataloop FaaS library (application hub). For that, please specify the source path (src_path) of the \u201cmain.py\u201d file you downloaded, and then run the following code:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["src_path = 'functions/opencv_functions'\n", "project = dl.projects.get(project_name=project_name)\n", "package = project.packages.push(package_name='image-processing',\n", "                                modules=modules,\n", "                                src_path=src_path)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Deploy a service  \n", "Now that the package is ready, it can be deployed to the Dataloop platform as a service.  \n", "To create a service from a package, you need to define which module the service will serve. Notice that a service can only contain a single module. All the module functions will be automatically added to the service.  \n", "  \n", "Multiple services can be deployed from a single package. Each service can get its own configuration: a different module and settings (computing resources, triggers, UI slots, etc.).  \n", "  \n", "In our example, there is only one module in the package. Let\u2019s deploy the service:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["service = package.services.deploy(service_name='image-processing',\n", "                                  runtime=dl.KubernetesRuntime(concurrency=32),\n", "                                  module_name='image-processing-module')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Trigger the service  \n", "Once the service is up, we can configure a trigger to automatically run the service functions. When you bind a trigger to a function, that function will execute when the trigger fires. The trigger is defined by a given time pattern or by an event in the Dataloop system.  \n", "  \n", "Event based trigger is related to a combination of resource and action. A resource can be any entity in our system (item, dataset, annotation, etc.) and the associated action will define a change in the resource that will prompt the trigger (update, create, delete). You can only have one resource per trigger.  \n", "  \n", "  \n", "The resource object that triggered the function will be passed as the function's parameter (input).  \n", "  \n", "Let\u2019s set a trigger in the event a new item is created:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["filters = dl.Filters()\n", "filters.add(field='datasetId', values=dataset.id)\n", "", "trigger = service.triggers.create(name='image-processing2',\n", "                                  function_name='clahe_equalization',\n", "                                  execution_mode=dl.TriggerExecutionMode.ONCE,\n", "                                  resource=dl.TriggerResource.ITEM,\n", "                                  actions=dl.TriggerAction.CREATED,\n", "                                  filters=filters)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the defined filters we specified a dataset. Once a new item is uploaded (created) in this dataset, the CLAHE function will be executed for this item. You can also add filters to specify the item type (image, video, JSON, directory, etc.) or a certain format (jpeg, jpg, WebM, etc.).  \n", "  \n", "A separate trigger must be set for each function in your service.  \n", "Now, we will define a trigger for the second function in the module rgb2gray. Each time an item is updated, invoke the rgb2gray function:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["trigger = service.triggers.create(name='image-processing-rgb',\n", "                                  function_name='rgb2gray',\n", "                                  execution_mode=dl.TriggerExecutionMode.ALWAYS,\n", "                                  resource=dl.TriggerResource.ITEM,\n", "                                  actions=dl.TriggerAction.UPDATED,\n", "                                  filters=filters)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To trigger the function only once (only on the first item update), set TriggerExecutionMode.ONCE instead of TriggerExecutionMode.ALWAYS.  \n", "  \n", "## Execute the function  \n", "Now we can upload (\u201ccreate\u201d) an image to our dataset to trigger the service. The function clahe_equalization will be invoked:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item = dataset.items.upload(\n", "    local_path=['https://raw.githubusercontent.com/dataloop-ai/tiny_coco/master/images/train2017/000000463730.jpg'])\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To see the original item, please click [here](https://raw.githubusercontent.com/dataloop-ai/tiny_coco/master/images/train2017/000000463730.jpg).  \n", "  \n", "## Review the function's logs  \n", "You can review the execution log history to check that your execution succeeded:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["service.log()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The transformed image will be saved in your dataset.  \n", "Once you see in the log that the execution succeeded, you may open the item to see its transformation:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["item.open_in_web()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pause the service:  \n", "We recommend pausing the service you created for this tutorial so it will not be triggered:  \n"]}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "outputs": [], "source": ["service.pause()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Congratulations! You have successfully created, deployed, and tested Dataloop functions!  \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.7"}}, "nbformat": 4, "nbformat_minor": 4}