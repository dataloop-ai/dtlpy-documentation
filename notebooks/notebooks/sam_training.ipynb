{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM2 (Segment Anything Model 2) Comprehensive Guide with Dataloop SDK\n",
    "\n",
    "This notebook provides a comprehensive guide on how to use SAM2 (Segment Anything Model 2), a powerful image segmentation model by Meta AI, with the Dataloop platform and its Python SDK. We will cover the full workflow from setup to model training and evaluation.\n",
    "\n",
    "### Overview\n",
    "This guide will walk you through the following key stages:\n",
    "1. **[Dependencies](#dependencies):** Installing necessary Python packages.\n",
    "2. **[Environment Setup and Dataloop Connection](#environment-setup):** Importing libraries and connecting to your Dataloop account.\n",
    "3. **[Project and Dataset Configuration](#project-dataset-config):** Setting up your Dataloop project and dataset.\n",
    "4. **[Load and Visualize Data](#load-visualize-data):** Loading an image from your dataset and visualizing it with existing annotations.\n",
    "5. **[SAM2 Prediction](#sam2-prediction):** Making predictions using a pre-trained SAM2 model in various modes.\n",
    "6. **[SAM2 Training](#sam2-training):** Fine-tuning a SAM2 model on your custom dataset.\n",
    "7. **[Model Evaluation](#model-evaluation):** Evaluating the performance of your trained model.\n",
    "8. **[Conclusion and Next Steps](#conclusion):** Summarizing the process and suggesting further actions.\n",
    "\n",
    "For more details about SAM2 in the Dataloop platform, refer to the [Dataloop SAM Github repository](https://github.com/dataloop-ai-apps/grounded-sam-adapter/tree/main/adapters/sam_adapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='dependencies'></a>1. Dependencies\n",
    "\n",
    "First, let's ensure all required Python packages are installed. The cell below will install `dtlpy` for Dataloop SDK interaction, along with `matplotlib`, `numpy`, and `Pillow` for data handling and visualization. It's recommended to run this cell if you haven't installed these packages or want to ensure you have compatible versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install dtlpy\n",
    "!pip install matplotlib numpy Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='environment-setup'></a>2. Environment Setup and Dataloop Connection\n",
    "\n",
    "With dependencies potentially installed or updated, we'll import the necessary libraries and establish a connection to the Dataloop platform. If your Dataloop token is expired or not found, you will be prompted to log in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import dtlpy as dl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Login to the Dataloop platform\n",
    "# This will check if your current token is valid and prompt for login if necessary.\n",
    "if dl.token_expired():\n",
    "    dl.login()\n",
    "print('Successfully logged into Dataloop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='project-dataset-config'></a>3. Project and Dataset Configuration\n",
    "\n",
    "Now, we need to specify the Dataloop project and dataset you'll be working with. \n",
    "\n",
    "**Action Required:** In the code cell below, please replace `'your_project_name'` and `'your_dataset_name'` with the names of your Dataloop project and dataset, respectively. The dataset should contain images, which can be with or without existing annotations. If the specified project or dataset does not exist, an error will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project\n",
    "# IMPORTANT: Modify 'your_project_name' to your specific Dataloop project name.\n",
    "project = dl.projects.get(project_name='your_project_name')\n",
    "print(f'Connected to project: {project.name}')\n",
    "\n",
    "# Get the dataset\n",
    "# IMPORTANT: Modify 'your_dataset_name' to your specific Dataloop dataset name.\n",
    "dataset = project.datasets.get(dataset_name='your_dataset_name')\n",
    "print(f'Connected to dataset: {dataset.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='load-visualize-data'></a>4. Load and Visualize Data\n",
    "\n",
    "Let's select a random image from our dataset and visualize it. If the image has existing annotations, we'll display those as well. This helps in understanding the data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random item from the dataset\n",
    "items_list = list(dataset.items.list().all)\n",
    "if items_list:\n",
    "    item = items_list[random.randint(0, len(items_list) - 1)]\n",
    "    print(f\"Selected random item: {item.name} (ID: {item.id})\") \n",
    "else:\n",
    "    print(\"No items found in the dataset!\")\n",
    "    item = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_item_with_annotations(item):\n",
    "    \"\"\"\n",
    "    Display an image item and its annotations\n",
    "    \n",
    "    Args:\n",
    "        item: A Dataloop item object\n",
    "    \"\"\"\n",
    "    if not item:\n",
    "        print(\"No item to display\")\n",
    "        return\n",
    "        \n",
    "    # Download the image locally\n",
    "    buffer = item.download(save_locally=False)\n",
    "    \n",
    "    # Convert buffer to image\n",
    "    image = Image.open(io.BytesIO(buffer))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Image: {item.name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Get annotations for the item\n",
    "    annotations = item.annotations.list()\n",
    "    if annotations.items:\n",
    "        print(f\"Found {len(annotations.items)} annotations\")\n",
    "        \n",
    "        # Display image with annotations\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        # Plot each annotation\n",
    "        for annotation in annotations.items:\n",
    "            if hasattr(annotation, 'coordinates'):\n",
    "                coords = np.array(annotation.coordinates)\n",
    "                if annotation.type == 'box':\n",
    "                    x, y, w, h = coords\n",
    "                    plt.gca().add_patch(plt.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2))\n",
    "                    plt.text(x, y, annotation.label, color='white', backgroundcolor='red', fontsize=8)\n",
    "                elif annotation.type == 'polygon':\n",
    "                    plt.plot(coords[:, 0], coords[:, 1], 'r-', linewidth=2)\n",
    "                    plt.text(coords[0, 0], coords[0, 1], annotation.label, color='white', backgroundcolor='red', fontsize=8)\n",
    "                elif annotation.type == 'point':\n",
    "                    plt.scatter(coords[0], coords[1], c='red', s=50)\n",
    "                    plt.text(coords[0], coords[1], annotation.label, color='white', backgroundcolor='red', fontsize=8)\n",
    "                elif annotation.type == 'segmentation':\n",
    "                    # Assuming annotation.geo is a Dataloop geo object for segmentation\n",
    "                    # The geo_to_mask method requires image height and width\n",
    "                    mask = annotation.geo.geo_to_mask((image.height, image.width)) \n",
    "                    plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "                    \n",
    "        plt.axis('off')\n",
    "        plt.title(\"Image with Annotations\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No annotations found for this item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and item annotations in the notebook\n",
    "display_item_with_annotations(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and item annotations in the platform\n",
    "# This will open the item in your web browser, in the Dataloop annotation studio.\n",
    "item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='sam2-prediction'></a>5. SAM2 Prediction\n",
    "\n",
    "We will now use a pre-trained SAM2 model available on the Dataloop platform to perform image segmentation. SAM2 in Dataloop supports multiple prediction modes:\n",
    "\n",
    "1.  **Zero-shot Segmentation (No Annotations Provided):**\n",
    "    *   If no specific annotations (like boxes or points) are on the item, a bounding box encompassing the entire image is implicitly passed to the model.\n",
    "    *   The model typically returns a binary mask for the most prominent object it identifies in the image.\n",
    "\n",
    "2.  **Box-guided Segmentation:**\n",
    "    *   Users can provide bounding box annotations around specific areas of interest.\n",
    "    *   The model generates segmentation masks for objects within these specified bounding boxes.\n",
    "\n",
    "3.  **Point-based Segmentation:**\n",
    "    *   Users can input point annotations indicating specific locations inside different objects.\n",
    "    *   The model returns a segmentation mask for each object that contains an indicated point.\n",
    "\n",
    "4.  **Multi-points Segmentation (Advanced):**\n",
    "    *   Users can provide multiple points, labeled as \"inside\" (positive) or \"outside\" (negative) the object of interest.\n",
    "    *   The model uses these labeled points to generate more refined segmentation masks.\n",
    "    *   This mode may require specific model configuration, such as `multi_points_prediction=true`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to get the SAM2 DPK (Dataloop Package), install it as an app in our project (if not already installed), and then retrieve the associated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SAM2 DPK (Dataloop Package)\n",
    "sam2_dpk = dl.dpks.get(dpk_name='sam2')\n",
    "\n",
    "# Install the SAM2 app from the DPK if not already installed in the project\n",
    "try:\n",
    "    sam2_app = project.apps.install(app_name=sam2_dpk.display_name, dpk=sam2_dpk, custom_installation=sam2_dpk.to_json())\n",
    "except dl.exceptions.BadRequest as e: # Catch error if app is already installed\n",
    "    print(f\"App {sam2_dpk.display_name} already installed, getting existing app instance.\")\n",
    "    sam2_app = project.apps.get(app_name=sam2_dpk.display_name)\n",
    "\n",
    "# Get the SAM2 model associated with the installed app\n",
    "# Models are typically created when an app is installed or can be managed separately.\n",
    "filters = dl.Filters(resource=dl.FiltersResource.MODEL)\n",
    "filters.add(field='app.id', values=sam2_app.id)\n",
    "model = project.models.list(filters=filters)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the model is deployed before making predictions. If the model is not deployed, the following cell will attempt to deploy it. The model's configuration is also displayed for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SAM2 model (this line is commented out as 'model' should be defined from the previous cell)\n",
    "# model = dl.models.get(model_name='your_model_name') \n",
    "print(f'\\nLoaded model: {model.name}')\n",
    "\n",
    "# Check model status and deploy if not already deployed\n",
    "if model.status != 'deployed':\n",
    "    print('Deploying model...')\n",
    "    model.deploy() # This deploys the model with default settings\n",
    "print(f'Model status: {model.status}')\n",
    "\n",
    "# Display model configuration for reference\n",
    "print('\\nModel configuration:')\n",
    "for key, value in model.configuration.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a prediction on the randomly selected item. If the item has no annotations, SAM2 will perform zero-shot segmentation. If it has box or point annotations, those will guide the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "prediction = model.predict(item_ids=[item.id])\n",
    "prediction.wait() # Wait for the prediction process to complete\n",
    "print('Prediction completed successfully')\n",
    "\n",
    "# Get updated item with predictions\n",
    "# The item in the dataset will now have new annotations generated by the model.\n",
    "updated_item = dataset.items.get(item_id=item.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the item with the newly added prediction annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and item annotations (including predictions) in the notebook\n",
    "display_item_with_annotations(updated_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and item annotations (including predictions) in the platform\n",
    "updated_item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions above show the model's segmentation results, which will typically be mask annotations. You can experiment with different prediction modes by:\n",
    "\n",
    "- Providing bounding boxes for box-guided segmentation (as we'll try next).\n",
    "- Using point-based segmentation by adding point annotations to an item before prediction.\n",
    "- Testing multi-point predictions with appropriately labeled points, if supported by your model configuration.\n",
    "\n",
    "Remember to check the [SAM2 model documentation](https://github.com/dataloop-ai-apps/grounded-sam-adapter/tree/main/adapters/sam_adapter) for detailed configuration options and best practices for different modes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Prediction with a Bounding Box Prompt\n",
    "\n",
    "Let's try guiding SAM2 with a bounding box. You can either add a bounding box manually to the image using the Dataloop UI or add one programmatically using the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Adding a Bounding Box via the Dataloop UI\n",
    "\n",
    "1.  Run the cell below to open the selected item in the Dataloop annotation studio.\n",
    "2.  Use the bounding box tool in the UI to draw a box around an object of interest.\n",
    "3.  Assign a label to the box (e.g., \"target_object\").\n",
    "4.  Save the annotation.\n",
    "5.  Once saved, continue to the cells below to run prediction on this modified item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to open the item in the Dataloop UI for manual annotation\n",
    "# After adding and saving a bounding box in the UI, come back to this notebook.\n",
    "item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Adding a Bounding Box Programmatically\n",
    "\n",
    "Alternatively, use the Dataloop SDK to add a bounding box annotation to the item. Adjust the coordinates and label as needed. Note that the coordinates `(left, top, right, bottom)` are in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and upload a bounding box annotation\n",
    "image_annotation = dl.AnnotationCollection()\n",
    "image_annotation.add(annotation_definition=dl.Box(left=float(100),  # left coordinate in pixels from the left edge of the image\n",
    "                                                top=float(100),    # top coordinate in pixels from the top edge of the image\n",
    "                                                right=float(200),  # right coordinate in pixels from the left edge of the image\n",
    "                                                bottom=float(200), # bottom coordinate in pixels from the top edge of the image\n",
    "                                                label='your_label' # Assign a meaningful label to your prompt box\n",
    "                                                ))\n",
    "item.annotations.upload(image_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run a prediction on the item, which now includes a bounding box prompt (either added via UI or code). We first refetch the item to ensure we have the latest version with the prompt annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the item again to get any annotations added via UI or code\n",
    "annotated_item = dataset.items.get(item_id=item.id)\n",
    "\n",
    "# Make prediction using the item with the prompt\n",
    "prediction = model.predict(item_ids=[annotated_item.id])\n",
    "prediction.wait()\n",
    "print('Prediction completed successfully')\n",
    "\n",
    "# Get updated item with predictions based on the prompt\n",
    "updated_item = dataset.items.get(item_id=item.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the result of the prompt-guided prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and its annotations (including new predictions) in the notebook\n",
    "display_item_with_annotations(updated_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the item and its annotations in the platform\n",
    "updated_item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='sam2-training'></a>6. SAM2 Training\n",
    "\n",
    "To fine-tune SAM2 on your own dataset, we first need to clone the pre-trained model. This creates a new model artifact that you own and can modify. We will then associate our dataset with this cloned model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the base SAM2 model to create a trainable version\n",
    "# It's good practice to give the cloned model a descriptive name.\n",
    "clone_model = model.clone(model_name=model.name, # Or provide a new name like f\"{model.name}-finetune\"\n",
    "                          dataset=dataset, # Associate the dataset for training context\n",
    "                          description='Cloned model for training')\n",
    "\n",
    "print('Model cloned successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect and modify the configuration of this cloned model. For example, training parameters like the number of epochs, batch size, or learning rate can be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the configuration of the cloned model\n",
    "print('\\nCloned model configuration:')\n",
    "for key, value in clone_model.configuration.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's say we want to change the number of training epochs. You can do this directly in the Dataloop platform UI by opening the model's page, or programmatically via the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change configuration in the UI, run the cell below to open the cloned model's page in your browser. Navigate to the configuration settings and make your edits (e.g., set 'num_epochs' or 'epochs' to 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Open the cloned model in the Dataloop UI to modify configuration\n",
    "clone_model.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, update the configuration using the SDK. The exact key for the number of epochs might vary (e.g., `num_epochs`, `epochs`). Check your model's specific configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Modify configuration programmatically (e.g., number of epochs)\n",
    "# Make sure the key 'num_epochs' (or similar, like 'epochs') exists in your model's configuration.\n",
    "clone_model.configuration['num_epochs'] = 10 # Set desired number of epochs\n",
    "clone_model.update() # Save the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the configuration change by displaying it again. If you changed it via UI, re-fetch the model first: `clone_model = dl.models.get(model_id=clone_model.id)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloned model configuration:\n",
      "weights_filename: weights/best_ckpt.pth\n",
      "checkpoint_url: https://storage.googleapis.com/model-mgmt-snapshots/YOLOX/yolox_tiny.pth\n",
      "exp_class_name: TinyExp\n",
      "epochs: 10\n",
      "batch_size: 4\n",
      "conf_thres: 0.25\n",
      "resume: False\n",
      "fp16: False\n",
      "occupy: False\n",
      "logger: tensorboard\n",
      "id_to_label_map: {'0': 'cheetah, chetah, Acinonyx jubatus', '1': 'jaguar, panther, Panthera onca, Felis onca', '2': 'lion, king of beasts, Panthera leo', '3': 'tiger, Panthera tigris', '4': 'leopard, Panthera pardus'}\n",
      "label_to_id_map: {'cheetah, chetah, Acinonyx jubatus': 0, 'jaguar, panther, Panthera onca, Felis onca': 1, 'lion, king of beasts, Panthera leo': 2, 'tiger, Panthera tigris': 3, 'leopard, Panthera pardus': 4}\n",
      "current_epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# Display model configuration again to confirm changes\n",
    "print('\\nCloned model configuration:')\n",
    "for key, value in clone_model.configuration.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for Training: Subsets\n",
    "\n",
    "For effective model training, it's crucial to split your dataset into training, validation, and (optionally) test subsets. Dataloop provides tools to manage these splits. Here, we'll split our dataset items based on percentages. The items will be tagged accordingly (e.g., 'train', 'validation', 'test').\n",
    "\n",
    "For more information on dataset splitting and subsets, refer to the [Dataloop documentation on ML Subsets](https://developers.dataloop.ai/tutorials/data_management/datasets_and_versioning/chapter#ml-subsets-your-datasets-secret-sauce-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add subsets to the dataset\n",
    "# This operation tags items with 'train', 'validation', or 'test'.\n",
    "filters = dl.Filters(field='type', values='file') # Filter to select only 'file' type items (e.g., images)\n",
    "dataset.split_ml_subsets(\n",
    "    # Define the query to filter items (only files in this case)\n",
    "    items_query=filters,\n",
    "    # Split the dataset into train (60%), validation (20%), and test (20%) subsets\n",
    "    # These will be used for training, validating, and testing the model respectively\n",
    "    # Adjust percentages as needed for your dataset size and requirements.\n",
    "    percentages={'train': 60, 'validation': 20, 'test': 20}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to inform the cloned model which items belong to the training and validation sets. We do this by creating filters based on the subset tags (e.g., `metadata.system.tags.train`) and adding these subsets to the model. Then, we initiate the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters to select items tagged as 'train' and 'validation'\n",
    "# These tags are automatically added by the split_ml_subsets method.\n",
    "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
    "validation_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
    "\n",
    "# Add the train subset to the model, specifying the dataset and the filter\n",
    "# This tells the model which items to use for training\n",
    "clone_model.add_subset(subset_name=\"train\", subset_filter=train_filters) # dataset_id is taken from clone_model.dataset_id if not specified\n",
    "\n",
    "# Add the validation subset to the model\n",
    "# This tells the model which items to use for validation during training\n",
    "clone_model.add_subset(subset_name=\"validation\", subset_filter=validation_filters)\n",
    "\n",
    "# Update the model to save the subset configurations\n",
    "# The system_metadata=True parameter ensures system metadata (like subset definitions) is updated.\n",
    "clone_model.update(system_metadata=True)\n",
    "\n",
    "# Start the model training process\n",
    "# This will use the items defined in the 'train' and 'validation' subsets.\n",
    "# This returns an execution object that can be used to track training progress.\n",
    "execution = clone_model.train()\n",
    "\n",
    "# Print confirmation message\n",
    "print('Model training started successfully')\n",
    "# print(f\"Training initiated. Execution ID: {execution.id}\") # Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training can take a significant amount of time, depending on the dataset size, model complexity, and hardware resources. The `execution.wait()` call will block the notebook until training is finished or fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the training execution to complete\n",
    "execution.wait() \n",
    "print('Model training finished successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can navigate to the 'Training' tab on the model's page in the Dataloop UI to view detailed progress, logs, and performance metrics as the training runs. The cell below will open this page for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the model page in the Dataloop platform to monitor training\n",
    "clone_model.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='model-evaluation'></a>7. Model Evaluation\n",
    "\n",
    "After the training process is complete, it's essential to evaluate the performance of your fine-tuned model. We'll use the 'test' subset of our data, which the model has not seen during training or validation, for this purpose. The evaluation process runs predictions on the test set and compares them to ground truth annotations to calculate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters to select items tagged as 'test'\n",
    "# This filter will identify all items in the dataset that have been tagged for testing.\n",
    "test_filters = dl.Filters(field='metadata.system.tags.test', values=True)\n",
    "\n",
    "# Start the model evaluation process on the test subset\n",
    "# - dataset_id: Specifies which dataset to use for evaluation (taken from clone_model.dataset_id by default if associated).\n",
    "# - filters: Applies the test filters to only evaluate on test items.\n",
    "execution = clone_model.evaluate(dataset_id=dataset.id, # Explicitly providing dataset.id\n",
    "                                 filters=test_filters)\n",
    "\n",
    "# Print confirmation message\n",
    "print('Model evaluation started successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training, evaluation can take some time. The `execution.wait()` call will block until it's complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the evaluation execution to complete\n",
    "execution.wait()\n",
    "print('Model evaluation finished successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the evaluation is finished, you can access detailed performance metrics in the Dataloop platform. These are typically found under a 'Metrics' or 'Precision-Recall' tab on the model's page (accessible via `clone_model.open_in_web()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_model.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a>8. Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You have successfully walked through the process of using SAM2 with Dataloop, including:\n",
    "1.  Setting up your environment and connecting to Dataloop.\n",
    "2.  Configuring your project and dataset.\n",
    "3.  Visualizing data and annotations.\n",
    "4.  Performing predictions with a pre-trained SAM2 model using various prompting techniques.\n",
    "5.  Fine-tuning SAM2 on your custom dataset.\n",
    "6.  Evaluating the performance of your fine-tuned model.\n",
    "\n",
    "### Next Steps:\n",
    "*   **Explore Advanced Configurations:** Dive deeper into the SAM2 model's configuration options for both prediction and training to optimize performance for your specific use case.\n",
    "*   **Iterate on Training:** Adjust training parameters (epochs, learning rate, batch size), dataset composition, and augmentation strategies to improve your fine-tuned model.\n",
    "*   **Deploy Your Trained Model:** Once satisfied with your fine-tuned model, deploy it as a service to use it for inference on new, unseen data within your Dataloop workflows or external applications.\n",
    "*   **Analyze Evaluation Metrics:** Thoroughly review the evaluation metrics in the Dataloop platform (accessible via the model's page) to understand your model's strengths and weaknesses.\n",
    "\n",
    "This notebook provides a foundational guide. The Dataloop platform offers many more features for comprehensive AI data management and model development. We encourage you to explore the [Dataloop documentation](https://dataloop.ai/docs) for more advanced topics and functionalities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
