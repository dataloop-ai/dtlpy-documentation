{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Custom Model Adapter on Dataloop\n",
    "\n",
    "This notebook provides a comprehensive guide on how to build, configure, and deploy a custom model adapter on the Dataloop platform. Model adapters are a powerful feature that allows you to integrate any model, including your own locally trained or fine-tuned models, into the Dataloop ecosystem for inference, annotation, and quality assurance.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Dependencies & Setup](#setup)\n",
    "2. [Building the Custom Model Adapter](#build-adapter)\n",
    "3. [Configuring the Dataloop Application (DPK)](#configure-dpk)\n",
    "4. [Publishing and Deploying the DPK](#publish-deploy)\n",
    "5. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='setup'></a>1. Dependencies & Setup\n",
    "\n",
    "First, let's ensure all required Python packages are installed. The cell below will install `dtlpy` for Dataloop SDK interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtlpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup and Dataloop Connection\n",
    "\n",
    "With the dependencies installed, we'll import the necessary libraries and establish a connection to the Dataloop platform. If your Dataloop token is expired or not found, you will be prompted to log in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if dl.token_expired():\n",
    "    dl.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='build-adapter'></a>2. Building the Custom Model Adapter\n",
    "\n",
    "The `dl.BaseModelAdapter` is the bridge between your model's code and the Dataloop platform. It's a Python class where you implement a few key methods to define how your model loads, trains, and predicts.\n",
    "\n",
    "Here are the most important methods you'll need to implement:\n",
    "\n",
    "- `load(self, local_path, **kwargs)`: This function is responsible for loading your model's architecture and weights into memory. The `local_path` argument points to a directory where your model's artifacts (like weight files) are downloaded.\n",
    "\n",
    "- `predict(self, batch, **kwargs)`: This is the core inference function. It takes a batch of prepared items (e.g., a list of NumPy arrays for images) and should return a list of `dl.AnnotationCollection` objects, with one collection for each item in the batch.\n",
    "\n",
    "- `train(self, data_path, output_path, **kwargs)`: (Optional) If you want to enable training or fine-tuning from within the Dataloop platform, you'll implement this method to define your training loop.\n",
    "\n",
    "- `save(self, local_path, **kwargs)`: (Optional) After training, this function is called to save the updated model weights and any other necessary artifacts to the specified `local_path`.\n",
    "\n",
    "### Example: Creating a YOLOv12 Adapter\n",
    "\n",
    "Let's create a model adapter for a hypothetical `YOLOv12` object detection model. We'll focus on the `load` and `predict` methods for this example. We will write this class to a file named `model_adapter.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_adapter.py\n",
    "import dtlpy as dl\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger('YOLOv12Adapter')\n",
    "\n",
    "@dl.Package.decorators.module(description='Model Adapter for YOLOv12 object detection',\n",
    "                              name='model-adapter',\n",
    "                              init_inputs={'model_entity': dl.Model})\n",
    "class Adapter(dl.BaseModelAdapter):\n",
    "\n",
    "    def load(self, local_path, **kwargs):\n",
    "        weights_filename = self.configuration.get('weights_filename', 'yolo12n.pt')\n",
    "        model_filepath = os.path.join(local_path, weights_filename)\n",
    "        \n",
    "        # The YOLO class from ultralytics automatically handles downloads if the file doesn't exist\n",
    "        self.model = YOLO(model_filepath)\n",
    "        self.logger.info(f\"Model loaded from {model_filepath}\")\n",
    "        \n",
    "    def predict(self, batch, **kwargs):\n",
    "        \"\"\"\n",
    "        Run inference on a batch of items.\n",
    "        \"\"\"\n",
    "        logger.info(f'Predicting batch of size: {len(batch)}')\n",
    "        batch_annotations = []\n",
    "        for image in batch:\n",
    "            # YOLO model can take PIL image directly\n",
    "            results = self.model(image)\n",
    "            collection = dl.AnnotationCollection()\n",
    "            \n",
    "            # Process results for a single image\n",
    "            for result in results:\n",
    "                if result.boxes:\n",
    "                    for box in result.boxes:\n",
    "                        # Extract box coordinates, class, and confidence\n",
    "                        left, top, right, bottom = box.xyxy[0].tolist()\n",
    "                        confidence = box.conf[0].item()\n",
    "                        label_id = int(box.cls[0].item())\n",
    "                        label = self.model.names[label_id]\n",
    "                        \n",
    "                        # Add a box annotation to the collection\n",
    "                        collection.add(\n",
    "                            annotation_definition=dl.Box(\n",
    "                                top=top,\n",
    "                                left=left,\n",
    "                                bottom=bottom,\n",
    "                                right=right,\n",
    "                                label=label\n",
    "                            ),\n",
    "                            model_info={\n",
    "                                'name': self.model_entity.name,\n",
    "                                'confidence': confidence\n",
    "                            }\n",
    "                        )\n",
    "            \n",
    "            batch_annotations.append(collection)\n",
    "            \n",
    "        return batch_annotations\n",
    "    \n",
    "    def prepare_item_func(self, item: dl.Item):\n",
    "        \"\"\"\n",
    "        Prepare an item for prediction.\n",
    "        \"\"\"\n",
    "        buffer = item.download(save_locally=False)\n",
    "        image = Image.open(buffer).convert('RGB')\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='configure-dpk'></a>3. Configuring the Dataloop Application (DPK)\n",
    "\n",
    "Every model and service on Dataloop is packaged as a Dataloop Application (DPK). The configuration for this app is defined in a manifest file called `dataloop.json`. This file contains all the necessary information for the platform to understand, display, and execute your model.\n",
    "\n",
    "Key sections in `dataloop.json`:\n",
    "\n",
    "- **`name`, `displayName`, `version`, `description`**: Basic metadata about your app.\n",
    "- **`codebase`**: Specifies the source of your code. For this tutorial we use a local codebase, but it can also be a Git repository.\n",
    "- **`components`**: This is the core section where you define the building blocks of your app.\n",
    "  - **`modules`**: Defines the code modules in your package. It specifies the entry point (e.g., `model_adapter.py`), the class name (`Adapter`), and the functions that can be executed.\n",
    "  - **`computeConfigs`**: Defines named configurations for compute resources. This allows you to specify different hardware (like CPU or GPU types) and scaling behaviors for different tasks. For example, you might use a lightweight CPU configuration for simple prediction tasks but a powerful GPU configuration for training.\n",
    "  - **`models`**: Here you define one or more models that your adapter can handle. Each model has its own configuration (`weights_filename`, `labels`, etc.), input/output types, and description.\n",
    "\n",
    "### 3.1 `dataloop.json` Template\n",
    "\n",
    "**Action Required:** In the template below, you would replace all placeholders like `<your-app-name>` with your specific details. For this tutorial, we will provide a complete `dataloop.json` in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"name\": \"<your-app-name>\",\n",
    "  \"displayName\": \"<Your Model Display Name>\",\n",
    "  \"version\": \"0.0.1\",\n",
    "  \"scope\": \"public\",\n",
    "  \"description\": \"<A brief description of your model>\",\n",
    "  \"codebase\": {\n",
    "    \"type\": \"local\",\n",
    "    \"filePath\": \"model_adapter.py\"\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"computeConfigs\": [\n",
    "      {\n",
    "        \"name\": \"<your-deploy-config-name>\",\n",
    "        \"runtime\": {\n",
    "          \"podType\": \"regular-m\",\n",
    "          \"concurrency\": 1,\n",
    "          \"autoscaler\": {\n",
    "            \"type\": \"rabbitmq\",\n",
    "            \"minReplicas\": 0,\n",
    "            \"maxReplicas\": 1,\n",
    "            \"queueLength\": 10\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"<your-train-config-name>\",\n",
    "        \"runtime\": {\n",
    "          \"podType\": \"gpu-t4\",\n",
    "          \"concurrency\": 1,\n",
    "          \"autoscaler\": {\n",
    "            \"type\": \"rabbitmq\",\n",
    "            \"minReplicas\": 0,\n",
    "            \"maxReplicas\": 1,\n",
    "            \"queueLength\": 10\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"modules\": [\n",
    "      {\n",
    "        \"name\": \"<your-module-name>\",\n",
    "        \"entryPoint\": \"model_adapter.py\",\n",
    "        \"className\": \"Adapter\",\n",
    "        \"computeConfig\": \"<your-deploy-config-name>\",\n",
    "        \"description\": \"<Module Description>\",\n",
    "        \"initInputs\": [\n",
    "          {\n",
    "            \"type\": \"Model\",\n",
    "            \"name\": \"model_entity\"\n",
    "          }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "          {\n",
    "            \"name\": \"predict_items\",\n",
    "            \"input\": [\n",
    "              {\n",
    "                \"type\": \"Item[]\",\n",
    "                \"name\": \"items\"\n",
    "              }\n",
    "            ],\n",
    "            \"output\": [\n",
    "              {\n",
    "                \"type\": \"Annotation[]\",\n",
    "                \"name\": \"annotations\"\n",
    "              }\n",
    "            ],\n",
    "            \"displayName\": \"Predict Items\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"models\": [\n",
    "      {\n",
    "        \"name\": \"<your-model-name>\",\n",
    "        \"moduleName\": \"<your-module-name>\",\n",
    "        \"scope\": \"project\",\n",
    "        \"status\": \"pre-trained\",\n",
    "        \"configuration\": {\n",
    "          \"weights_filename\": \"<your_weights_file.pt>\",\n",
    "          \"labels\": [\n",
    "             \"label1\", \"label2\", \"...\"\n",
    "           ]\n",
    "        },\n",
    "        \"inputType\": \"image\",\n",
    "        \"outputType\": \"box\",\n",
    "        \"description\": \"<Detailed description of the model variant>\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 In-Depth Look at `computeConfigs`\n",
    "\n",
    "The `computeConfigs` section in your `dataloop.json` is critical for defining the computational resources your service will use. It allows you to create named configurations that can be referenced by your modules, giving you fine-grained control over performance and cost.\n",
    "\n",
    "Let's break down the components:\n",
    "\n",
    "-   **`name`**: A unique identifier for your compute configuration. You'll use this name to assign a specific configuration to a module (e.g., `\"computeConfig\": \"your-deploy-config-name\"`).\n",
    "\n",
    "-   **`runtime`**: This object specifies the execution environment for your service.\n",
    "    -   **`podType`**: This determines the size of the machine (pod) your service will run on. Dataloop offers a range of pod types with varying CPU, GPU, and memory resources. Choosing the right `podType` is a balance between performance and cost.\n",
    "\n",
    "| Pod Type | vCPU | Memory (GiB) | GPU | Description |\n",
    "|---|---|---|---|---|\n",
    "| `regular-xs` | 0.5 | 1.7 | - | Extra Small CPU instance |\n",
    "| `regular-s` | 1 | 3.5 | - | Small CPU instance |\n",
    "| `regular-m` | 2 | 7 | - | Medium CPU instance |\n",
    "| `regular-l` | 4 | 14 | - | Large CPU instance |\n",
    "| `gpu-k80` | 4 | 26 | 1x NVIDIA K80 | GPU instance for general purpose tasks |\n",
    "| `gpu-t4` | 4 | 14 | 1x NVIDIA T4 | GPU instance with Turing architecture, good for inference |\n",
    "| `gpu-v100` | 6 | 26 | 1x NVIDIA V100 | High-performance GPU for demanding training tasks |\n",
    "| `gpu-a100` | 12 | 85 | 1x NVIDIA A100 | Top-tier GPU for large-scale training and inference |\n",
    "\n",
    "\n",
    "-   **`concurrency`**: This sets the number of concurrent processes your service's replica can handle. For models that are not thread-safe or are resource-intensive per-task, this is typically set to `1`. If your model and pod size can handle multiple tasks at once, you can increase this value to improve throughput.\n",
    "\n",
    "-   **`autoscaler`**: This object controls how your service scales in response to demand.\n",
    "    -   `type`: The autoscaling trigger. `\"rabbitmq\"` is used for services that process jobs from a queue.\n",
    "    -   `minReplicas`: The minimum number of service replicas to keep running, even with no load. Setting this to `0` allows the service to scale down completely, saving costs when idle.\n",
    "    -   `maxReplicas`: The maximum number of replicas that can be created to handle a surge in demand.\n",
    "    -   `queueLength`: The number of messages in the RabbitMQ queue that will trigger the creation of a new replica. For example, if `queueLength` is `10`, a new replica will be spun up for every 10 pending executions.\n",
    "\n",
    "### 3.3 Runner Image and Custom Environments\n",
    "\n",
    "The optional `runnerImage` parameter allows you to specify a custom Docker image for your service's execution environment. This is extremely useful when your model requires specific system libraries, dependencies, or a particular version of Python that isn't available in the default Dataloop environment.\n",
    "\n",
    "If you don't provide a `runnerImage`, Dataloop uses a default image. However, for production and reproducibility, it's highly recommended to build and use your own.\n",
    "\n",
    "Here is a sample `Dockerfile` that you could use as a starting point. It uses a base PyTorch image, installs necessary dependencies, and sets up the environment for a Dataloop service.\n",
    "\n",
    "#### Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "FROM dataloopai/dtlpy-agent:gpu.cuda.11.8.py3.8.pytorch2\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglib2.0-0 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy and install Python requirements\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "```\n",
    "\n",
    "#### requirements.txt:\n",
    "\n",
    "```txt\n",
    "torch\n",
    "ultralytics\n",
    "dtlpy\n",
    "```\n",
    "\n",
    "For this tutorial, we are using a pre-built image specified in the final `dataloop.json`, but for your own projects, you would build this Docker image and push it to a container registry (like GCR, ECR, or Docker Hub) that your Dataloop organization is connected to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Complete `dataloop.json` for YOLOv12\n",
    "\n",
    "Below is the complete manifest for our YOLOv12 adapter. We'll write this to a `dataloop.json` file in our working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dataloop.json\n",
    "{\n",
    "  \"name\": \"yolov12\",\n",
    "  \"displayName\": \"YOLOv12\",\n",
    "  \"version\": \"0.0.1\",\n",
    "  \"scope\": \"project\",\n",
    "  \"description\": \"YOLOv12: Attention-Centric Object Detection\",\n",
    "  \"codebase\": {\n",
    "    \"type\": \"local\",\n",
    "    \"filePath\": \"model_adapter.py\"\n",
    "  },\n",
    "  \"attributes\": {\n",
    "    \"Provider\": \"Ultralytics\",\n",
    "    \"License\": \"AGPL-3.0\",\n",
    "    \"Category\": \"Model\",\n",
    "    \"Computer Vision\": \"Object Detection\",\n",
    "    \"Media Type\": [\"Image\"],\n",
    "    \"Deployed By\": \"Dataloop\"\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"computeConfigs\": [\n",
    "      {\n",
    "        \"name\": \"yolov12-deploy\",\n",
    "        \"runtime\": {\n",
    "          \"podType\": \"regular-m\",\n",
    "          \"concurrency\": 1,\n",
    "          \"runnerImage\": \"gcr.io/viewo-g/piper/agent/runner/apps/yolo-world:0.0.1-dev\",\n",
    "          \"autoscaler\": {\n",
    "            \"type\": \"rabbitmq\",\n",
    "            \"minReplicas\": 1,\n",
    "            \"maxReplicas\": 2,\n",
    "            \"queueLength\": 100\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"modules\": [\n",
    "      {\n",
    "        \"name\": \"yolov12-module\",\n",
    "        \"entryPoint\": \"model_adapter.py\",\n",
    "        \"className\": \"Adapter\",\n",
    "        \"computeConfig\": \"yolov12-deploy\",\n",
    "        \"description\": \"YoloV12 Module\",\n",
    "        \"initInputs\": [\n",
    "          {\n",
    "            \"type\": \"Model\",\n",
    "            \"name\": \"model_entity\"\n",
    "          }\n",
    "        ],\n",
    "        \"functions\": [\n",
    "          {\n",
    "            \"name\": \"predict_items\",\n",
    "            \"input\": [\n",
    "              {\n",
    "                \"type\": \"Item[]\",\n",
    "                \"name\": \"items\",\n",
    "                \"description\": \"List of items to run inference on\"\n",
    "              }\n",
    "            ],\n",
    "            \"output\": [\n",
    "              {\n",
    "                \"type\": \"Annotation[]\",\n",
    "                \"name\": \"annotations\",\n",
    "                \"description\": \"The predicted annotations.\"\n",
    "              }\n",
    "            ],\n",
    "            \"displayName\": \"Predict Items\",\n",
    "            \"displayIcon\": \"\",\n",
    "            \"description\": \"Function to run YOLOv12 inference on items\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"models\": [\n",
    "      {\n",
    "        \"name\": \"yolo12n\",\n",
    "        \"moduleName\": \"yolov12-module\",\n",
    "        \"scope\": \"project\",\n",
    "        \"status\": \"pre-trained\",\n",
    "        \"configuration\": {\n",
    "          \"weights_filename\": \"yolo12n.pt\",\n",
    "          \"labels\": [\n",
    "             \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \n",
    "             \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \n",
    "             \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \n",
    "             \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \n",
    "             \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \n",
    "             \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \n",
    "             \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \n",
    "             \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \n",
    "             \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \n",
    "             \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "           ]\n",
    "        },\n",
    "        \"inputType\": \"image\",\n",
    "        \"outputType\": \"box\",\n",
    "        \"description\": \"YOLO12 Nano model\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='publish-deploy'></a>4. Publishing and Deploying the DPK\n",
    "\n",
    "Once you have your `model_adapter.py` and `dataloop.json` files ready, the final step is to publish your DPK to the Dataloop platform. This makes your model available as an app that can be installed in any project.\n",
    "\n",
    "The following script automates this process:\n",
    "\n",
    "1. **`project.dpks.publish()`**: This command reads your `dataloop.json`, finds your local codebase, and publishes it as a new DPK version in the app store.\n",
    "2. **`project.apps.install()` or `app.update()`**: After publishing, this script checks if the app is already installed in your target project. If it is, it updates the app to the new version. If not, it installs it for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define Project and Publish\n",
    "\n",
    "**Action Required:** In the code cell below, replace `'<your-project-name>'` with the name of the Dataloop project where you want to publish and install your model app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project = dl.projects.get(project_name='<your-project-name>')\n",
    "\n",
    "# Publish the DPK to the Dataloop platform\n",
    "dpk = project.dpks.publish(manifest_filepath='dataloop.json', \n",
    "                           local_path=os.getcwd())\n",
    "\n",
    "print(f\"DPK '{dpk.display_name}' published successfully. Version: {dpk.version}\")\n",
    "\n",
    "try:\n",
    "    # If the app is already installed, update it to the new version\n",
    "    app = project.apps.get(app_name=dpk.display_name)\n",
    "    app.dpk_version = dpk.version\n",
    "    app.update()\n",
    "    print(f\"App '{app.name}' updated successfully to version {dpk.version}.\")\n",
    "except dl.exceptions.NotFound:\n",
    "    # If the app is not installed, install it\n",
    "    app = project.apps.install(dpk=dpk, app_name=dpk.display_name)\n",
    "    print(f\"App '{app.name}' installed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a>5. Conclusion\n",
    "\n",
    "Congratulations! You've now walked through the entire process of integrating a custom object detection model into the Dataloop platform. \n",
    "\n",
    "You have learned how to:\n",
    "- **Bring Your Own Model**: Use the `BaseModelAdapter` to wrap any model for use on Dataloop.\n",
    "- **Handle Data**: Implement the `predict` function to process items and generate Dataloop-standard annotations.\n",
    "- **Package Your App**: Define your model, its functions, and configurations in the `dataloop.json` manifest.\n",
    "- **Deploy and Manage**: Publish your DPK and install it as a usable app within your Dataloop projects.\n",
    "\n",
    "From here, you can explore more advanced features like implementing the `train` method to fine-tune your models directly on the platform, creating complex pipelines, and building interactive UI panels for your applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-dtlpy-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
