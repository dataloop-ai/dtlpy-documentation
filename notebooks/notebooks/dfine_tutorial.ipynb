{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "main-title",
      "metadata": {},
      "source": [
       "# D-FINE Object Detection Model with Dataloop Platform Tutorial\n",
       "\n",
       "This notebook provides a comprehensive guide on using the D-FINE (Diverse Fine-grained Distribution Refinement) object detection model with the Dataloop platform. D-FINE is a real-time object detection model designed for diverse applications such as autonomous driving, surveillance systems, robotics, and retail analytics.\n",
       "\n",
       "The D-FINE model uses two key components: Fine-grained Distribution Refinement (FDR) for enhanced localization accuracy, and Global Optimal Localization Self-Distillation (GO-LSD) for improved training efficiency. You'll learn how to fine-tune this powerful model on your custom datasets and deploy it for real-time inference.\n",
       "\n",
       "### Prerequisites:\n",
       "* **Dataloop Account:** You should have access to a Dataloop platform account.\n",
       "* **Python Environment:** Python 3.7+ with pip for installing required packages.\n",
       "* **Basic Knowledge:** Familiarity with object detection concepts and machine learning workflows is helpful.\n",
       "\n",
       "### Navigate through the following sections:\n",
       "1. **[Install Dependencies](#install-dependencies)** - Setting up required Python libraries\n",
       "2. **[Import Required Libraries](#import-libraries)** - Loading necessary modules\n",
       "3. **[Set Up Dataloop Environment](#setup-environment)** - Connecting to the platform\n",
       "4. **[Install D-FINE Model Package](#install-dfine-dpk)** - Loading the model from marketplace\n",
       "5. **[Load Base D-FINE Model](#configure-dfine-model)** - Configuring the base model\n",
       "6. **[Prepare Dataset](#prepare-dataset)** - Setting up training data\n",
       "7. **[Configure Model for Training](#configure-model-training)** - Setting training parameters\n",
       "8. **[Clone Model and Start Training](#clone-train-model)** - Fine-tuning the model\n",
       "9. **[Deploy Model as Service](#deploy-service)** - Setting up inference endpoint\n",
       "10. **[Test Deployed Model](#test-deployed)** - Running predictions\n",
       "11. **[Extract Embeddings](#extract-embeddings)** - Generating feature vectors\n",
       "12. **[Conclusion](#conclusion)** - Summary and next steps"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "install-dependencies",
      "metadata": {},
      "source": [
       "<a id=\"install-dependencies\"></a>\n",
       "## 1. Install Dependencies\n",
       "\n",
       "First, ensure that the necessary Python libraries are installed. This notebook requires `dtlpy` for interacting with the Dataloop platform and standard Python libraries for data processing and visualization.\n",
       "\n",
       "**Note:** The D-FINE model dependencies (transformers, torch, etc.) will be managed by the Dataloop model adapter."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "install-deps",
      "metadata": {},
      "outputs": [],
      "source": [
       "!pip install dtlpy --upgrade --quiet"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "import-libraries",
      "metadata": {},
      "source": [
       "<a id=\"import-libraries\"></a>\n",
       "## 2. Import Required Libraries\n",
       "\n",
       "Now, we import all the Python libraries that will be used throughout this tutorial."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
       "import dtlpy as dl\n",
       "import time"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "setup-environment",
      "metadata": {},
      "source": [
       "<a id=\"setup-environment\"></a>\n",
       "## 3. Set Up Dataloop Environment\n",
       "\n",
       "Connect to the Dataloop platform and create or get an existing project to work with."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-project",
      "metadata": {},
      "outputs": [],
      "source": [
       "dl.setenv(\"prod\")\n",
       "if dl.token_expired():\n",
       "    dl.login()\n",
       "\n",
       "PROJECT_NAME = \"My Dfine Finetune Project\"\n",
       "project = dl.projects.create(project_name=PROJECT_NAME)\n",
       "print(f\"Working with project: {project.name} (ID: {project.id})\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "project-note",
      "metadata": {},
      "source": [
       "**Action Required:** In the cell above, replace `\"My Dfine Finetune Project\"` with the desired name for your Dataloop project. If a project with this name already exists, the SDK will retrieve it; otherwise, a new project will be created."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "install-dfine-dpk",
      "metadata": {},
      "source": [
       "<a id=\"install-dfine-dpk\"></a>\n",
       "## 4. Install D-FINE Model Package\n",
       "\n",
       "Install the D-FINE model package from the Dataloop marketplace. This will provide the model adapter and all necessary dependencies.\n",
       "\n",
       "**Note:** If a D-FINE DPK is not yet available in the marketplace, we'll create a model entity directly and use the model adapter pattern. This section shows both approaches."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "install-dpk",
      "metadata": {},
      "outputs": [],
      "source": [
       "print(\"Loading D-FINE app from marketplace...\")\n",
       "dfine_dpk = dl.dpks.get(dpk_name=\"dfine-xlarge-obj2coco-huggingface-app\")\n",
       "dfine_app = project.apps.install(dpk=dfine_dpk)\n",
       "print(f\"D-FINE App installed: {dfine_app.name} (ID: {dfine_app.id})\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "configure-dfine-model",
      "metadata": {},
      "source": [
       "<a id=\"configure-dfine-model\"></a>\n",
       "## 5. Load Base D-FINE Model\n",
       "\n",
       "Load the D-FINE model entity from the installed app. This model will serve as the base for fine-tuning."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-base-model",
      "metadata": {},
      "outputs": [],
      "source": [
       "base_model = project.models.get(model_name='dfine-xlarge-obj2coco-huggingface-model')"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "prepare-dataset",
      "metadata": {},
      "source": [
       "<a id=\"prepare-dataset\"></a>\n",
       "## 6. Prepare Dataset\n",
       "\n",
       "Now prepare a dataset with images for object detection. We'll install one from the marketplace and split the dataset for ML subsets."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-dataset",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Install dataset from marketplace\n",
       "dataset_dpk = dl.dpks.get(dpk_name=\"military-assets-dataset\")\n",
       "dataset_app = project.apps.install(dpk=dataset_dpk)\n",
       "print(f\"Dataset app installed: {dataset_app.name}\")\n",
       "\n",
       "# Wait for dataset to fully load\n",
       "dataset = project.datasets.get(dataset_name=\"Military Assets Dataset\")\n",
       "while dataset.items.list().items_count < 200:\n",
       "    print(f\"Loading dataset... ({dataset.items.list().items_count}/200 items)\")\n",
       "    time.sleep(60)\n",
       "    dataset = project.datasets.get(dataset_name=\"Military Assets Dataset\")\n",
       "\n",
       "print(f\"Dataset ready with {dataset.items.list().items_count} items\")\n",
       "\n",
       "# Split into train/validation/test subsets\n",
       "dataset.split_ml_subsets(percentages={'train': 80, 'validation': 10, 'test': 10})"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "configure-model-training",
      "metadata": {},
      "source": [
       "<a id=\"configure-model-training\"></a>\n",
       "## 7. Configure Model for Training\n",
       "\n",
       "Configure the model metadata with dataset subsets and training parameters. The subset filters tell the model which items to use for training and validation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "configure-training",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Configure model metadata and subsets\n",
       "base_model.metadata[\"system\"] = {}\n",
       "base_model.metadata[\"system\"][\"subsets\"] = {}\n",
       "\n",
       "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
       "val_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
       "\n",
       "base_model.metadata[\"system\"][\"subsets\"][\"train\"] = train_filters.prepare()\n",
       "base_model.metadata[\"system\"][\"subsets\"][\"validation\"] = val_filters.prepare()\n",
       "\n",
       "# Set model configuration (optional)\n",
       "base_model.configuration = {\n",
       "  \"image_size\": 640,\n",
       "  \"confidence_threshold\": 0.25,\n",
       "  \"image_processor_path\": \"ustc-community/dfine-xlarge-obj2coco\",\n",
       "  \"pooling_method\": \"max\",\n",
       "  \"augmentation_config\": {\n",
       "    \"rotate_limit\": 15,\n",
       "    \"rotate_p\": 0.5,\n",
       "    \"perspective_p\": 0.1,\n",
       "    \"horizontal_flip_p\": 0.5,\n",
       "    \"brightness_contrast_p\": 0.5,\n",
       "    \"hue_saturation_p\": 0.1\n",
       "  },\n",
       "  \"train_configs\": {\n",
       "    \"per_device_train_batch_size\": 8,\n",
       "    \"per_device_eval_batch_size\": 8,\n",
       "    \"gradient_accumulation_steps\": 1,\n",
       "    \"learning_rate\": 0.00005,\n",
       "    \"weight_decay\": 0,\n",
       "    \"num_train_epochs\": 3,\n",
       "    \"warmup_steps\": 300,\n",
       "    \"max_grad_norm\": 0.1,\n",
       "    \"logging_steps\": 50,\n",
       "    \"save_strategy\": \"epoch\",\n",
       "    \"eval_strategy\": \"epoch\",\n",
       "    \"fp16\": False,\n",
       "    \"metric_for_best_model\": \"eval_loss\",\n",
       "    \"greater_is_better\": False\n",
       "  }\n",
       "}"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "clone-train-model",
      "metadata": {},
      "source": [
       "<a id=\"clone-train-model\"></a>\n",
       "## 8. Clone Model and Start Training\n",
       "\n",
       "Clone the base model to create a new model entity linked to your dataset, then start the training process. The cloned model will inherit the configuration from the base model."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "train-model",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Clone base model and start training\n",
       "finetuned_model = base_model.clone(\n",
       "    model_name=base_model.name + \"-finetuned\",\n",
       "    dataset=dataset\n",
       ")\n",
       "print(f\"Created model: {finetuned_model.name} (ID: {finetuned_model.id})\")\n",
       "\n",
       "# Train and wait for completion\n",
       "execution = finetuned_model.train()\n",
       "print(f\"Training started (execution: {execution.id})\")\n",
       "\n",
       "execution.wait()\n",
       "finetuned_model = project.models.get(model_id=finetuned_model.id)\n",
       "print(f\"Training complete. Model status: {finetuned_model.status}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "deploy-service",
      "metadata": {},
      "source": [
       "<a id=\"deploy-service\"></a>\n",
       "## 9. Deploy Model as Service\n",
       "\n",
       "Deploy the trained model as a service on the Dataloop platform to enable real-time inference. This allows you to run predictions on-demand through API calls."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "deploy-model",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Deploy the trained model as a service\n",
       "service = finetuned_model.deploy()\n",
       "print(f\"Deployment started (service: {service.id})\")\n",
       "\n",
       "# Wait for deployment to complete\n",
       "while finetuned_model.status != dl.ModelStatus.DEPLOYED:\n",
       "    time.sleep(30)\n",
       "    finetuned_model = project.models.get(model_id=finetuned_model.id)\n",
       "\n",
       "print(f\"Model deployed. Service: {service.name}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "test-deployed",
      "metadata": {},
      "source": [
       "<a id=\"test-deployed\"></a>\n",
       "## 10. Test Deployed Model\n",
       "\n",
       "Test the deployed model service by running predictions on images. Since the model is now deployed, predictions will run through the service."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "test-predictions",
      "metadata": {},
      "outputs": [],
      "source": [
       "# Run predictions on test items\n",
       "test_filters = dl.Filters(field=\"metadata.system.tags.test\", values=True)\n",
       "test_items = list(dataset.items.list(filters=test_filters).all())[:3]\n",
       "\n",
       "execution = finetuned_model.predict(item_ids=[item.id for item in test_items])\n",
       "print(f\"Running predictions on {len(test_items)} items...\", end=\"\", flush=True)\n",
       "\n",
       "# Wait for execution with progress updates using Dataloop's in_progress() method\n",
       "while execution.in_progress():\n",
       "    status = execution.get_latest_status()['status']\n",
       "    print(f\" {status}...\", end=\"\", flush=True)\n",
       "    time.sleep(5)\n",
       "    execution = dl.executions.get(execution_id=execution.id)\n",
       "\n",
       "print(\" done\")\n",
       "\n",
       "# Show results\n",
       "test_item = dataset.items.get(item_id=test_items[0].id)\n",
       "annotations = test_item.annotations.list()\n",
       "print(f\"Item: {test_item.name} - {len(annotations)} detections\")\n",
       "for ann in annotations[:5]:\n",
       "    if ann.type == dl.AnnotationType.BOX:\n",
       "        print(f\"  - {ann.label}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "extract-embeddings",
      "metadata": {},
      "source": [
       "<a id=\"extract-embeddings\"></a>\n",
       "## 11. Extract Embeddings (Optional)\n",
       "\n",
       "The D-FINE model can extract feature embeddings from images, which can be used for similarity search and retrieval tasks. This section shows how to extract embeddings from the deployed model."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "debug-setup",
      "metadata": {},
      "outputs": [],
      "source": [
       "# FOR DEBUGGING - Reconnect to existing resources if needed\n",
       "FINETUNED_MODEL_NAME=\"dfine-xlarge-obj2coco-huggingface-model-finetuned-7e89f\"\n",
       "import dtlpy as dl\n",
       "import time\n",
       "if dl.token_expired():\n",
       "    dl.login()\n",
       "dl.setenv(\"prod\")\n",
       "project = dl.projects.get(\"My Dfine Finetune Project\")\n",
       "base_model = project.models.get(model_name='dfine-xlarge-obj2coco-huggingface-model')\n",
       "try:\n",
       "    finetuned_model = project.models.get(model_name=FINETUNED_MODEL_NAME)\n",
       "except Exception:\n",
       "    print(\"No finetuned model created yet, create first\")\n",
       "dataset = project.datasets.get(dataset_name=\"Military Assets Dataset\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "extract-features",
      "metadata": {},
      "outputs": [],
      "source": [
       "# The model.embed() method extracts feature vectors from items and stores them\n",
       "# in a feature set associated with the model. \n",
       "\n",
       "# Get test items to extract embeddings from\n",
       "test_filters = dl.Filters(field=\"metadata.system.tags.test\", values=True)\n",
       "test_items = list(dataset.items.list(filters=test_filters).all())[:5]  # Get 5 test items\n",
       "\n",
       "print(f\"Extracting embeddings for {len(test_items)} items...\")\n",
       "\n",
       "# Extract embeddings using the model's embed method\n",
       "# This creates an execution that processes items and stores embeddings in a feature set\n",
       "item_ids = [item.id for item in test_items]\n",
       "execution = finetuned_model.embed(item_ids=item_ids)\n",
       "\n",
       "# Wait for the embedding extraction to complete\n",
       "execution.wait()\n",
       "print(f\"Embedding extraction completed. Execution status: {execution.status[-1]['status']}\")\n",
       "\n",
       "# Access the feature set associated with this model\n",
       "# Each model has one feature set that stores all generated embeddings\n",
       "feature_set = finetuned_model.feature_set\n",
       "print(f\"\\nFeature Set Details:\")\n",
       "print(f\"  Name: {feature_set.name}\")\n",
       "print(f\"  Size (dimensions): {feature_set.size}\")\n",
       "print(f\"  Entity type: {feature_set.entity_type}\")\n",
       "\n",
       "# List features in the feature set\n",
       "features_page = feature_set.features.list()\n",
       "print(f\"  Total features: {features_page.items_count}\")\n",
       "\n",
       "# Show sample feature vectors\n",
       "for feature in list(features_page.all())[:3]:\n",
       "    print(f\"\\n  Feature ID: {feature.id}\")\n",
       "    print(f\"  Entity ID: {feature.entity_id}\")\n",
       "    print(f\"  Vector (first 5 values): {feature.value[:5]}...\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
       "<a id=\"conclusion\"></a>\n",
       "## 12. Conclusion\n",
       "\n",
       "Congratulations! You have successfully fine-tuned the D-FINE object detection model with a custom dataset on the Dataloop platform.\n",
       "\n",
       "### What We Accomplished\n",
       "\n",
       "1. **Installed the D-FINE model package** from the Dataloop marketplace\n",
       "2. **Configured the model** with custom training parameters\n",
       "3. **Prepared and split a dataset** for training, validation, and testing\n",
       "4. **Trained the model** on your custom dataset\n",
       "5. **Deployed the model as a service** for real-time inference\n",
       "6. **Tested the deployed model** with predictions\n",
       "7. **Extracted embeddings** for similarity search applications\n",
       "\n",
       "### Next Steps\n",
       "\n",
       "- **Monitor Model Performance:** Check the model metrics and training logs in the Dataloop UI\n",
       "- **Improve Model Accuracy:** Experiment with different hyperparameters, data augmentation settings, or training epochs\n",
       "- **Scale Deployment:** Adjust service configuration (replicas, pod types) based on your inference workload\n",
       "- **Production Integration:** Use the deployed service API to integrate object detection into your applications\n",
       "\n",
       "### Additional Resources\n",
       "\n",
       "- [Dataloop Developer Documentation](https://developers.dataloop.ai/)\n",
       "- [Dataloop Model Management Guide](https://developers.dataloop.ai/tutorials/model_management/)\n",
       "- [Dataloop Service Deployment Guide](https://developers.dataloop.ai/tutorials/model_management/deploy/)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }