{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4194d0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Dataloop AI Advanced Embedding Processing Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide and a ready-to-use workflow for enhancing your datasets with advanced embedding techniques. By leveraging your existing data labels, you can generate more powerful and insightful data representations for visualization and similarity search.\n",
    "\n",
    "### Workflow Overview\n",
    "\n",
    "This guide will walk you through the following key stages:\n",
    "\n",
    "1. **[Setup and Configuration](#setup):** Installing dependencies and establishing a connection to the Dataloop platform. This section runs a fully automated setup to create a project and dataset for this tutorial.\n",
    "2. **[Option A: Label-Guided UMAP Embedding](#option-a):** A powerful technique for creating 3D embeddings that are visually clustered based on your data's labels. Ideal for data exploration and pattern discovery.\n",
    "3. **[Option B: Extended CLIP Embedding](#option-b):** A method to enrich existing CLIP feature vectors by appending binary information derived from your labels, significantly improving similarity search performance.\n",
    "4. **[Conclusion and Next Steps](#conclusion):** A summary of what you've accomplished and how to leverage your new, enhanced embeddings in the Dataloop platform.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Embedding Options at a Glance\n",
    "\n",
    "#### Option A: Label-Guided UMAP Embedding\n",
    "- **Purpose**: Creates low-dimensional (3D) embeddings that visually group items with similar labels.\n",
    "- **Best for**: Interactive visualization, understanding data structure, and discovering how labels relate to underlying features.\n",
    "- **Output**: A new Dataloop feature set with 3D coordinates, viewable in the platform's 3D data viewer.\n",
    "\n",
    "#### Option B: Extended CLIP Embedding  \n",
    "- **Purpose**: Augments high-dimensional CLIP features with explicit label data.\n",
    "- **Best for**: Powering more accurate similarity searches where both visual and label information are important.\n",
    "- **Output**: A new Dataloop feature set with enriched, high-dimensional vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-markdown-anchor",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup and Common Configuration\n",
    "\n",
    "**ğŸ“Œ Important:** This section must be run first, regardless of which embedding option you choose later. It handles package installation, connection to the Dataloop platform, and automated project setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571022c7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 1.1 Install Required Packages\n",
    "\n",
    "First, we'll install the necessary Python packages. These libraries are essential for interacting with the Dataloop platform (`dtlpy`), handling data (`pandas`), processing embeddings (`scikit-learn`), and performing dimensionality reduction (`umap-learn`). This step may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a02b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install dtlpy\n",
    "%pip install pandas\n",
    "%pip install bson\n",
    "%pip install python-rapidjson\n",
    "%pip install scikit-learn\n",
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28717bc0",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries and Define Helpers\n",
    "\n",
    "Next, we import the required libraries and define a helper function. This function, `ensure_feature_set`, simplifies the process of creating or retrieving a feature set in your Dataloop project, preventing errors if the feature set already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71148349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import dtlpy as dl\n",
    "import numpy as np\n",
    "import os\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ensure_feature_set(project: dl.Project, feature_set_name, dim, set_type):\n",
    "    \"\"\"\n",
    "    Create or get an existing feature set in the project.\n",
    "    \n",
    "    Args:\n",
    "        project: Dataloop project object\n",
    "        feature_set_name: Name for the feature set\n",
    "        dim: Dimension/size of the feature vectors\n",
    "        set_type: Type of the feature set (e.g., '3d', 'embedding')\n",
    "    \n",
    "    Returns:\n",
    "        dl.FeatureSet: The created or existing feature set\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_set: dl.FeatureSet = project.feature_sets.create(\n",
    "            name=feature_set_name, \n",
    "            size=dim, \n",
    "            set_type=set_type, \n",
    "            entity_type=dl.FeatureEntityType.ITEM\n",
    "        )\n",
    "    except Exception as e:\n",
    "        feature_set: dl.FeatureSet = project.feature_sets.get(feature_set_name=feature_set_name)\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b0dc3",
   "metadata": {},
   "source": [
    "### 1.3 Automated Project and Dataset Setup\n",
    "\n",
    "This section fully automates the setup process within the Dataloop platform. It is designed to run without any manual input.\n",
    "\n",
    "**What this step does:**\n",
    "1. **Connects to Dataloop:** Establishes a connection to the platform, handling authentication if needed.\n",
    "2. **Creates a Project:** A new project named `My First Embeddings Project` is created to house our work.\n",
    "3. **Installs a Dataset App:** The `dataset-images-animals` Dataloop App (DPK) is installed from the Marketplace. This app automatically creates a sample dataset with images, annotations, and pre-computed CLIP embeddings.\n",
    "4. **Waits for Setup:** The script waits for the app's setup services to complete.\n",
    "5. **Extracts Configuration:** Finally, it retrieves the newly created `dataset_id` and the existing `feature_set_id` ('clip-feature-set'), which are essential for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3eb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— Step 1: Connect to Dataloop Environment\n",
    "print(\"ğŸ”— Step 1: Connecting to Dataloop...\")\n",
    "dl.setenv('prod')  # Set environment to RC (adjust if needed)\n",
    "if dl.token_expired():\n",
    "    print(\"ğŸ” Token expired, logging in...\")\n",
    "    dl.login()\n",
    "print(\"âœ… Successfully connected to Dataloop environment\")\n",
    "\n",
    "# ğŸ“ Step 2: Create New Project\n",
    "print(\"\\nğŸ“ Step 2: Creating project...\")\n",
    "project = dl.projects.create(project_name=\"My First Embeddings Project\")\n",
    "print(f\"âœ… Project loaded: '{project.name}' (ID: {project.id})\")\n",
    "\n",
    "# ğŸ“¦ Step 3: Install DPK\n",
    "print(\"\\nğŸ“¦ Step 3: Installing dataset app...\")\n",
    "dpk = dl.dpks.get(dpk_name='dataset-images-animals')\n",
    "app = project.apps.install(dpk=dpk, app_name=dpk.display_name)\n",
    "print(f\"âœ… DPK installed: '{dpk.display_name}' (Version: {dpk.version})\")\n",
    "\n",
    "# âš™ï¸ Step 4: Setup Services\n",
    "print(\"\\nâš™ï¸ Step 4: Configuring services...\")\n",
    "# Create a filter to get services belonging to the app\n",
    "filters = dl.Filters(resource=dl.FiltersResource.SERVICE)\n",
    "filters.add(field='packageId', values=dpk.id)\n",
    "\n",
    "# List the services with the specified filters\n",
    "services = [ser for ser in project.services.list(filters=filters).all()]\n",
    "service: dl.Service = services[0]\n",
    "print(f\"âœ… Service configured: '{service.name}' (ID: {service.id})\")\n",
    "\n",
    "# ğŸ” Step 5: Extract Configuration\n",
    "print(\"\\nğŸ” Step 5: Wait for execution to complete...\")\n",
    "execution = service.executions.list()[0][0]\n",
    "execution.wait()\n",
    "dataset_id = execution.input['dataset']['dataset_id']\n",
    "feature_set: dl.Feature = project.feature_sets.get(feature_set_name='clip-feature-set')\n",
    "\n",
    "print(f\"âœ… Configuration extracted successfully!\")\n",
    "print(f\"ğŸ“Š Dataset ID: {dataset_id}\")\n",
    "print(f\"ğŸ¯ Feature Set: '{feature_set.name}' (ID: {feature_set.id})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ Setup Complete! Use these values in the next steps:\")\n",
    "print(f\"   ğŸ“Š dataset_id: {dataset_id}\")\n",
    "print(f\"   ğŸ¯ feature_set_id: {feature_set.id}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f044810",
   "metadata": {},
   "source": [
    "### 1.4 Download Dataset and Extract Features\n",
    "\n",
    "This final setup step brings the data from the Dataloop platform to our local notebook environment. We use the SDK's `export` functionality to download a JSON representation of our dataset, which includes all items, their annotations (labels), and their pre-computed feature vectors.\n",
    "\n",
    "**What happens here:**\n",
    "1. An export job is created for the entire dataset.\n",
    "2. The job is configured to include feature vectors and annotations.\n",
    "3. The resulting JSON file is downloaded to a local `./export` directory.\n",
    "4. The script then loads this JSON file to confirm the export and count the number of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Configure export directory\n",
    "save_dir = \"./export\"  # Local directory for exported data\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ğŸ”„ Get dataset and export data\n",
    "dataset = dl.datasets.get(dataset_id=dataset_id)\n",
    "\n",
    "print(\"ğŸš€ Starting data export process...\")\n",
    "print(f\"ğŸ“ Dataset: {dataset.name}\")\n",
    "print(f\"ğŸ’¾ Save directory: {save_dir}\")\n",
    "\n",
    "# ğŸ“¤ Export dataset with feature vectors and annotations using the simple export method\n",
    "print(\"ğŸ“¤ Exporting dataset with feature vectors and annotations...\")\n",
    "export_result = dataset.export(\n",
    "    local_path=save_dir,\n",
    "    include_feature_vectors=True,\n",
    "    include_annotations=True,\n",
    "    export_type='json',\n",
    "    timeout=0  # No timeout - wait until complete\n",
    ")\n",
    "\n",
    "print(\"â³ Export completed...\")\n",
    "print(f\"ğŸ“¥ Export result: {export_result}\")\n",
    "\n",
    "# The export returns the directory path, we need to find the actual JSON file\n",
    "data_file = None\n",
    "\n",
    "# Look for JSON files in the export directory\n",
    "json_files = [f for f in os.listdir(export_result) if f.endswith('.json')]\n",
    "data_file = os.path.join(export_result, json_files[0])\n",
    "print(f\"ğŸ“Š Found JSON file: {data_file}\")\n",
    "print(f\"ğŸ“Š Data file: {data_file}\")\n",
    "\n",
    "# Count items in the export\n",
    "with open(data_file, 'r') as f:\n",
    "    exported_data = json.load(f)\n",
    "    items_count = len(exported_data)\n",
    "\n",
    "print(\"âœ… Data export completed successfully!\")\n",
    "print(f\"ğŸ“Š Total items exported: {items_count}\")\n",
    "print(\"ğŸ“‹ You can now proceed to choose your embedding option below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b245f2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"option-a\"></a>\n",
    "## 2. Option A: Label-Guided UMAP Embedding\n",
    "\n",
    "**Choose this option if your goal is to create meaningful 3D visualizations of your data.** This technique uses the UMAP algorithm in a supervised mode, leveraging your annotation labels to guide the dimensionality reduction process. The result is an embedding where items with similar labels are positioned closer together in the 3D space.\n",
    "\n",
    "### How it Works:\n",
    "1. **Input**: Takes the existing high-dimensional feature vectors (e.g., from CLIP) and the corresponding annotation labels for each item.\n",
    "2. **Process**: The UMAP algorithm is trained on both the features and the labels simultaneously. The `target_weight` parameter controls how strongly the labels influence the final layout.\n",
    "3. **Output**: A new 3D coordinate for each item, plus a set of 2D scatter plot images (one for each label) saved locally for quick inspection.\n",
    "4. **Result**: A new Dataloop feature set containing these 3D embeddings, which can be visualized directly on the platform.\n",
    "\n",
    "**ğŸ’¡ Tip**: Experiment with the UMAP parameters (`n_neighbors`, `min_dist`, `target_weight`) in the code to see how they affect the clustering and separation of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "option-a-step1-markdown",
   "metadata": {},
   "source": [
    "### 2.1 Configure Feature Set Name\n",
    "\n",
    "First, specify the name for the new UMAP feature set that will be created in your Dataloop project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7705431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ·ï¸ Configure the name for your new UMAP feature set\n",
    "# This will be created in your Dataloop project\n",
    "new_feature_set_name = \"umap-label-enhanced\"\n",
    "\n",
    "print(f\"âœ… Feature set name configured: {new_feature_set_name}\")\n",
    "print(\"ğŸ“‹ This will create a new feature set with 3D UMAP embeddings in your project, optimized to separate by labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8d506",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.2 Generate Label-Guided UMAP Embeddings\n",
    "\n",
    "This code cell executes the entire UMAP generation workflow. It will:\n",
    "1. **Load data** from the exported JSON file, extracting the features and labels.\n",
    "2. **Prepare labels** by converting them into a binary format suitable for supervised UMAP.\n",
    "3. **Run the UMAP algorithm** with the specified parameters to generate 3D embeddings.\n",
    "4. **Generate and save visualizations** as PNG files, showing the distribution of each label in the 2D plane.\n",
    "5. **Upload the new embeddings** back to your Dataloop project under the feature set name you configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ab30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Step 1: Loading and processing data...\")\n",
    "\n",
    "# ğŸ“Š Load data from exported file\n",
    "items = dict()\n",
    "with open(data_file, 'r') as f:\n",
    "    exported_data = json.load(f)\n",
    "    \n",
    "    # Handle different export formats\n",
    "    if isinstance(exported_data, dict) and 'items' in exported_data:\n",
    "        items_list = exported_data['items']\n",
    "    elif isinstance(exported_data, list):\n",
    "        items_list = exported_data\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected export format\")\n",
    "    \n",
    "    # Process each item\n",
    "    for item in items_list:\n",
    "        # Only process annotated items\n",
    "        if not item.get('annotated', False):\n",
    "            continue\n",
    "        \n",
    "        # Extract feature vectors and labels\n",
    "        if item.get(\"itemVectors\") and len(item.get(\"itemVectors\", [])) > 0:\n",
    "            # Find the feature vector for the current feature set\n",
    "            feature_vector = None\n",
    "            for vector in item[\"itemVectors\"]:\n",
    "                if vector.get('featureSetId') == feature_set.id:\n",
    "                    feature_vector = vector.get('value')\n",
    "                    break\n",
    "            \n",
    "            if feature_vector is None:\n",
    "                # Try to get the first available vector if specific feature set not found\n",
    "                feature_vector = item[\"itemVectors\"][0].get('value')\n",
    "            \n",
    "            if feature_vector is not None:\n",
    "                labels = [ann['label'] for ann in item.get(\"annotations\", [])]\n",
    "                items[item[\"id\"]] = {\"features\": feature_vector, \"labels\": labels}\n",
    "\n",
    "print(f\"ğŸ“‹ Loaded {len(items)} annotated items with feature vectors\")\n",
    "\n",
    "# ğŸ”„ Step 2: Prepare data for UMAP\n",
    "print(\"ğŸ”„ Step 2: Preparing labels for supervised learning...\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "features = np.array([v[\"features\"] for v in items.values()])\n",
    "labels = [v[\"labels\"] for v in items.values()]  # keep as list for multi-label processing\n",
    "\n",
    "# Convert labels to binary format for UMAP\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(labels)\n",
    "\n",
    "print(f\"âœ… Feature matrix shape: {features.shape}\")\n",
    "print(f\"âœ… Label matrix shape: {y.shape}\")\n",
    "print(f\"âœ… Unique labels found: {list(mlb.classes_)}\")\n",
    "\n",
    "# ğŸ”„ Step 3: Run UMAP algorithm\n",
    "print(\"ğŸ”„ Step 3: Running UMAP algorithm (this may take several minutes)...\")\n",
    "\n",
    "# Configure UMAP with label guidance\n",
    "dumap = umap.UMAP(\n",
    "    n_components=3,           # Create 3D embeddings\n",
    "    n_neighbors=50,           # Controls local vs global structure (try 15, 30, 50, 100)\n",
    "    min_dist=0.1,            # Controls cluster tightness (try 0.0, 0.1, 0.3, 0.5)\n",
    "    metric=\"cosine\",         # Distance metric for features\n",
    "    target_metric=\"jaccard\",  # Distance metric for labels\n",
    "    target_weight=0.7,       # How much labels influence embedding (try 0.5, 0.7, 0.9)\n",
    "    verbose=True,            # Show progress\n",
    "    random_state=42          # For reproducible results\n",
    ")\n",
    "\n",
    "# Generate embeddings\n",
    "embedding = dumsap.fit_transform(features, y=y)\n",
    "print(f\"âœ… Generated {embedding.shape[0]} embeddings with {embedding.shape[1]} dimensions\")\n",
    "\n",
    "# ğŸ”„ Step 4: Create visualizations\n",
    "print(\"ğŸ”„ Step 4: Creating visualization plots...\")\n",
    "\n",
    "# Create visualizations for each label\n",
    "for idx, label in enumerate(mlb.classes_):\n",
    "    mask = y[:, idx] == 1  # Items with this label\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(embedding[~mask, 0], embedding[~mask, 1], \n",
    "                c='lightgray', alpha=0.5, s=30, label=f'Other items')\n",
    "    plt.scatter(embedding[mask, 0], embedding[mask, 1], \n",
    "                c='red', alpha=0.8, s=50, label=f'{label} items')\n",
    "    \n",
    "    plt.title(f\"UMAP Embedding: '{label}' Distribution\", fontsize=14)\n",
    "    plt.xlabel(\"UMAP Dimension 1\", fontsize=12)\n",
    "    plt.ylabel(\"UMAP Dimension 2\", fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Save plot\n",
    "    plot_filename = f\"{save_dir}/umap_visualization_{label.replace(' ', '_')}.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ğŸ“Š Saved visualization for '{label}' -> {plot_filename}\")\n",
    "\n",
    "print(\"âœ… All visualizations saved successfully!\")\n",
    "\n",
    "# ğŸ”„ Step 5: Prepare embeddings for upload\n",
    "print(\"ğŸ”„ Step 5: Preparing embeddings for upload to Dataloop...\")\n",
    "\n",
    "# Match embeddings back to item IDs\n",
    "to_upload = {}\n",
    "for indx, key in enumerate(items.keys()):\n",
    "    to_upload[key] = embedding[indx].tolist()\n",
    "\n",
    "# Create feature set in Dataloop\n",
    "feature_set_umap = ensure_feature_set(project, new_feature_set_name, 3, \"3d\")\n",
    "print(f\"âœ… Feature set '{new_feature_set_name}' ready in project\")\n",
    "\n",
    "# ğŸ”„ Step 6: Upload embeddings\n",
    "print(\"ğŸ”„ Step 6: Uploading embeddings to Dataloop...\")\n",
    "\n",
    "def upload_single(feature_set, item, value, pbar):\n",
    "    \"\"\"Upload a single feature vector to Dataloop\"\"\"\n",
    "    try:\n",
    "        feature_set.features.create(value=value, entity=item)\n",
    "        pbar.update(1)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error uploading feature for {item.id}: {e}\")\n",
    "        pbar.update(1)\n",
    "        return False\n",
    "\n",
    "# Upload with progress tracking\n",
    "with tqdm(total=len(to_upload), desc=\"ğŸ“¤ Uploading UMAP embeddings\") as pbar:\n",
    "    pool = ThreadPoolExecutor(max_workers=50)\n",
    "    futures = []\n",
    "    \n",
    "    for item_id, feature in to_upload.items():\n",
    "        item = dataset.items.get(item_id=item_id, fetch=False)\n",
    "        future = pool.submit(upload_single, feature_set_umap, item, feature, pbar)\n",
    "        futures.append(future)\n",
    "    \n",
    "    # Wait for all uploads to complete\n",
    "    successful_uploads = sum(1 for future in futures if future.result())\n",
    "    pool.shutdown(wait=True)\n",
    "\n",
    "print(f\"âœ… UMAP embedding generation completed!\")\n",
    "print(f\"ğŸ“Š Feature set '{new_feature_set_name}' created with 3D embeddings\")\n",
    "print(f\"ğŸ“ Visualizations saved in: {save_dir}\")\n",
    "print(f\"ğŸ¯ Total items processed: {len(to_upload)}\")\n",
    "print(f\"âœ… Successfully uploaded: {successful_uploads}/{len(to_upload)}\")\n",
    "print(\"\\nğŸ‰ Your label-guided UMAP embeddings are now available in Dataloop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b43afd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"option-b\"></a>\n",
    "## 3. Option B: Extended CLIP Embedding\n",
    "\n",
    "**Choose this option if your goal is to improve similarity search performance.** This technique enriches your existing high-dimensional CLIP vectors by appending binary information derived from your labels. This allows similarity searches to consider both visual features and explicit label data, leading to more accurate results.\n",
    "\n",
    "### How it Works:\n",
    "1. **Input**: Takes the existing high-dimensional CLIP feature vectors and the annotation labels for each item.\n",
    "2. **Process**: First, all unique labels across the dataset are identified. For each item, a binary vector is created where each position corresponds to a unique label (1 if present, 0 if absent). This binary vector is then concatenated to the end of the item's original CLIP vector.\n",
    "3. **Output**: A new, higher-dimensional feature vector for each item.\n",
    "4. **Result**: A new Dataloop feature set containing these extended embeddings, ready to be used for enhanced similarity search.\n",
    "\n",
    "**ğŸ’¡ Example**: If your original CLIP features are 512-dimensional and you have 10 unique labels in your dataset, the new extended features will be 522-dimensional (512 + 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "option-b-step1-markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configure Feature Set Name\n",
    "\n",
    "First, specify the name for the new extended CLIP feature set that will be created in your Dataloop project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2659dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ·ï¸ Configure the name for your new extended CLIP feature set\n",
    "# This will be created in your Dataloop project\n",
    "new_feature_set_name = \"extended-clip\"\n",
    "\n",
    "print(f\"âœ… Feature set name configured: {new_feature_set_name}\")\n",
    "print(\"ğŸ“‹ This will create a new feature set with extended CLIP embeddings in your project.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94c92e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 3.2 Generate Extended CLIP Embeddings\n",
    "\n",
    "This code cell executes the entire workflow for creating extended CLIP embeddings. It will:\n",
    "1. **Analyze the dataset** to find all unique labels available.\n",
    "2. **Create a binary vector** for each item, representing the presence or absence of each unique label.\n",
    "3. **Concatenate** the original CLIP feature vector with the new label binary vector for each item.\n",
    "4. **Upload the new, extended embeddings** back to your Dataloop project under the feature set name you configured.\n",
    "\n",
    "**â±ï¸ Processing time**: This process is generally much faster than UMAP as it does not involve complex model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ddf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_binary_vector(all_labels, sample_labels):\n",
    "    \"\"\"\n",
    "    Create a binary vector indicating the presence of each label from all_labels\n",
    "    in sample_labels.\n",
    "\n",
    "    Args:\n",
    "        all_labels (list): List of all possible labels.\n",
    "        sample_labels (list): Labels for the current sample (may contain duplicates).\n",
    "\n",
    "# List the services with the specified filters\n",
    "    Returns:\n",
    "        list: Binary vector (list of 0/1).\n",
    "    \"\"\"\n",
    "    sample_set = set(sample_labels)\n",
    "    return [int(label in sample_set) for label in all_labels]\n",
    "\n",
    "print(\"ğŸ”„ Step 1: Analyzing dataset to find all unique labels...\")\n",
    "\n",
    "# ğŸ“Š Load data from exported file\n",
    "with open(data_file, 'r') as f:\n",
    "    exported_data = json.load(f)\n",
    "    \n",
    "# Handle different export formats\n",
    "if isinstance(exported_data, dict) and 'items' in exported_data:\n",
    "    items_list = exported_data['items']\n",
    "elif isinstance(exported_data, list):\n",
    "    items_list = exported_data\n",
    "else:\n",
    "    raise ValueError(\"Unexpected export format\")\n",
    "\n",
    "# ğŸ” Find all unique labels in the dataset\n",
    "all_labels = set()\n",
    "for item in items_list:\n",
    "    for annotation in item.get(\"annotations\", []):\n",
    "        all_labels.add(annotation.get(\"label\"))\n",
    "\n",
    "all_labels = list(sorted(all_labels))  # Sort for consistent ordering\n",
    "print(f\"âœ… Found {len(all_labels)} unique labels: {all_labels}\")\n",
    "\n",
    "print(\"ğŸ”„ Step 2: Processing items and creating extended embeddings...\")\n",
    "\n",
    "# ğŸ“Š Process each item and create extended embeddings\n",
    "all_processed_data = {}\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "for item in items_list:\n",
    "    # Skip items without feature vectors\n",
    "    if not item.get(\"itemVectors\") or len(item.get(\"itemVectors\", [])) == 0:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Extract original feature vector\n",
    "    # Try to find the vector for the current feature set first\n",
    "    original_vector = None\n",
    "    for vector in item[\"itemVectors\"]:\n",
    "        if vector.get('featureSetId') == feature_set.id:\n",
    "            original_vector = vector.get(\"value\")\n",
    "            break\n",
    "    \n",
    "    # If not found, use the first available vector\n",
    "    if original_vector is None:\n",
    "        original_vector = item[\"itemVectors\"][0].get(\"value\")\n",
    "    \n",
    "    if original_vector is None:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    # Extract labels for this item\n",
    "    item_labels = [annotation.get(\"label\") for annotation in item.get(\"annotations\", [])]\n",
    "    \n",
    "    # Create binary label vector\n",
    "    label_binary_vector = labels_to_binary_vector(all_labels, item_labels)\n",
    "    \n",
    "    # Concatenate original features with label binary vector\n",
    "    extended_vector = np.concatenate([original_vector, label_binary_vector])\n",
    "    \n",
    "    # Store processed data\n",
    "    all_processed_data[item.get(\"id\")] = {\n",
    "        \"item_vector_data\": extended_vector,\n",
    "        \"annotations_labels\": item_labels,\n",
    "        \"id\": item.get(\"id\")\n",
    "    }\n",
    "    processed_count += 1\n",
    "\n",
    "print(f\"âœ… Successfully processed {processed_count} items\")\n",
    "print(f\"âš ï¸  Skipped {skipped_count} items (missing feature vectors)\")\n",
    "\n",
    "# Show dimension information\n",
    "if all_processed_data:\n",
    "    sample_vector = next(iter(all_processed_data.values()))[\"item_vector_data\"]\n",
    "    original_dim = len(sample_vector) - len(all_labels)\n",
    "    print(f\"ğŸ“Š Original feature dimension: {original_dim}\")\n",
    "    print(f\"ğŸ“Š Label dimension: {len(all_labels)}\")\n",
    "    print(f\"ğŸ“Š Extended feature dimension: {len(sample_vector)}\")\n",
    "    print(f\"ğŸ’¡ Extension ratio: {len(sample_vector)/original_dim:.2f}x original size\")\n",
    "\n",
    "def add_vector_to_feature_set(args):\n",
    "    \"\"\"\n",
    "    Adds a vector to the feature set for a single item.\n",
    "    Args:\n",
    "        args: Tuple (item_id, value, dataset, feature_set)\n",
    "    Returns:\n",
    "        (item_id, success) tuple for tracking\n",
    "    \"\"\"\n",
    "    item_id, value, dataset, feature_set = args\n",
    "    try:\n",
    "        item = dataset.items.get(item_id=item_id)\n",
    "        feature_set.features.create(\n",
    "            value=value['item_vector_data'].tolist(),\n",
    "            entity=item\n",
    "        )\n",
    "        return item_id, True\n",
    "    except Exception as e:\n",
    "        # Optionally log the exception: print(f\"Failed {item_id}: {e}\")\n",
    "        return item_id, False\n",
    "\n",
    "def add_all_vectors_parallel(all_processed_data, dataset, feature_set, max_workers=8):\n",
    "    \"\"\"\n",
    "    Add all vectors to the feature set in parallel.\n",
    "    Args:\n",
    "        all_processed_data (dict): Dict of item_id -> vector_data\n",
    "        dataset: Dataloop dataset instance\n",
    "        feature_set: Dataloop feature_set instance\n",
    "        max_workers (int): Number of threads\n",
    "\n",
    "    Returns:\n",
    "        (success_ids, failed_ids)\n",
    "    \"\"\"\n",
    "    args_iter = [\n",
    "        (item_id, value, dataset, feature_set)\n",
    "        for item_id, value in all_processed_data.items()\n",
    "    ]\n",
    "    success_ids = []\n",
    "    failed_ids = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(add_vector_to_feature_set, args): args[0] for args in args_iter}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"ğŸ“¤ Uploading extended CLIP embeddings\"):\n",
    "            item_id, success = future.result()\n",
    "            if success:\n",
    "                success_ids.append(item_id)\n",
    "            else:\n",
    "                failed_ids.append(item_id)\n",
    "    return success_ids, failed_ids\n",
    "\n",
    "print(\"\\nğŸ”„ Step 3: Creating extended feature set and uploading embeddings...\")\n",
    "\n",
    "# Create the extended feature set\n",
    "original_feature_set = dl.feature_sets.get(feature_set_id=feature_set.id)\n",
    "extended_dim = original_feature_set.size + len(all_labels)\n",
    "extended_feature_set = ensure_feature_set(\n",
    "    project, \n",
    "    new_feature_set_name, \n",
    "    extended_dim, \n",
    "    original_feature_set.set_type + \"-extended\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Created feature set '{new_feature_set_name}' with dimension {extended_dim}\")\n",
    "\n",
    "# Upload all vectors in parallel\n",
    "success_ids, failed_ids = add_all_vectors_parallel(\n",
    "    all_processed_data, \n",
    "    dataset, \n",
    "    extended_feature_set, \n",
    "    max_workers=50\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Extended CLIP embedding generation completed!\")\n",
    "print(f\"ğŸ“Š Feature set '{new_feature_set_name}' created with {extended_dim} dimensions\")\n",
    "print(f\"ğŸ¯ Successfully uploaded: {len(success_ids)}/{len(all_processed_data)}\")\n",
    "if failed_ids:\n",
    "    print(f\"âš ï¸  Failed uploads: {len(failed_ids)}\")\n",
    "print(\"\\nğŸ‰ Your extended CLIP embeddings are now available in Dataloop!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422c84f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "<a id=\"conclusion\"></a>\n",
    "## 4. Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You have successfully walked through the process of enhancing a dataset with advanced, label-aware embedding techniques. You have created one or two new feature sets in your Dataloop project, each tailored for a specific purpose.\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "**If you chose Option A (Label-Guided UMAP):**\n",
    "- You created a `3d` feature set (e.g., `umap-label-enhanced`).\n",
    "- These embeddings are optimized for visualization, where items with similar labels are clustered together.\n",
    "- **Next Step:** Navigate to the dataset in the Dataloop platform, go to the 'Embeddings' tab, select your new 3D feature set, and explore your data in the interactive 3D viewer.\n",
    "\n",
    "**If you chose Option B (Extended CLIP):**\n",
    "- You created a high-dimensional `embedding` feature set (e.g., `extended-clip`).\n",
    "- These embeddings are enriched with label information, making them ideal for more accurate similarity searches.\n",
    "- **Next Step:** Use the platform's similarity search feature (e.g., by right-clicking an item and selecting 'Find Similar'). Ensure you select your new extended feature set to power the search.\n",
    "\n",
    "### Further Actions\n",
    "\n",
    "*   **Downstream Tasks:** These new feature sets can be used as inputs for other machine learning models or pipelines.\n",
    "*   **Parameter Tuning:** Experiment with the parameters in the UMAP and Extended CLIP generation cells to see how they affect your results.\n",
    "*   **Automation:** Integrate this notebook's logic into a Dataloop FaaS (Function as a Service) to automatically generate enhanced embeddings whenever your dataset is updated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
