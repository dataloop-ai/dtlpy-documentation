{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "main-title",
   "metadata": {},
   "source": [
    "# End-to-End Model Workflow Tutorial\n",
    "\n",
    "This notebook provides a comprehensive, step-by-step guide for a complete model training workflow on the Dataloop platform. You'll learn how to set up datasets, create annotation tasks, train models, and deploy them for inference - all within a unified MLOps environment.\n",
    "\n",
    "This tutorial demonstrates the full machine learning lifecycle from data preparation through model deployment, showcasing how Dataloop integrates data management, annotation workflows, and model training into a seamless experience.\n",
    "\n",
    "### Prerequisites:\n",
    "* **Dataloop Account:** You should have access to a Dataloop platform account.\n",
    "* **Python Environment:** Ensure you have Python 3.7+ installed with pip.\n",
    "* **Project Access:** Ability to create projects and install apps from the Dataloop Marketplace.\n",
    "* **Basic ML Knowledge:** Understanding of machine learning concepts and model training workflows.\n",
    "\n",
    "### Navigate through the following sections:\n",
    "1. [Dependencies & Setup](#dependencies-setup)\n",
    "2. [Project & Dataset Preparation](#dataset-preparation)\n",
    "3. [Labeling Task Creation & Annotation](#labeling-task)\n",
    "4. [Model Training & Deployment](#model-training)\n",
    "5. [Conclusion and Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependencies-setup",
   "metadata": {},
   "source": [
    "## <a id='dependencies-setup'></a>1. Dependencies & Setup\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "First, let's ensure that the necessary Python libraries are installed. This notebook requires `dtlpy` for interacting with the Dataloop platform. The following cell will install or upgrade the library quietly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtlpy --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "Now, we import all the Python libraries that will be used throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "print(f\"Dataloop SDK Version: {dl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-environment",
   "metadata": {},
   "source": [
    "### Set Up Dataloop Environment\n",
    "\n",
    "To begin, we need to connect to the Dataloop platform. If you're not already logged in, running the cell below will prompt you to do so. Then, we'll either create a new project or get an existing one to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "login-dataloop",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dl.token_expired():\n",
    "   dl.login() # Opens browser for login\n",
    "   print(f\"Logged in successfully to {dl.client_api.environment}\")\n",
    "else:\n",
    "   print(f\"Session active for {dl.client_api.info()['user_email']} in {dl.client_api.environment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique name for your project or use the one you already have\n",
    "user_email = dl.info()['user_email']\n",
    "user_prefix = user_email.split('@')[0].replace('.', '').replace('-', '') # Simple prefix from email\n",
    "project_name = f'{user_prefix}-model-workflow'\n",
    "\n",
    "# Check if the project exists, if not, create it\n",
    "try:\n",
    "    project = dl.projects.get(project_name=project_name)\n",
    "    print(f\"Successfully retrieved project: '{project.name}' (ID: {project.id})\")\n",
    "except dl.exceptions.NotFound:\n",
    "    project = dl.projects.create(project_name=project_name)\n",
    "    print(f\"Successfully created project: '{project.name}' (ID: {project.id})\")\n",
    "\n",
    "print(f\"\\n> **Action Required:** Project name is set to '{project_name}'. Modify if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-preparation",
   "metadata": {},
   "source": [
    "## <a id='dataset-preparation'></a>2. Project & Dataset Preparation\n",
    "\n",
    "### Install Dataset from Marketplace\n",
    "\n",
    "For model training (like ResNet), we need a dataset with multiple classes. Here we will install the \"Agricultural Seedlings Dataset\" from the Dataloop App Marketplace. This Dataloop App (DPK) not only provides the dataset but also pre-installs the ResNet model package, which we will use later.\n",
    "\n",
    "The code below will install the app, retrieve the created dataset, and wait for the app's setup services to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-dataset-app",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ML Compare Solution DPK which includes the Agricultural Seedlings Dataset\n",
    "dpk = dl.dpks.get(dpk_name=\"ml-compare-solution\")\n",
    "app = project.apps.install(dpk=dpk)\n",
    "print(f\"Seedlings Datasets installed: [Name: {app.name}, ID: {app.id}]\")\n",
    "\n",
    "# Get the annotated dataset that was created by the app\n",
    "dataset = project.datasets.get(dataset_name=\"V2 Plant Seedlings - Annotated\")\n",
    "print(f\"Got Annotated Dataset: [Name: {dataset.name}, ID: {dataset.id}]\")\n",
    "\n",
    "# Wait for app services to complete setup\n",
    "filters = dl.Filters(resource=dl.FiltersResource.SERVICE, field=\"appId\", values=app.id)\n",
    "services = project.services.list(filters=filters)\n",
    "if isinstance(services, dl.entities.PagedEntities):\n",
    "    services = services.all()\n",
    "\n",
    "service: dl.Service\n",
    "print(\"Waiting for app services to finish, please wait...\")\n",
    "for service in services:\n",
    "    service_executions = service.executions.list()\n",
    "    if isinstance(service_executions, dl.entities.PagedEntities):\n",
    "        service_executions = service_executions.all()\n",
    "    for service_execution in tqdm(service_executions, desc=f\"Service {service.name}\"):\n",
    "        service_execution.wait()\n",
    "print(\"App services finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-dataset",
   "metadata": {},
   "source": [
    "### Split Dataset for Training\n",
    "\n",
    "For effective model training, it's crucial to split your dataset into training, validation, and test subsets. The Dataloop SDK provides a convenient method to do this by automatically tagging items. We will use an 80/10/10 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-dataset-subsets",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_PERCENTAGES = {'train': 80, 'validation': 10, 'test': 10}\n",
    "dataset.split_ml_subsets(percentages=SUBSET_PERCENTAGES)\n",
    "print(f\"Dataset split completed with {SUBSET_PERCENTAGES}\")\n",
    "print(f\"Total items in dataset: {dataset.items_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeling-task",
   "metadata": {},
   "source": [
    "## <a id='labeling-task'></a>3. Labeling Task Creation & Annotation\n",
    "\n",
    "### Select Items and Create Task\n",
    "\n",
    "In a real-world scenario, you might have a large dataset that needs annotation. Here, we'll simulate this by selecting a few items from each of our newly created subsets (train, validation, and test) and placing them into a labeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-items-for-task",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filters for each subset\n",
    "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
    "valid_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
    "test_filters = dl.Filters(field=\"metadata.system.tags.test\", values=True)\n",
    "\n",
    "# Select a small number of items from each subset for the task\n",
    "train_items = list(dataset.items.list(filters=train_filters).all())[:2]\n",
    "valid_items = list(dataset.items.list(filters=valid_filters).all())[:2]\n",
    "test_items = list(dataset.items.list(filters=test_filters).all())[:2]\n",
    "\n",
    "print(f\"Selected items for task:\")\n",
    "print(f\"Train items: {[item.filename for item in train_items]}\")\n",
    "print(f\"Valid items: {[item.filename for item in valid_items]}\")\n",
    "print(f\"Test items: {[item.filename for item in test_items]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-annotation-task",
   "metadata": {},
   "source": [
    "### Create Annotation Task\n",
    "\n",
    "Now we will create a new annotation task for these selected items. We will assign the task to ourselves for this tutorial. The task uses the dataset's `recipe`, which defines the set of possible labels (the ontology) for annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-task",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current user information\n",
    "your_user_email = dl.info()[\"user_email\"]\n",
    "\n",
    "# Define task parameters\n",
    "task_name = \"Model Training Task\"\n",
    "assignee_ids = [your_user_email]\n",
    "workload = dl.Workload.generate(assignee_ids=assignee_ids)\n",
    "task_owner = your_user_email\n",
    "recipe = dataset.recipes.list()[0]\n",
    "items = train_items + valid_items + test_items\n",
    "\n",
    "# Create the task\n",
    "task: dl.Task = project.tasks.create(\n",
    "    task_name=task_name, \n",
    "    assignee_ids=assignee_ids,\n",
    "    workload=workload,\n",
    "    dataset=dataset,\n",
    "    task_owner=task_owner,\n",
    "    recipe_id=recipe.id,\n",
    "    items=items\n",
    ")\n",
    "print(f\"Created Task: [Name: {task.name}, ID: {task.id}, Items Count: {task.total_items}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "get-assignment",
   "metadata": {},
   "source": [
    "### Get Task Assignment\n",
    "\n",
    "When a task is created, the system generates `assignments` for each assignee. Let's retrieve the assignment created for our user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-task-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment: dl.Assignment = task.assignments.list()[0]\n",
    "print(f\"Task assignment: [Name: {assignment.name}, ID: {assignment.id}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annotate-complete-task",
   "metadata": {},
   "source": [
    "### Annotate and Complete the Task Items\n",
    "\n",
    "The next stage involves creating annotations for the dataset items and marking them as completed. For this tutorial, we'll programmatically add classification annotations. The label for each annotation will be derived from the item's parent folder name.\n",
    "\n",
    "We'll use the script below to add annotations that are properly linked to both the task and assignment. Once annotated, we'll update the status of each item to `completed` to indicate it is ready for the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-available-labels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the following labels for our annotations\n",
    "available_labels = list(dataset.labels_flat_dict.keys())\n",
    "print(f\"Available labels in dataset: {available_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annotate-items",
   "metadata": {},
   "source": [
    "### Programmatically Annotate Items\n",
    "\n",
    "Now we will iterate through all items in the task, add annotations, and mark them as complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annotate-task-items",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all items in the task\n",
    "items = task.get_items()\n",
    "if isinstance(items, dl.entities.PagedEntities):\n",
    "    items = items.all()\n",
    "items = list(items)\n",
    "\n",
    "print(f\"Processing {len(items)} items in the task...\")\n",
    "\n",
    "item: dl.Item\n",
    "for item in tqdm(items, desc=\"Annotating items\"):\n",
    "    # Delete existing annotations on the item\n",
    "    filters = dl.Filters(resource=dl.FiltersResource.ANNOTATION)  # Filter is required to delete all annotations\n",
    "    item.annotations.delete(filters=filters)\n",
    "\n",
    "    # Creating new classification annotation based on the item folder name\n",
    "    builder = item.annotations.builder()\n",
    "    label = pathlib.Path(item.filename).parent.name\n",
    "    classification = dl.Classification(label=label, description=f\"Created by assignment {assignment.id}\")\n",
    "\n",
    "    # Linking the annotations to the task\n",
    "    metadata = {\n",
    "        \"system\": {\n",
    "            \"recipeId\": recipe.id,\n",
    "            \"taskId\": task.id,\n",
    "            \"assignmentId\": assignment.id\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Adding the annotations to the item\n",
    "    builder.add(\n",
    "        annotation_definition=classification,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    item.annotations.upload(builder)\n",
    "    \n",
    "    # Mark item as completed\n",
    "    item.update_status(\n",
    "        status=\"completed\", \n",
    "        assignment_id=assignment.id, \n",
    "        task_id=task.id\n",
    "    )\n",
    "    print(f\"Processed Item: [ID: {item.id}, Filename: {item.filename}, Label: {label}]\")\n",
    "\n",
    "print(f\"\\nCompleted annotation of {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-training",
   "metadata": {},
   "source": [
    "## <a id='model-training'></a>4. Model Training & Deployment\n",
    "\n",
    "### Configure Base Model\n",
    "\n",
    "With our data annotated, we can now begin the training process. We will retrieve the pre-trained ResNet model that was installed with the dataset DPK. We then configure it by specifying which data subsets to use for training and validation, and by setting key hyperparameters like the number of epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure-base-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pre-trained ResNet model\n",
    "base_model = project.models.get(model_name=\"pretrained-resnet\")\n",
    "print(f\"Retrieved base model: {base_model.name} (ID: {base_model.id})\")\n",
    "\n",
    "# Configure model metadata and subsets\n",
    "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
    "val_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
    "\n",
    "base_model.add_subset(\"train\", train_filters)\n",
    "base_model.add_subset(\"validation\", val_filters)\n",
    "\n",
    "# Set model configuration for ResNet training\n",
    "base_model.configuration = {\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "print(f\"Base model configured: {base_model.name}\")\n",
    "print(f\"Training configuration: {base_model.configuration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clone-train-model",
   "metadata": {},
   "source": [
    "### Clone and Train Model\n",
    "\n",
    "To fine-tune a model, we first `clone` the pre-trained model. This creates a new, trainable model entity in your project. We associate our dataset and its labels with this new model and then start the training process.\n",
    "\n",
    "> **NOTE**: The training process can take a significant amount of time, depending on your dataset size, model configuration, and the available compute resources (GPU type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the base model for fine-tuning\n",
    "finetuned_model_name = base_model.name + \"-finetuned\"\n",
    "labels = [label.tag for label in dataset.labels]\n",
    "finetuned_model = base_model.clone(model_name=finetuned_model_name, dataset=dataset, labels=labels)\n",
    "print(f\"Created new model for finetuning: [Name: {finetuned_model.name}, ID: {finetuned_model.id}]\")\n",
    "print(f\"Model will be trained on labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "start-training",
   "metadata": {},
   "source": [
    "### Start Model Training\n",
    "\n",
    "Now we'll initiate the training process and get the execution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "start-model-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting training for model: {finetuned_model.name}\")\n",
    "execution = finetuned_model.train()\n",
    "print(f\"Training execution started: [ID: {execution.id}, Status: {execution.status}]\")\n",
    "print(f\"You can monitor training progress in the Dataloop platform at: {finetuned_model.platform_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wait-for-training",
   "metadata": {},
   "source": [
    "### Wait for Training Completion\n",
    "\n",
    "The cell below will periodically check the status of the training execution and wait for it to complete. You can also monitor the training progress, view logs, and see performance metrics directly in the Dataloop platform by navigating to your model's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wait-training-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for training to complete\n",
    "print(\"Waiting for training to complete...\")\n",
    "start_time = time.time()\n",
    "\n",
    "while execution.in_progress():\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Training in progress... (Elapsed: {elapsed_time/60:.1f} minutes) - checking again in 2 minutes\")\n",
    "    time.sleep(120)  # Sleep for 2 minutes\n",
    "    execution = dl.executions.get(execution_id=execution.id)\n",
    "\n",
    "# Check final status\n",
    "final_status = execution.get_latest_status()['status']\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "if final_status == \"success\":\n",
    "    print(f\"Training completed successfully! (Total time: {total_time/60:.1f} minutes)\")\n",
    "    print(f\"Model ID: {finetuned_model.id}\")\n",
    "elif final_status == \"failed\":\n",
    "    print(f\"Training failed. Execution ID: {execution.id}. Check logs in Dataloop platform for details.\")\n",
    "else:\n",
    "    print(f\"Training ended with status: {final_status}. Execution ID: {execution.id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deploy-model",
   "metadata": {},
   "source": [
    "### Deploy the Trained Model\n",
    "\n",
    "Once training is complete, the final step is to deploy the fine-tuned model. Deployment creates a live service endpoint that can be used for inference on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deploy-trained-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training was successful before deploying\n",
    "if final_status == \"success\":\n",
    "    # Get the updated model entity\n",
    "    finetuned_model = project.models.get(model_id=finetuned_model.id)\n",
    "    \n",
    "    print(f\"Deploying model: {finetuned_model.name}\")\n",
    "    # Deploy the model\n",
    "    service = finetuned_model.deploy()\n",
    "    print(f\"Model deployed successfully: [Name: {service.name}, ID: {service.id}]\")\n",
    "    print(f\"Service status: {service.status}\")\n",
    "    \n",
    "    # Wait for deployment to complete\n",
    "    print(\"Waiting for deployment to complete...\")\n",
    "    while finetuned_model.status not in [dl.ModelStatus.DEPLOYED, dl.ModelStatus.FAILED]:\n",
    "        print(f\"Model status: {finetuned_model.status} - waiting...\")\n",
    "        time.sleep(30)\n",
    "        finetuned_model = project.models.get(model_id=finetuned_model.id)\n",
    "    \n",
    "    print(f\"Final model status: {finetuned_model.status}\")\n",
    "    if finetuned_model.status == dl.ModelStatus.DEPLOYED:\n",
    "        print(f\"🎉 Model successfully deployed and ready for inference!\")\n",
    "        print(f\"Model URL: {finetuned_model.platform_url}\")\n",
    "else:\n",
    "    print(\"Skipping deployment due to training failure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a>5. Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You have successfully walked through the entire process of an end-to-end model workflow on Dataloop.\n",
    "\n",
    "### Summary of What You've Accomplished:\n",
    "- **Environment Setup:** Connected to Dataloop and configured your project for machine learning workflows\n",
    "- **Dataset Preparation:** Installed a dataset from the Marketplace and prepared it for training by creating ML subsets (train/validation/test)\n",
    "- **Annotation Workflow:** Created a labeling task for a subset of data and programmatically annotated items with proper task linkage\n",
    "- **Model Configuration:** Retrieved and configured a pre-trained ResNet model with appropriate training parameters\n",
    "- **Model Training:** Cloned the base model, fine-tuned it on your annotated data, and monitored the training process\n",
    "- **Model Deployment:** Successfully deployed the trained model as a live service for inference\n",
    "- **MLOps Integration:** Experienced the complete machine learning lifecycle within a unified platform\n",
    "\n",
    "### Next Steps:\n",
    "From here, you can explore more advanced concepts:\n",
    "- **Model Inference:** Use your deployed model to make predictions on new items and evaluate its performance\n",
    "- **Pipeline Automation:** Create a full pipeline that automates this entire workflow for continuous model improvement\n",
    "- **Active Learning:** Explore active learning loops to intelligently select which items to annotate next based on model uncertainty\n",
    "- **Model Monitoring:** Set up monitoring and alerting for your deployed models to track performance over time\n",
    "- **A/B Testing:** Deploy multiple model versions and compare their performance on real data\n",
    "- **Advanced Workflows:** Integrate multiple models, create ensemble methods, or build complex multi-stage pipelines\n",
    "- **Custom Models:** Bring your own model architectures using Dataloop's model adapter framework\n",
    "\n",
    "### Additional Resources:\n",
    "- **[Active Learning Pipeline Tutorial](https://docs.dataloop.ai/docs/active-learning-pipeline):** Learn how to create intelligent annotation workflows\n",
    "- **[Model Management Documentation](https://developers.dataloop.ai/tutorials/model_management):** Explore advanced model management features\n",
    "- **[Pipeline Builder](https://developers.dataloop.ai/tutorials/pipelines):** Create automated ML workflows\n",
    "- **[Custom Model Adapters](https://developers.dataloop.ai/tutorials/model_management):** Integrate your own models into Dataloop\n",
    "\n",
    "This tutorial demonstrates the power of having an integrated MLOps platform where data management, annotation, training, and deployment work seamlessly together. You're now ready to build production-ready machine learning workflows on Dataloop!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
