{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# End-to-End Model Workflow Tutorial\n",
       "\n",
       "This notebook provides a comprehensive, step-by-step guide for a complete model training workflow on the Dataloop platform. We will start with dataset preparation, proceed to a labeling task, annotate the data, and finally train and deploy a model.\n",
       "\n",
       "### Overview\n",
       "\n",
       "This guide will walk you through the following key stages:\n",
       "\n",
       "1. **[Dependencies & Setup](#dependencies-setup):** Installing necessary libraries and connecting to your Dataloop environment.\n",
       "2. **[Project & Dataset Preparation](#dataset-preparation):** Setting up a Dataloop project, installing a dataset from the Marketplace, and splitting it for machine learning tasks.\n",
       "3. **[Labeling Task Creation & Annotation](#labeling-task):** Creating a task with a subset of data, assigning it for annotation, and programmatically completing the annotations.\n",
       "4. **[Model Training & Deployment](#model-training):** Configuring a pre-trained model, fine-tuning it on our annotated data, and deploying it as a live service.\n",
       "5. **[Conclusion & Next Steps](#conclusion):** Summarizing the process and suggesting further actions.\n",
       "\n",
       "Let's get started!"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## <a id='dependencies-setup'></a>1. Dependencies & Setup\n",
       "\n",
       "### Install Dependencies\n",
       "\n",
       "First, let's ensure that the necessary Python libraries are installed. This notebook requires `dtlpy` for interacting with the Dataloop platform. The following cell will install or upgrade the library quietly."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "!pip install dtlpy --upgrade --quiet"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Import Required Libraries\n",
       "\n",
       "Now, we import all the Python libraries that will be used throughout this tutorial."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import dtlpy as dl\n",
       "from tqdm import tqdm\n",
       "import pathlib\n",
       "import time"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Set Up Dataloop Environment\n",
       "\n",
       "To begin, we need to connect to the Dataloop platform. If you're not already logged in, running the cell below will prompt you to do so. Then, we'll either create a new project or get an existing one to work with."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if dl.token_expired():\n",
       "    dl.login()\n",
       "\n",
       "PROJECT_NAME = \"<your project name here>\"\n",
       "project = dl.projects.create(project_name=PROJECT_NAME)\n",
       "print(f\"Project created: [Name: {project.name}, ID: {project.id}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "> **Action Required:** In the cell above, replace `\"<your project name here>\"` with the desired name for your Dataloop project. If a project with this name already exists, the SDK will retrieve it; otherwise, a new project with this name will be created."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## <a id='dataset-preparation'></a>2. Project & Dataset Preparation\n",
       "\n",
       "### Install Dataset from Marketplace\n",
       "\n",
       "For model training (like ResNet), we need a dataset with multiple classes. Here we will install the \"Agricultural Seedlings Dataset\" from the Dataloop App Marketplace. This Dataloop App (DPK) not only provides the dataset but also pre-installs the ResNet model package, which we will use later.\n",
       "\n",
       "The code below will install the app, retrieve the created dataset, and wait for the app's setup services to complete."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "dpk = dl.dpks.get(dpk_name=\"ml-compare-solution\")\n",
       "app = project.apps.install(dpk=dpk)\n",
       "print(f\"Seedlings Datasets installed: [Name: {app.name}, ID: {app.id}]\")\n",
       "\n",
       "dataset = project.datasets.get(dataset_name=\"V2 Plant Seedlings - Annotated\")\n",
       "print(f\"Got Annotated Dataset: [Name: {dataset.name}, ID: {dataset.id}]\")\n",
       "\n",
       "filters = dl.Filters(resource=dl.FiltersResource.SERVICE, field=\"appId\", values=app.id)\n",
       "services = project.services.list(filters=filters)\n",
       "if isinstance(services, dl.entities.PagedEntities):\n",
       "    services = services.all()\n",
       "\n",
       "service: dl.Service\n",
       "print(\"Waiting for app services to finish, please wait...\")\n",
       "for service in services:\n",
       "    service_executions = service.executions.list()\n",
       "    if isinstance(service_executions, dl.entities.PagedEntities):\n",
       "        service_executions = service_executions.all()\n",
       "    for service_execution in tqdm(service_executions):\n",
       "        service_execution.wait()\n",
       "print(\"App services finished\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Split Dataset for Training\n",
       "\n",
       "For effective model training, it's crucial to split your dataset into training, validation, and test subsets. The Dataloop SDK provides a convenient method to do this by automatically tagging items. We will use an 80/10/10 split."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "SUBSET_PERCENTAGES = {'train': 80, 'validation': 10, 'test': 10}\n",
       "dataset.split_ml_subsets(percentages=SUBSET_PERCENTAGES)\n",
       "print(f\"Dataset split completed with {SUBSET_PERCENTAGES}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## <a id='labeling-task'></a>3. Labeling Task Creation & Annotation\n",
       "\n",
       "### Select Items and Create Task\n",
       "\n",
       "In a real-world scenario, you might have a large dataset that needs annotation. Here, we'll simulate this by selecting a few items from each of our newly created subsets (train, validation, and test) and placing them into a labeling task."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
       "valid_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
       "test_filters = dl.Filters(field=\"metadata.system.tags.test\", values=True)\n",
       "\n",
       "train_items = list(dataset.items.list(filters=train_filters).all())[:2]\n",
       "valid_items = list(dataset.items.list(filters=valid_filters).all())[:2]\n",
       "test_items = list(dataset.items.list(filters=test_filters).all())[:2]\n",
       "\n",
       "print(f\"Train items: {[item.filename for item in train_items]}\")\n",
       "print(f\"Valid items: {[item.filename for item in valid_items]}\")\n",
       "print(f\"Test items: {[item.filename for item in test_items]}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Now we will create a new annotation task for these selected items. We will assign the task to ourselves for this tutorial. The task uses the dataset's `recipe`, which defines the set of possible labels (the ontology) for annotation."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "your_user_email = dl.info()[\"user_email\"]\n",
       "\n",
       "task_name = \"Model Training Task\"\n",
       "assignee_ids = [your_user_email]\n",
       "workload = dl.Workload.generate(assignee_ids=assignee_ids)\n",
       "task_owner = your_user_email\n",
       "recipe = dataset.recipes.list()[0]\n",
       "items = train_items + valid_items + test_items\n",
       "\n",
       "task: dl.Task = project.tasks.create(\n",
       "    task_name=task_name, \n",
       "    assignee_ids=assignee_ids,\n",
       "    workload=workload,\n",
       "    dataset=dataset,\n",
       "    task_owner=task_owner,\n",
       "    recipe_id=recipe.id,\n",
       "    items=items\n",
       ")\n",
       "print(f\"Created Task: [Name: {task.name}, ID: {task.id}, Items Count: {task.total_items}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "When a task is created, the system generates `assignments` for each assignee. Let's retrieve the assignment created for our user."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "assignment: dl.Assignment = task.assignments.list()[0]\n",
       "print(f\"Task assignment: [Name: {assignment.name}, ID: {assignment.id}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Annotate and Complete the Task Items\n",
       "\n",
       "The next stage involves creating annotations for the dataset items and marking them as completed. For this tutorial, we'll programmatically add classification annotations. The label for each annotation will be derived from the item's parent folder name.\n",
       "\n",
       "We'll use the script below to add annotations that are properly linked to both the task and assignment. Once annotated, we'll update the status of each item to `completed` to indicate it is ready for the training phase."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# We will use the following labels for our annotations\n",
       "print(list(dataset.labels_flat_dict.keys()))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Now we will iterate through all items in the task, add annotations, and mark them as complete."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "items = task.get_items()\n",
       "if isinstance(items, dl.entities.PagedEntities):\n",
       "    items = items.all()\n",
       "items = list(items)\n",
       "\n",
       "item: dl.Item\n",
       "for item in items:\n",
       "    # Delete the item annotations\n",
       "    filters = dl.Filters(resource=dl.FiltersResource.ANNOTATION)  # Filter is required to delete all annotations\n",
       "    item.annotations.delete(filters=filters)\n",
       "\n",
       "    # Creating new classification annotation based on the item folder name\n",
       "    builder = item.annotations.builder()\n",
       "    label = pathlib.Path(item.filename).parent.name\n",
       "    classification = dl.Classification(label=label, description=f\"Created by assignment {assignment.id}\")\n",
       "\n",
       "    # Linking the annotations to the task\n",
       "    metadata = {\n",
       "        \"system\": {\n",
       "            \"recipeId\": recipe.id,\n",
       "            \"taskId\": task.id,\n",
       "            \"assignmentId\": assignment.id\n",
       "        }\n",
       "    }\n",
       "\n",
       "    # Adding the annotations to the item\n",
       "    builder.add(\n",
       "        annotation_definition=classification,\n",
       "        metadata=metadata\n",
       "    )\n",
       "    item.annotations.upload(builder)\n",
       "    item.update_status(\n",
       "        status=\"completed\", \n",
       "        assignment_id=assignment.id, \n",
       "        task_id=task.id\n",
       "    )\n",
       "    print(f\"Uploaded annotations to Item: [ID: {item.id}, Filename: {item.filename}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## <a id='model-training'></a>4. Model Training & Deployment\n",
       "\n",
       "### Configure Base Model\n",
       "\n",
       "With our data annotated, we can now begin the training process. We will retrieve the pre-trained ResNet model that was installed with the dataset DPK. We then configure it by specifying which data subsets to use for training and validation, and by setting key hyperparameters like the number of epochs and batch size."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "base_model = project.models.get(model_name=\"pretrained-resnet\")\n",
       "\n",
       "# Configure model metadata and subsets\n",
       "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
       "val_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
       "\n",
       "base_model.add_subset(\"train\", train_filters)\n",
       "base_model.add_subset(\"validation\", val_filters)\n",
       "\n",
       "# Set model configuration for ResNet training\n",
       "base_model.configuration = {\n",
       "    \"num_epochs\": 5,\n",
       "    \"batch_size\": 32,\n",
       "}\n",
       "\n",
       "print(f\"Base model configured: {base_model.name}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Clone and Train Model\n",
       "\n",
       "To fine-tune a model, we first `clone` the pre-trained model. This creates a new, trainable model entity in your project. We associate our dataset and its labels with this new model and then start the training process.\n",
       "\n",
       "> **NOTE**: The training process can take a significant amount of time, depending on your dataset size, model configuration, and the available compute resources (GPU type)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "finetuned_model_name = base_model.name + \"-finetuned\"\n",
       "labels = [label.tag for label in dataset.labels]\n",
       "finetuned_model = base_model.clone(model_name=finetuned_model_name, dataset=dataset, labels=labels)\n",
       "print(f\"Created new model for finetuning: [Name: {finetuned_model.name}, ID: {finetuned_model.id}]\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "print(f\"Training model: {finetuned_model.name}\")\n",
       "execution = finetuned_model.train()\n",
       "print(f\"Training execution: [ID: {execution.id}, status: {execution.status}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "The cell below will periodically check the status of the training execution and wait for it to complete. You can also monitor the training progress, view logs, and see performance metrics directly in the Dataloop platform by navigating to your model's page."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Wait for training to complete\n",
       "print(\"Waiting for training to complete...\")\n",
       "\n",
       "while execution.in_progress():\n",
       "    print(\"Training in progress... checking again in 2 minutes\")\n",
       "    time.sleep(120)  # Sleep for 2 minutes\n",
       "    execution = dl.executions.get(execution_id=execution.id)\n",
       "\n",
       "if execution.get_latest_status()['status'] == \"success\":\n",
       "    print(\"Training completed successfully!\")\n",
       "else:\n",
       "    print(f\"Training failed with status: {execution.get_latest_status()['status']}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Deploy the Trained Model\n",
       "\n",
       "Once training is complete, the final step is to deploy the fine-tuned model. Deployment creates a live service endpoint that can be used for inference on new, unseen data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Get the updated model entity\n",
       "finetuned_model = project.models.get(model_id=finetuned_model.id)\n",
       "\n",
       "# Deploy the model\n",
       "service = finetuned_model.deploy()\n",
       "print(f\"Model deployed successfully: [Name: {service.name}, ID: {service.id}]\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## <a id='conclusion'></a>5. Conclusion\n",
       "\n",
       "Congratulations! You have successfully walked through the entire process of an end-to-end model workflow on Dataloop. You have accomplished the following:\n",
       "\n",
       "1. Set up your Dataloop environment and project.\n",
       "2. Installed a dataset from the Marketplace and prepared it for training by creating ML subsets.\n",
       "3. Created a labeling task for a subset of data.\n",
       "4. Programmatically annotated items and marked them as complete.\n",
       "5. Configured and fine-tuned a pre-trained model on your annotated data.\n",
       "6. Deployed the trained model as a live service for inference.\n",
       "\n",
       "### Next Steps\n",
       "\n",
       "From here, you can explore more advanced concepts:\n",
       "- Use your deployed model to make predictions on new items.\n",
       "- Create a full pipeline that automates this entire workflow.\n",
       "- Explore active learning loops to intelligently select which items to annotate next.\n",
       "- Check out our [Active Learning Pipeline Tutorial](https://docs.dataloop.ai/docs/active-learning-pipeline) for an example."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
