{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the Dataloop Python SDK (dtlpy)\n",
    "\n",
    "Welcome! This notebook provides a comprehensive introduction to interacting with the Dataloop platform using its Python SDK, `dtlpy`. It will cover:\n",
    "\n",
    "1.  **Setup & Authentication:** Connecting to the Dataloop platform and managing credentials.\n",
    "2.  **Projects:** Creating and managing your main workspace containers.\n",
    "3.  **Datasets:** Organizing your data within projects and managing data collections.\n",
    "4.  **Setting the Ontology and Recipe:** Defining labels and annotation schemas for your data.\n",
    "5.  **Items:** Uploading, managing, and working with individual data files (images, videos, text, JSON, etc.).\n",
    "6.  **Prompt Items:** Working with specialized items for Large Language Model interactions.\n",
    "7.  **Annotations:** Adding labels and metadata to your data items for training and analysis.\n",
    "8.  **Tasks & Assignments:** Creating annotation or QA workflows and managing collaborative work.\n",
    "9.  **Conclusion and Next Steps:** Summarizing the concepts and suggesting further exploration.\n",
    "\n",
    "### Prerequisites:\n",
    "*   **Dataloop Account:** You should have access to a Dataloop platform account.\n",
    "*   **Python Environment:** Ensure you have Python 3.7+ installed with pip.\n",
    "*   **Basic Python Knowledge:** Familiarity with Python programming concepts.\n",
    "\n",
    "### Navigate through the following sections:\n",
    "\n",
    "1. [Setup & Authentication](#setup-authentication)\n",
    "2. [Projects](#projects)\n",
    "3. [Datasets](#datasets)\n",
    "4. [Setting the Ontology and Recipe](#setting-ontology-recipe)\n",
    "5. [Items](#items)\n",
    "    *   [5.1 Uploading Items](#uploading-items)\n",
    "    *   [5.2 Listing Items](#listing-items)\n",
    "    *   [5.3 Retrieving Items](#retrieving-items)\n",
    "    *   [5.4 Getting and Updating Item Metadata](#getting-updating-item-metadata)\n",
    "    *   [5.5 Downloading Items](#downloading-items)\n",
    "6. [Prompt Items](#prompt-items)\n",
    "7. [Annotations](#annotations)\n",
    "8. [Tasks & Assignments](#tasks-assignments)\n",
    "9. [Conclusion and Next Steps](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='setup-authentication'></a>1. Setup & Authentication\n",
    "\n",
    "First, ensure you have the `dtlpy` library installed. If not, uncomment and run the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses `pip` to install the `dtlpy` package. The `--quiet` flag suppresses installation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtlpy --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with the Dataloop platform, you need to authenticate. The simplest way in an interactive environment like a Jupyter Notebook is using `dl.login()` which will open a browser window for you to log in via your Dataloop account (or uses saved credentials if available and valid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the `dtlpy` library as `dl` and the `datetime` library. We then check if the current Dataloop authentication token has expired using `dl.token_expired()`. If it has, `dl.login()` is called, which typically opens a web browser for you to log into your Dataloop account. Successful login or an active session will be confirmed with a print message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "import datetime\n",
    "\n",
    "if dl.token_expired():\n",
    "   dl.login() # Opens browser for login\n",
    "   print(f\"Logged in successfully to {dl.client_api.environment}\")\n",
    "else:\n",
    "   print(f\"Session active for {dl.client_api.info()['user_email']} in {dl.client_api.environment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='projects'></a>2. Projects\n",
    "\n",
    "Projects are the main containers for your work in Dataloop. They hold datasets, ontologies, models, tasks, pipelines, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines a unique project name using your Dataloop user email to create a prefix. It then attempts to retrieve an existing project with this name using `dl.projects.get()`. If the project is not found (raising a `dl.exceptions.NotFound` error), it creates a new project with `dl.projects.create()`. This ensures you have a project to work with for this tutorial. The project's name and ID are printed upon successful retrieval or creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique name for your project\n",
    "# Best practice: Use a combination of your username/initials and the purpose\n",
    "user_email = dl.info()['user_email']\n",
    "user_prefix = user_email.split('@')[0].replace('.', '').replace('-', '') # Simple prefix from email\n",
    "project_name = f'{user_prefix}-sdk-getting-started'\n",
    "\n",
    "# Check if the project exists, if not, create it\n",
    "try:\n",
    "    project = dl.projects.get(project_name=project_name)\n",
    "    print(f\"Successfully retrieved project: '{project.name}' (ID: {project.id})\")\n",
    "except dl.exceptions.NotFound:\n",
    "    project = dl.projects.create(project_name=project_name)\n",
    "    print(f\"Successfully created project: '{project.name}' (ID: {project.id})\")\n",
    "\n",
    "# Print project details (optional)\n",
    "# project.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can now access the project in the web interface\n",
    "# project.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following (commented out) code demonstrates how to list all projects accessible to your Dataloop user using `dl.projects.list()` and print their details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can list all projects you have access to\n",
    "# print(\"\\nListing projects accessible to you:\")\n",
    "# my_projects = dl.projects.list()\n",
    "# my_projects.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='datasets'></a>3. Datasets\n",
    "\n",
    "Datasets reside within projects and contain your data items (images, videos, text, etc.) and their associated annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a name for our dataset. Similar to projects, we use a try-except block to get the dataset if it already exists within the `project` object (`project.datasets.get()`) or create it if it doesn't (`project.datasets.create()`). When a dataset is created, Dataloop automatically sets up a default Recipe and Ontology for it. The dataset's name and ID are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique name for your dataset within the project\n",
    "dataset_name = 'my-sdk-dataset'\n",
    "\n",
    "# Check if the dataset exists within the project\n",
    "# if not, create it. Dataloop automatically creates a default Recipe and Ontology.\n",
    "try:\n",
    "    dataset = project.datasets.get(dataset_name=dataset_name)\n",
    "    print(f\"Successfully retrieved dataset: '{dataset.name}' (ID: {dataset.id})\")\n",
    "except dl.exceptions.NotFound:\n",
    "    dataset = project.datasets.create(dataset_name=dataset_name)\n",
    "    print(f\"Successfully created dataset: '{dataset.name}' (ID: {dataset.id}) in project '{project.name}'.\")\n",
    "\n",
    "# Print dataset details (optional)\n",
    "# dataset.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This commented-out code shows how to list all datasets within the previously retrieved or created `project` using `project.datasets.list()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List datasets within the project we retrieved/created\n",
    "# print(f\"\\nListing datasets in project '{project.name}'...\")\n",
    "# datasets = project.datasets.list()\n",
    "# datasets.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='setting-ontology-recipe'></a>4. Setting the Dataset Ontology and Recipe\n",
    "\n",
    "Before annotating, you need to define the *ontology* - the set of labels and their attributes that can be applied to your data.\n",
    "\n",
    "In Dataloop, the relationship is:\n",
    "*   **Dataset:** Contains your data items.\n",
    "*   **Recipe:** Links a Dataset to one or more Ontologies. It defines the *schema* for annotation and QA tasks within that dataset. Every dataset must have at least one recipe.\n",
    "*   **Ontology:** Defines the labels (e.g., 'car', 'person', 'text bounding box') and their attributes (e.g., color, size, type).\n",
    "\n",
    "When you create a dataset using the SDK (or UI), Dataloop automatically creates a default recipe and a default ontology for it. We will modify this default ontology to add the labels we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell handles the setup of the dataset's ontology, which defines the set of labels for annotation.\n",
    "1.  It retrieves the default recipe associated with our `dataset`. If, for some reason, a default recipe isn't found (which is unlikely for SDK-created datasets), it creates one and links it.\n",
    "2.  It then retrieves the default ontology linked to this recipe. Similarly, if an ontology isn't found, it creates an empty one and links it to the recipe.\n",
    "3.  A dictionary `labels_to_add` is defined with desired label names and their corresponding display colors.\n",
    "4.  It iterates through these labels, checking if they already exist in the `ontology.labels`. If a label doesn't exist, it's added using `ontology.add_label()`.\n",
    "5.  An example of adding a label with attributes (`AttributedObject`) is also shown. Attributes allow for more detailed annotation, such as boolean flags (e.g., 'Is Occluded?') or option lists (e.g., 'Object Size').\n",
    "6.  If any labels were added or modified, `ontology.update()` is called to save these changes to the Dataloop platform.\n",
    "7.  Finally, it prints the current list of labels in the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the dataset's default recipe\n",
    "# Datasets usually have one recipe by default upon creation\n",
    "try:\n",
    "    recipe = dataset.recipes.list()[0] # Get the first recipe (usually the default)\n",
    "    print(f\"Retrieved recipe: '{recipe.title}' (ID: {recipe.id})\")\n",
    "except IndexError:\n",
    "    # This should ideally not happen for SDK-created datasets, but as a fallback:\n",
    "    print(\"No default recipe found. Creating one...\")\n",
    "    recipe = dataset.recipes.create()\n",
    "    dataset.metadata['system']['recipes'] = [recipe.id] # Link recipe to dataset\n",
    "    dataset.update(system_metadata=True)\n",
    "    print(f\"Created and linked recipe: '{recipe.title}' (ID: {recipe.id})\")\n",
    "\n",
    "# Retrieve the ontology linked to the recipe\n",
    "# Recipes usually have one ontology by default\n",
    "try:\n",
    "    ontology = recipe.ontologies.list()[0] # Get the first ontology\n",
    "    print(f\"Retrieved ontology: '{ontology.title}' (ID: {ontology.id}) with {len(ontology.labels)} labels initially.\")\n",
    "except IndexError:\n",
    "    # This should also ideally not happen.\n",
    "    print(\"No default ontology found for the recipe. Creating one...\")\n",
    "    ontology = recipe.ontologies.create(labels=[]) # Create empty ontology\n",
    "    recipe.ontology_ids = [ontology.id] # Link ontology to recipe\n",
    "    recipe.update()\n",
    "    print(f\"Created and linked ontology: '{ontology.title}' (ID: {ontology.id})\")\n",
    "\n",
    "# Define the labels we want to use later for annotation\n",
    "labels_to_add = {\n",
    "    \"Object1\": '#FF0000',  # Red\n",
    "    \"CornerPoint\": '#00FF00', # Lime Green\n",
    "    \"IndoorScene\": '#0000FF', # Blue\n",
    "    \"MyTextLabel\": '#FFFF00' # Yellow (For potential text annotation)\n",
    "}\n",
    "\n",
    "# Add labels to the ontology if they don't exist\n",
    "labels_updated = False\n",
    "existing_labels = [lbl.tag for lbl in ontology.labels]\n",
    "\n",
    "for label_name, color_hex in labels_to_add.items():\n",
    "    if label_name not in existing_labels:\n",
    "        print(f\"Adding label '{label_name}'...\")\n",
    "        ontology.add_label(label_name=label_name, color=color_hex)\n",
    "        labels_updated = True\n",
    "    else:\n",
    "        print(f\"Label '{label_name}' already exists.\")\n",
    "\n",
    "# Add a simple label first, then we'll add attributes to it separately\n",
    "attributes_label_name = 'AttributedObject'\n",
    "if attributes_label_name not in existing_labels:\n",
    "    print(f\"Adding label '{attributes_label_name}'...\")\n",
    "    ontology.add_label(label_name=attributes_label_name, color='#FFA500')  # Orange\n",
    "    labels_updated = True\n",
    "\n",
    "# Update the ontology on the platform *only* if changes were made\n",
    "if labels_updated:\n",
    "    ontology = ontology.update()\n",
    "    print(f\"Ontology updated successfully. It now has {len(ontology.labels)} labels.\")\n",
    "else:\n",
    "    print(\"No new labels needed to be added.\")\n",
    "\n",
    "# Now add attributes using the correct method\n",
    "print(\"Adding attributes to the ontology...\")\n",
    "\n",
    "# Add a boolean attribute (Yes/No)\n",
    "ontology.update_attributes(\n",
    "    key='occluded',\n",
    "    title='Is Occluded?',\n",
    "    attribute_type=dl.AttributesTypes.YES_NO,\n",
    "    scope=[attributes_label_name]  # Apply only to the AttributedObject label\n",
    ")\n",
    "\n",
    "# Add a multi-choice attribute (Radio Button)\n",
    "ontology.update_attributes(\n",
    "    key='size',\n",
    "    title='Object Size',\n",
    "    attribute_type=dl.AttributesTypes.RADIO_BUTTON,\n",
    "    values=['small', 'medium', 'large'],\n",
    "    scope=[attributes_label_name]  # Apply only to the AttributedObject label\n",
    ")\n",
    "\n",
    "print(\"Attributes added successfully!\")\n",
    "\n",
    "# Optional: Print ontology labels\n",
    "print(\"\\nCurrent Ontology Labels:\")\n",
    "ontology.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shortcut:** You can also use `dataset.add_label(...)` which automatically finds the default recipe and ontology and adds the label. This is convenient for simple cases.\n",
    "\n",
    "```python\n",
    "# Example shortcut:\n",
    "# dataset.add_label(label_name='ShortcutLabel', color='#FFC0CB') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='items'></a>5. Items\n",
    "\n",
    "Items are the individual data points within a dataset (e.g., images, videos, text files, JSON)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='uploading-items'></a>5.1 Uploading Items\n",
    "\n",
    "Let's upload sample items, an image and a text file.\n",
    "Make sure you have a `data` directory with `sample.jpg` and `sample.txt` inside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell prepares dummy data files for upload if they don't already exist. \n",
    "1. It defines a `data_dir` ('data') and filenames for a sample image (`sample.jpg`) and text file (`sample.txt`).\n",
    "2. It creates the `data_dir` if it's missing using `os.makedirs(data_dir, exist_ok=True)`.\n",
    "3. If `sample.jpg` doesn't exist, it generates a small random dummy image using PIL (Pillow) and NumPy and saves it.\n",
    "4. If `sample.txt` doesn't exist, it creates a simple text file with some content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data_dir = 'data/getting_started_with_sdk'\n",
    "image_filename = 'sample.jpg'\n",
    "text_filename = 'sample.txt'\n",
    "image_filepath = os.path.join(data_dir, image_filename)\n",
    "text_filepath = os.path.join(data_dir, text_filename)\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Create dummy image if it doesn't exist\n",
    "if not os.path.exists(image_filepath):\n",
    "    print(f\"Creating dummy image at: {image_filepath}\")\n",
    "    dummy_image = Image.fromarray(np.random.randint(0, 256, (100, 150, 3), dtype=np.uint8))\n",
    "    dummy_image.save(image_filepath)\n",
    "else:\n",
    "    print(f\"Image already exists at: {image_filepath}\")\n",
    "\n",
    "# Create dummy text file if it doesn't exist\n",
    "if not os.path.exists(text_filepath):\n",
    "    print(f\"Creating dummy text file at: {text_filepath}\")\n",
    "    with open(text_filepath, 'w') as f:\n",
    "        f.write(\"This is a sample text file for the Dataloop SDK getting started guide.\")\n",
    "else:\n",
    "    print(f\"Text file already exists at: {text_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload the local files prepared in the previous step to our Dataloop dataset.\n",
    "1. Filepaths for the local image and text file are constructed.\n",
    "2. It checks if these files exist and raises a `FileNotFoundError` if they don't (this is a safeguard, as the previous cell should have created them).\n",
    "3. The `dataset.items.upload()` method is used to upload each file:\n",
    "    - `local_path`: Specifies the path to the file on your local system.\n",
    "    - `remote_path`: Defines the directory structure where the item will be stored within the Dataloop dataset (e.g., '/images', '/docs').\n",
    "    - `overwrite=True`: If an item with the same name already exists at the remote path, it will be overwritten. This is useful for re-running notebooks.\n",
    "4. The returned `dl.Item` object for each uploaded item is stored (e.g., `image_item`, `text_item`), and their filenames and IDs are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'data/getting_started_with_sdk'\n",
    "image_filename = 'sample.jpg' # Ensure this file exists in the 'data' directory\n",
    "text_filename = 'sample.txt' # Ensure this file exists in the 'data' directory\n",
    "image_filepath = os.path.join(data_dir, image_filename)\n",
    "text_filepath = os.path.join(data_dir, text_filename)\n",
    "\n",
    "# Check if files exist before uploading\n",
    "if not os.path.exists(image_filepath):\n",
    "    raise FileNotFoundError(f\"Image file not found: {image_filepath}. Please create it.\")\n",
    "if not os.path.exists(text_filepath):\n",
    "    raise FileNotFoundError(f\"Text file not found: {text_filepath}. Please create it.\")\n",
    "\n",
    "# Upload the local files to the dataset\n",
    "# 'remote_path' specifies the directory structure within the Dataloop dataset\n",
    "print(\"Uploading items...\")\n",
    "\n",
    "# Use overwrite=True to avoid errors if the item already exists\n",
    "image_item: dl.Item = dataset.items.upload(\n",
    "    local_path=image_filepath,\n",
    "    remote_path='/images',\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "print(f\"Uploaded/Retrieved image item: {image_item.filename}, ID: {image_item.id}\")\n",
    "# image_item.print()\n",
    "\n",
    "text_item: dl.Item = dataset.items.upload(\n",
    "    local_path=text_filepath,\n",
    "    remote_path='/docs',\n",
    "    overwrite=True\n",
    "    )\n",
    "\n",
    "print(f\"\\nUploaded/Retrieved text item: {text_item.filename}, ID: {text_item.id}\")\n",
    "# text_item.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='listing-items'></a>5.2 Listing Items\n",
    "\n",
    "You can list items in a dataset, optionally applying filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates how to list items within the dataset.\n",
    "1.  `dataset.items.list()` is called without filters to get a paginated list of all items in the dataset. The `.print()` method displays a summary, and `items_count` gives the total number.\n",
    "2.  To list items from a specific directory (e.g., '/images'), we create a `dl.Filters` object, specifying `resource=dl.FiltersResource.ITEM`. \n",
    "3.  We then use `filters.add()` to specify the filtering condition: `field='dir'` and `values='/images'`.\n",
    "4.  `dataset.items.list(filters=filters)` is then called with these filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List items in the dataset (can use filters)\n",
    "print(\"\\nListing all items in the dataset:\")\n",
    "all_items_page = dataset.items.list()\n",
    "all_items_page.print()\n",
    "print(f\"Total items in dataset: {all_items_page.items_count}\")\n",
    "\n",
    "print(\"\\nListing items in the '/images' directory:\")\n",
    "filters = dl.Filters(resource=dl.FiltersResource.ITEM)\n",
    "filters.add(field='dir', values='/images') # Use add() method\n",
    "image_items_page = dataset.items.list(filters=filters)\n",
    "image_items_page.print()\n",
    "print(f\"Items in /images: {image_items_page.items_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='retrieving-items'></a>5.3 Retrieving Items\n",
    "\n",
    "You can retrieve items using either their filepath within your dataset or by using their unique item ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell shows how to retrieve individual items.\n",
    "1.  It first ensures that `image_item` and `text_item` (from the upload step) exist and gets their IDs and remote filepaths (which include the directory, e.g., `/images/sample.jpg`).\n",
    "2.  To get an item by its path: `dataset.items.get(filepath=image_remote_filepath)` is used. This is wrapped in a try-except block to handle `dl.exceptions.NotFound` if the item doesn't exist at that path.\n",
    "3.  To get an item by its ID: `dataset.items.get(item_id=text_item_id)` is used, also with error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have the item IDs from the upload step\n",
    "image_item_id = image_item.id\n",
    "text_item_id = text_item.id\n",
    "image_remote_filepath = image_item.filename # Get the actual remote path\n",
    "text_remote_filepath = text_item.filename # Get the actual remote path\n",
    "\n",
    "# Get an item by its path\n",
    "try:\n",
    "    retrieved_image_item = dataset.items.get(filepath=image_remote_filepath)\n",
    "    print(f\"\\nRetrieved image item by path: {retrieved_image_item.filename}\")\n",
    "    # retrieved_image_item.print()\n",
    "except dl.exceptions.NotFound:\n",
    "    print(f\"Error: Could not find item by path: {image_remote_filepath}\")\n",
    "\n",
    "# Get an item by its item id\n",
    "try:\n",
    "    retrieved_text_item = dataset.items.get(item_id=text_item_id)\n",
    "    print(f\"\\nRetrieved text item by item id: {retrieved_text_item.id}\")\n",
    "    # retrieved_text_item.print()\n",
    "except dl.exceptions.NotFound:\n",
    "     print(f\"Error: Could not find item by ID: {text_item_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='getting-updating-item-metadata'></a>5.4 Getting and Updating Item Metadata\n",
    "\n",
    "Each item has system metadata (like dimensions, mimetype) and user metadata (a flexible dictionary for your own information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates working with item metadata.\n",
    "1.  It first checks if `retrieved_image_item` (from the previous step) exists.\n",
    "2.  It prints the item's system metadata (`retrieved_image_item.system`) and user metadata (`retrieved_image_item.metadata.get('user', {})`) using `json.dumps` for pretty printing.\n",
    "3.  To update user metadata, it accesses `retrieved_image_item.metadata['user']`. It ensures this key exists and is a dictionary. New key-value pairs are then added, such as `processed_by_script` and a timestamp.\n",
    "4.  The `retrieved_image_item.update()` method is called to save these metadata changes to the Dataloop platform. The updated item object is reassigned to `retrieved_image_item`.\n",
    "5.  The user metadata is printed again to show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Make sure we successfully retrieved the image item\n",
    "if 'retrieved_image_item' in locals():\n",
    "    # Print existing metadata\n",
    "    print(\"\\nItem System Metadata:\")\n",
    "    print(json.dumps(retrieved_image_item.system, indent=2))\n",
    "    print(\"\\nItem User Metadata (before update):\")\n",
    "    print(json.dumps(retrieved_image_item.metadata.get('user', {}), indent=2))\n",
    "\n",
    "    # Add/Update user metadata\n",
    "    # The metadata is a dictionary. We usually add custom info under the 'user' key.\n",
    "\n",
    "    # Ensure 'user' key exists and is a dictionary\n",
    "    if 'user' not in retrieved_image_item.metadata or not isinstance(retrieved_image_item.metadata['user'], dict):\n",
    "        retrieved_image_item.metadata['user'] = {}\n",
    "    retrieved_image_item.metadata['user']['processed_by_script'] = True\n",
    "    retrieved_image_item.metadata['user']['custom_info'] = 'This is from the SDK notebook'\n",
    "    retrieved_image_item.metadata['user']['run_timestamp'] = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "\n",
    "    # Push the update to the platform\n",
    "    retrieved_image_item = retrieved_image_item.update()\n",
    "    print(\"\\nItem User Metadata (after update):\")\n",
    "    print(json.dumps(retrieved_image_item.metadata.get('user', {}), indent=2))\n",
    "else:\n",
    "    print(\"\\nSkipping metadata update because image item retrieval failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='downloading-items'></a>5.5 Downloading Items\n",
    "\n",
    "You can download items back to your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell shows how to download an item.\n",
    "1.  A `download_dir` ('downloaded_data') is defined, and `os.makedirs` ensures it exists.\n",
    "2.  It checks if `retrieved_image_item` is available.\n",
    "3.  `retrieved_image_item.download(local_path=download_path)` is called. The `local_path` specifies the full path (including filename) where the item will be saved locally. The method returns the actual filepath of the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = 'downloaded_data'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "if 'retrieved_image_item' in locals():\n",
    "    download_path = os.path.join(download_dir, retrieved_image_item.name)\n",
    "    filepath = retrieved_image_item.download(local_path=download_path)\n",
    "    print(f\"Item '{retrieved_image_item.name}' downloaded successfully to: {filepath}\")\n",
    "else:\n",
    "    print(\"Skipping item download because image item retrieval failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='prompt-items'></a>6. Prompt Items\n",
    "\n",
    "Prompt Items are a special type used for Large Language Model (LLM) interactions. They are structured JSON files containing prompts (which can include text, references to images/videos, etc.) and potentially responses (stored as annotations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates the creation and upload of a `dl.PromptItem`.\n",
    "1.  It checks if `retrieved_image_item` exists, as we'll reference this image in our prompt.\n",
    "2.  A `dl.PromptItem` object is instantiated with a name (which will be its filename, e.g., \"my-first-prompt.json\").\n",
    "3.  A `dl.Prompt` object is created. Each prompt within a `PromptItem` has a unique `key` and a `role` (e.g., \"user\", \"assistant\").\n",
    "4.  Elements are added to this `user_prompt` using `user_prompt.add_element()`:\n",
    "    *   A text element (`dl.PromptType.TEXT`) with the value \"Describe this image:\".\n",
    "    *   An image element (`dl.PromptType.IMAGE`) where the `value` is `retrieved_image_item.stream`. This `stream` attribute provides a reference to the image data on the Dataloop platform, allowing the prompt item to link to it without duplicating the image data itself.\n",
    "5.  The `user_prompt` is appended to the `prompt_item_obj.prompts` list.\n",
    "6.  Finally, the `prompt_item_obj` is uploaded to the dataset using `dataset.items.upload()`. The `local_path` is the `PromptItem` object itself, `remote_path` specifies a directory in the dataset, and `overwrite=True` is used. The uploaded prompt item's filename and ID are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the image item was retrieved before creating the prompt item\n",
    "if 'retrieved_image_item' in locals():\n",
    "    # Create a PromptItem object (this doesn't upload yet)\n",
    "    # The name will be the filename in the platform.\n",
    "    prompt_item_name = \"my-first-prompt.json\"\n",
    "    prompt_item_obj = dl.PromptItem(name=prompt_item_name)\n",
    "\n",
    "    # Create a prompt (a single turn in a conversation)\n",
    "    # Use a unique key for each prompt within the item\n",
    "    user_prompt_key = \"user_query_1\"\n",
    "    user_prompt = dl.Prompt(key=user_prompt_key, role=\"user\")  # Default role is 'user'\n",
    "\n",
    "    # Add elements to the prompt\n",
    "    user_prompt.add_element(\n",
    "        mimetype=dl.PromptType.TEXT,\n",
    "        value=\"Describe this image:\"\n",
    "    )\n",
    "    # Reference the image item we uploaded earlier by its data stream\n",
    "    user_prompt.add_element(\n",
    "        mimetype=dl.PromptType.IMAGE,\n",
    "        value=retrieved_image_item.stream,\n",
    "    )\n",
    "\n",
    "    # Add the prompt to the PromptItem\n",
    "    prompt_item_obj.prompts.append(user_prompt)\n",
    "\n",
    "    # We can upload the prompt item directly\n",
    "    uploaded_prompt_item: dl.Item = dataset.items.upload(\n",
    "        local_path=prompt_item_obj,\n",
    "        remote_path='/prompts',\n",
    "        overwrite=True\n",
    "        )\n",
    "    print(f\"Uploaded prompt item: {uploaded_prompt_item.filename} (ID: {uploaded_prompt_item.id})\")\n",
    "\n",
    "    # Open the item in the web interface\n",
    "    # uploaded_prompt_item.open_in_web() # Uncomment to open\n",
    "else:\n",
    "    print(\"Skipping Prompt Item creation because image item retrieval failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='annotations'></a>7. Annotations\n",
    "\n",
    "Annotations add semantic meaning to your data items. Dataloop supports various types like bounding boxes, polygons, points, classifications, etc.\n",
    "\n",
    "**Important:** The labels used here (`'Object1'`, `'CornerPoint'`, `'IndoorScene'`) should exist in the dataset's ontology (defined in Section 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates how to add various types of annotations to the `retrieved_image_item`.\n",
    "1.  It checks if `retrieved_image_item` exists.\n",
    "2.  An `AnnotationBuilder` is obtained from the item: `builder = item_to_annotate.annotations.builder()`.\n",
    "3.  Different annotation types are added using `builder.add()`:\n",
    "    *   `dl.Box`: A bounding box defined by `top`, `left`, `bottom`, `right` coordinates and a `label` (e.g., \"Object1\"). An optional `object_id` can be used for instance tracking, and `attributes` (like `{'size': 'small'}`) can be added if defined in the ontology for that label.\n",
    "    *   `dl.Point`: A point annotation defined by `x`, `y` coordinates and a `label` (e.g., \"CornerPoint\").\n",
    "    *   `dl.Classification`: A classification label (e.g., \"IndoorScene\") applied to the entire item, which has no geometric definition.\n",
    "4.  The annotations built are currently in memory. The commented-out line `# item_to_annotate.annotations.delete(filters=None)` shows how you could clear all existing annotations from an item before uploading new ones (use with caution).\n",
    "5.  `item_to_annotate.annotations.upload(annotations=builder)` uploads the annotations from the builder to the Dataloop platform.\n",
    "6.  After uploading, `item_to_annotate.annotations.list()` retrieves all annotations on the item for verification, and `.print()` displays them.\n",
    "7.  An error handling block catches exceptions during upload, reminding the user to ensure labels exist in the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add annotations to the image item we uploaded\n",
    "if 'retrieved_image_item' in locals():\n",
    "    item_to_annotate = retrieved_image_item\n",
    "    print(f\"Preparing to annotate item: {item_to_annotate.name}\")\n",
    "\n",
    "    # Use the Annotation Builder for the specific item\n",
    "    builder = item_to_annotate.annotations.builder()\n",
    "\n",
    "    # Add a Bounding Box annotation\n",
    "    # Coordinates are relative to the top-left corner (0,0)\n",
    "    builder.add(\n",
    "        annotation_definition=dl.Box(\n",
    "            top=10,\n",
    "            left=10,\n",
    "            bottom=50, # Increased size slightly\n",
    "            right=60,\n",
    "            label=\"Object1\" # Ensure this label exists in the ontology\n",
    "        ),\n",
    "        object_id=1 # Optional: for tracking instances\n",
    "    )\n",
    "\n",
    "    # Add a Point annotation\n",
    "    builder.add(\n",
    "        annotation_definition=dl.Point(\n",
    "            x=75,\n",
    "            y=75,\n",
    "            label=\"CornerPoint\" # Ensure this label exists in the ontology\n",
    "        ),\n",
    "         object_id=2 # Optional: for tracking instances\n",
    "    )\n",
    "\n",
    "    # Add a Classification annotation (no geometry)\n",
    "    builder.add(\n",
    "        annotation_definition=dl.Classification(label=\"IndoorScene\") # Ensure this label exists in the ontology\n",
    "    )\n",
    "\n",
    "    # The builder now holds these annotations in memory.\n",
    "    # Before uploading, you might want to clear existing annotations for this item\n",
    "    # Be cautious with this in real projects!\n",
    "    # item_to_annotate.annotations.delete(filters=None) # Deletes ALL annotations on the item\n",
    "\n",
    "    # Upload them to the platform:\n",
    "    print(\"Uploading annotations...\")\n",
    "    try:\n",
    "        uploaded_annotations = item_to_annotate.annotations.upload(annotations=builder)\n",
    "        print(f\"Successfully uploaded {len(uploaded_annotations)} annotations.\")\n",
    "\n",
    "        # You can retrieve the annotations on the item again to verify\n",
    "        annotations_on_item = item_to_annotate.annotations.list()\n",
    "        print(\"\\nAnnotations now on the item:\")\n",
    "        annotations_on_item.print() # Prints a summary table\n",
    "\n",
    "        # Open the item in the web interface\n",
    "        # item_to_annotate.open_in_web() # Uncomment to open\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading annotations: {e}\")\n",
    "        print(\"Ensure the labels used exist in the dataset's ontology (Section 4).\")\n",
    "else:\n",
    "    print(\"Skipping annotation creation because image item retrieval failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='tasks-assignments'></a>8. Tasks & Assignments\n",
    "\n",
    "Tasks allow you to manage annotation or QA workflows. You assign items to specific users (assignees) to perform work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell demonstrates creating an annotation task.\n",
    "1.  The assignee for the task is set to the current user's email (`dl.info()['user_email']`).\n",
    "2.  It checks if `image_item` (from the upload step) exists, as this item will be assigned to the task.\n",
    "3.  A `due_date` for the task is set to 7 days from the current time using `datetime`.\n",
    "4.  A unique `task_name` is generated including the current timestamp.\n",
    "5.  `dataset.tasks.create()` is called to create the task:\n",
    "    *   `task_name`: The name of the task.\n",
    "    *   `due_date`: The due date as a Unix timestamp.\n",
    "    *   `assignee_ids`: A list of user emails or IDs to assign the task to.\n",
    "    *   `items`: A list of specific `dl.Item` objects to include in the task. Alternatively, `filters` could be used to assign items based on criteria (e.g., all items in a specific directory, as shown in the commented-out example).\n",
    "6.  If task creation is successful, the task's name and ID are printed.\n",
    "7.  Creating a task automatically generates assignments for each assignee. `task.assignments.list()` retrieves these assignments, and `.print()` displays them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have a valid item and user email\n",
    "assignee_email = dl.info()['user_email'] # Assign task to yourself\n",
    "if 'image_item' in locals():\n",
    "    # Define due date (e.g., 1 week from now)\n",
    "    due_date = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(days=7)\n",
    "\n",
    "    # Create an annotation task for the image item\n",
    "    task_name = f\"SDK-GettingStarted-Task-{datetime.datetime.now().strftime('%Y%m%d-%H%M')}\" \n",
    "    print(f\"Creating task '{task_name}'...\")\n",
    "    try:\n",
    "        task: dl.Task = dataset.tasks.create(\n",
    "            task_name=task_name,\n",
    "            due_date=due_date.timestamp(),\n",
    "            assignee_ids=[assignee_email],\n",
    "            # You can assign specific items or use filters\n",
    "            items=[image_item], # Assign the specific image item we uploaded\n",
    "            # Example using filters to assign all items in '/images':\n",
    "            # filters=dl.Filters(resource=dl.FiltersResource.ITEM, field='dir', values='/images') \n",
    "        )\n",
    "        print(f\"Task created successfully: {task.name} (ID: {task.id})\")\n",
    "\n",
    "        # Creating a task automatically creates assignments for the assignees\n",
    "        # You can list assignments for the task\n",
    "        assignments = task.assignments.list()\n",
    "        print(\"\\nAssignments created for the task:\")\n",
    "        assignments.print()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating task: {e}\")\n",
    "else:\n",
    "    print(\"Skipping task creation because image item upload/retrieval failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a>9. Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You have successfully completed the getting started tutorial for the Dataloop Python SDK.\n",
    "\n",
    "### Summary of What You've Accomplished:\n",
    "- Authenticated and connected to the Dataloop platform\n",
    "- Created and managed Projects and Datasets\n",
    "- Defined the Dataset's Ontology (Labels) for annotation\n",
    "- Uploaded and retrieved Items (including PromptItems)\n",
    "- Added Annotations based on the Ontology\n",
    "- Created Tasks and Assignments for collaborative work\n",
    "\n",
    "### Next Steps:\n",
    "This is just the beginning! The SDK offers much more functionality for data management, automation, model integration, and pipeline creation.\n",
    "\n",
    "*   Explore the [Dataloop Developer Documentation](https://developers.dataloop.ai/) for more tutorials and examples.\n",
    "*   Check out the [SDK Reference](https://dataloop-ai.github.io/dtlpy/modules.html) for detailed information on classes and methods.\n",
    "*   Experiment with different item types, annotation types, filters, and ontology attributes.\n",
    "*   Try building automated pipelines and integrating machine learning models.\n",
    "*   Join the Dataloop community to share experiences and get support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
