{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR Data Processing with the Dataloop SDK\n",
    "\n",
    "This notebook provides a comprehensive guide on preparing and managing LiDAR data on the Dataloop platform using its Python SDK. It will cover:\n",
    "\n",
    "### Prerequisites:\n",
    "*   **Dataloop Account:** You should have access to a Dataloop platform account.\n",
    "*   **Python Environment:** Ensure you have Python 3.7+ installed with pip.\n",
    "*   **LiDAR Data:** Access to LiDAR data files including PCD files, camera images, and calibration data.\n",
    "*   **Local Data Structure:** Your LiDAR data should be organized as described in this tutorial.\n",
    "\n",
    "### Navigate through the following sections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Install Dependencies](#install-dependencies)\n",
    "2. [Import Required Libraries](#import-libraries)\n",
    "3. [Set Up Dataloop Environment](#setup-environment)\n",
    "4. [LiDAR Data Preparation](#data-preparation)\n",
    "    * [4.1 Local File Structure](#local-file-structure)\n",
    "    * [4.2 Upload Data to Dataloop](#upload-data)\n",
    "5. [Construct LiDAR Video Item](#construct-lidar-video)\n",
    "6. [Upload Annotations](#upload-annotations)\n",
    "    * [6.1 Define and Upload a 3D Cuboid](#upload-cuboid)\n",
    "    * [6.2 View in Dataloop Studio](#view-in-studio)\n",
    "7. [Conclusion and Next Steps](#conclusion)\n",
    "\n",
    "For more detailed information, refer to the official Dataloop documentation:\n",
    "- [LiDAR Data Setup](https://docs.dataloop.ai/docs/lidar-data-setup)\n",
    "- [LiDAR Video Annotations](https://developers.dataloop.ai/tutorials/annotations/lidar/chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='install-dependencies'></a>1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's ensure all required Python packages are installed. The cell below will install `dtlpy` for Dataloop SDK interaction and `dtlpylidar` for LiDAR-specific functionalities. It is recommended to run this to ensure you have the latest compatible versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dtlpy git+https://github.com/dataloop-ai-apps/dtlpy-lidar.git --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='import-libraries'></a>2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dependencies installed, we will now import the necessary libraries for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtlpy as dl\n",
    "from dtlpylidar.parsers.base_parser import LidarFileMappingParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='setup-environment'></a>3. Set Up Dataloop Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we need to connect to the Dataloop platform. If you're not already logged in, running the cell below will prompt you to do so. We will then create a new project or retrieve an existing one to work in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Action Required:** In the cell below, replace `\"your-lidar-project-name\"` with your Dataloop project name. If a project with this name already exists, it will be retrieved; otherwise, a new one will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dl.token_expired():\n",
    "    dl.login()\n",
    "\n",
    "PROJECT_NAME = \"your-lidar-project-name\"\n",
    "# Check if the project exists, if not, create it\n",
    "try:\n",
    "    project = dl.projects.get(project_name=PROJECT_NAME)\n",
    "    print(f\"Successfully retrieved project: '{project.name}' (ID: {project.id})\")\n",
    "except dl.exceptions.NotFound:\n",
    "    project = dl.projects.create(project_name=PROJECT_NAME)\n",
    "    print(f\"Successfully created project: '{project.name}' (ID: {project.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='data-preparation'></a>4. LiDAR Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a LiDAR video item, your dataset must contain three key components: PCD files for 3D scenes, camera images for 2D views, and a `mapping.json` file for sensor calibration. This section explains how to structure these files locally before uploading them to Dataloop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='local-file-structure'></a>4.1. Local File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before uploading to the Dataloop platform, your LiDAR data must be arranged in a specific local directory structure. This ensures that all components (point clouds, images) are correctly associated.\n",
    "\n",
    "1.  **`lidar` folder:** Contains all PCD files, named numerically in sequence (e.g., `0.pcd`, `1.pcd`, ...).\n",
    "\n",
    "2.  **`frames` folder:** Contains subfolders for each frame's camera images.\n",
    "    *   Subfolders must be named numerically to match the PCD files (e.g., `0`, `1`, ...).\n",
    "    *   Image files within each subfolder must be named sequentially (e.g., `0.jpg`, `1.jpg`, ...).\n",
    "\n",
    "3.  **`mapping.json` file:** This file, located at the root of your data directory, contains the calibration data that links the 3D point clouds to the 2D images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mapping.json` file must follow a specific schema. Below is a template demonstrating the required structure, including paths, timestamps, and camera calibration parameters (intrinsics and extrinsics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"frames\": {\n",
    "        \"0\": {\n",
    "            \"path\": <>, // for frame 0: \"lidar/0.pcd\" (Relative path from the mapping.json file)\n",
    "            \"timestamp\": <>,\n",
    "            \"position\": { // LiDAR sensor location (used as the center of the world)\n",
    "                \"x\": 0.0,\n",
    "                \"y\": 0.0,\n",
    "                \"z\": 0.0\n",
    "            },\n",
    "            \"heading\": { // LiDAR sensor rotation (Quaternion)\n",
    "                \"x\": 0.0,\n",
    "                \"y\": 0.0,\n",
    "                \"z\": 0.0,\n",
    "                \"w\": 1.0\n",
    "            },\n",
    "            \"images\": { // if no images are provided, add an empty dict\n",
    "                \"0\": {\n",
    "                    \"image_path\": <>, // for frame 0 image 0: \"frames/0/0.jpg\" (Relative path from the mapping.json file)\n",
    "                    \"timestamp\": <>,\n",
    "                    \"intrinsics\": { // camera intrinsic\n",
    "                        \"fx\": <>, // Focal length in pixels.\n",
    "                        \"fy\": <>,\n",
    "                        \"cx\": <>, // Optical center (the principal point), in pixels.\n",
    "                        \"cy\": <>,\n",
    "                    },\n",
    "                    \"extrinsics\": { // camera extrinsic\n",
    "                        \"translation\": { // camera location in world coordinates (in relation to the lidar sensor)\n",
    "                            \"x\": <>,\n",
    "                            \"y\": <>,\n",
    "                            \"z\": <>\n",
    "                        },\n",
    "                        \"rotation\": { // rotation of the camera (Quaternion)\n",
    "                            \"w\": <>,\n",
    "                            \"x\": <>,\n",
    "                            \"y\": <>,\n",
    "                            \"z\": <>\n",
    "                        }\n",
    "                    },\n",
    "                    \"distortion\" : { // distortion parameters\n",
    "                        \"k1\": <>,\n",
    "                        \"k2\": <>,\n",
    "                        \"p1\": <>,\n",
    "                        \"p2\": <>,\n",
    "                        \"k3\": <>,\n",
    "                        \"k4\": <>\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='upload-data'></a>4.2. Upload Data to Dataloop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own data structured as described above, or use sample data from [OSDaR23](https://data.fid-move.de/dataset/osdar23) for this tutorial.\n",
    "\n",
    "> **Action Required:** In the cell below, update `DATASET_NAME` with your desired dataset name and `DATA_PATH` with the local path to your data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"My-LiDAR-Dataset\"\n",
    "# Check if the dataset exists within the project\n",
    "# if not, create it. Dataloop automatically creates a default Recipe and Ontology.\n",
    "try:\n",
    "    dataset = project.datasets.get(dataset_name=DATASET_NAME)\n",
    "    print(f\"Successfully retrieved dataset: '{dataset.name}' (ID: {dataset.id})\")\n",
    "except dl.exceptions.NotFound:\n",
    "    dataset = project.datasets.create(dataset_name=DATASET_NAME)\n",
    "    print(f\"Successfully created dataset: '{dataset.name}' (ID: {dataset.id}) in project '{project.name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created or retrieved the dataset, we can upload items in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data to the dataset\n",
    "DATA_PATH = \"./data/*\"\n",
    "dataset.items.upload(local_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look at the items in the platform using the following\n",
    "dataset.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='construct-lidar-video'></a>5. Construct LiDAR Video Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After uploading your raw data files (`.pcd`, `.jpg`, `mapping.json`), we use the Dataloop LiDAR SDK to create a single, composite LiDAR video item. The `LidarFileMappingParser` reads the `mapping.json` file and generates a `frames.json` item, which represents the synchronized 3D video sequence in the Dataloop studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mapping item using filters\n",
    "filters = dl.Filters(field=dl.FiltersKnownFields.NAME, values=\"mapping.json\")\n",
    "mapping_item = dataset.items.get_all_items(filters=filters)[0]\n",
    "frames_item = LidarFileMappingParser().parse_data(mapping_item=mapping_item)\n",
    "print(f\"LiDAR Video File: ItemID: {frames_item.id}, ItemName: {frames_item.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='upload-annotations'></a>6. Upload Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `frames.json` video item created, you can now add annotations. The process is similar to annotating standard videos in Dataloop, but with support for 3D annotation types like cuboids. First, we need to retrieve the `frames.json` item we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the created frames item using filters\n",
    "filters = dl.Filters(field=dl.FiltersKnownFields.NAME, values=\"frames.json\")\n",
    "frames_item = dataset.items.get_all_items(filters=filters)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='upload-cuboid'></a>6.1. Define and Upload a 3D Cuboid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a 3D cuboid annotation, we define its geometric properties and any additional metadata. The key parameters are:\n",
    "\n",
    "*   **Position:** The 3D coordinates of the cuboid's center (x, y, z).\n",
    "*   **Rotation:** Euler angles for the cuboid's orientation (roll, pitch, yaw).\n",
    "*   **Scale:** The dimensions of the cuboid (width, height, depth).\n",
    "\n",
    "The code below defines a `dl.Cube3d` annotation for a \"person\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Your 3D Masterpiece\n",
    "label = \"person\"\n",
    "position = [\n",
    "    73.9,\n",
    "    -5.9,\n",
    "    0.79\n",
    "]\n",
    "rotation = [\n",
    "    0.0,\n",
    "    0.0,\n",
    "    0.0\n",
    "]\n",
    "scale = [\n",
    "    1.2,\n",
    "    0.8,\n",
    "    1.8\n",
    "]\n",
    "\n",
    "# Add Some Extra Details\n",
    "attributes = {\"age\": \"adult\"}\n",
    "description = \"An adult person standing on the station\"\n",
    "\n",
    "# Put It All Together\n",
    "annotation_definition = dl.Cube3d(\n",
    "    label=label,\n",
    "    position=position,\n",
    "    scale=scale,\n",
    "    rotation=rotation,\n",
    "    attributes=attributes,\n",
    "    description=description\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `dl.Cube3d` object is defined, we use an annotation `builder` to add it to the `frames.json` item. We specify the frame range (`frame_num` to `end_frame_num`) where the annotation should appear and then upload it to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Your Digital Sculpting Tools\n",
    "builder = frames_item.annotations.builder()\n",
    "\n",
    "# Place It in Your Scene\n",
    "frame_num = 0\n",
    "end_frame_num = 1\n",
    "object_id = \"0\"\n",
    "metadata = {\"user\": {\"isDistracted\": True}}\n",
    "\n",
    "builder.add(\n",
    "    annotation_definition=annotation_definition,\n",
    "    frame_num=frame_num,\n",
    "    end_frame_num=end_frame_num,\n",
    "    object_id=object_id,\n",
    "    metadata=metadata\n",
    ")\n",
    "\n",
    "# Save Your Work\n",
    "builder.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='view-in-studio'></a>6.2. View in Dataloop Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the annotation is uploaded, you can open the LiDAR video item in the Dataloop platform to view it in the LiDAR Studio. The following command will open the item directly in your web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_item.open_in_web()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='conclusion'></a>7. Conclusion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully walked through the entire process of preparing a LiDAR dataset for the Dataloop platform.\n",
    "\n",
    "### Summary of What You've Accomplished:\n",
    "1. Set up your Dataloop environment and project.\n",
    "2. Structured and uploaded raw LiDAR data (PCDs, images, and mapping file).\n",
    "3. Constructed a composite LiDAR video item using the Dataloop LiDAR SDK.\n",
    "4. Created and uploaded a 3D cuboid annotation to the video item.\n",
    "\n",
    "### Next Steps:\n",
    "From here, you can explore more advanced functionalities:\n",
    "*   Explore the full capabilities of the [Dataloop LiDAR SDK](https://github.com/dataloop-ai-apps/dtlpy-lidar).\n",
    "*   Try constructing a LiDAR video item using a [Custom LiDAR Parser](https://developers.dataloop.ai/tutorials/data_management/items_and_annotations/other_data_types/lidar/chapter#using-custom-lidar-parser) for data that doesn't fit the standard structure.\n",
    "*   Create automated pipelines for LiDAR data processing and annotation.\n",
    "*   Integrate LiDAR workflows with machine learning models for autonomous systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
